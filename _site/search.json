[
  {
    "objectID": "1.2_meta_storage.html",
    "href": "1.2_meta_storage.html",
    "title": "DICOM元数据存储优化",
    "section": "",
    "text": "传统DICOM格式的一个核心问题是元数据冗余。一个CT序列包含数百个文件，每个文件都重复存储相同的患者信息、检查参数等元数据。\n\nimport pydicom\nimport os\nfrom pathlib import Path\n\n# 检查DICOM序列中的元数据冗余\ndicom_dir = \"dicube-testdata/dicom/sample_200\"\ndicom_files = list(Path(dicom_dir).glob(\"*\"))[:3]\n\n# 检查关键字段的重复情况\nds1 = pydicom.dcmread(dicom_files[0], stop_before_pixels=True)\nds2 = pydicom.dcmread(dicom_files[1], stop_before_pixels=True)\n\npatient_same = ds1.PatientName == ds2.PatientName\nseries_same = ds1.SeriesDescription == ds2.SeriesDescription\ninstance_same = ds1.InstanceNumber == ds2.InstanceNumber\n\nprint(f\"PatientName 相同: {patient_same}\")\nprint(f\"SeriesDescription 相同: {series_same}\")\nprint(f\"InstanceNumber 相同: {instance_same}\")\nprint(f\"文件大小: {os.path.getsize(dicom_files[0])/1024:.1f}KB\")\n\nPatientName 相同: True\nSeriesDescription 相同: True\nInstanceNumber 相同: False\n文件大小: 523.4KB",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM元数据存储优化"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#dicom元数据的冗余问题",
    "href": "1.2_meta_storage.html#dicom元数据的冗余问题",
    "title": "DICOM元数据存储优化",
    "section": "",
    "text": "传统DICOM格式的一个核心问题是元数据冗余。一个CT序列包含数百个文件，每个文件都重复存储相同的患者信息、检查参数等元数据。\n\nimport pydicom\nimport os\nfrom pathlib import Path\n\n# 检查DICOM序列中的元数据冗余\ndicom_dir = \"dicube-testdata/dicom/sample_200\"\ndicom_files = list(Path(dicom_dir).glob(\"*\"))[:3]\n\n# 检查关键字段的重复情况\nds1 = pydicom.dcmread(dicom_files[0], stop_before_pixels=True)\nds2 = pydicom.dcmread(dicom_files[1], stop_before_pixels=True)\n\npatient_same = ds1.PatientName == ds2.PatientName\nseries_same = ds1.SeriesDescription == ds2.SeriesDescription\ninstance_same = ds1.InstanceNumber == ds2.InstanceNumber\n\nprint(f\"PatientName 相同: {patient_same}\")\nprint(f\"SeriesDescription 相同: {series_same}\")\nprint(f\"InstanceNumber 相同: {instance_same}\")\nprint(f\"文件大小: {os.path.getsize(dicom_files[0])/1024:.1f}KB\")\n\nPatientName 相同: True\nSeriesDescription 相同: True\nInstanceNumber 相同: False\n文件大小: 523.4KB",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM元数据存储优化"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#dicom-json标准",
    "href": "1.2_meta_storage.html#dicom-json标准",
    "title": "DICOM元数据存储优化",
    "section": "DICOM JSON标准",
    "text": "DICOM JSON标准\nDICOM标准委员会在PS3.18中引入了DICOM JSON格式，提供了标准化的JSON表示方法。\n\nimport json\n\n# PyDICOM直接支持转换为DICOM JSON\nds = pydicom.dcmread(dicom_files[0], stop_before_pixels=True)\ndicom_json = ds.to_json()\n\n# 解析并显示部分内容\njson_data = json.loads(dicom_json)\nkey_fields = [\"00100010\", \"00080020\", \"00200013\"]  # PatientName, StudyDate, InstanceNumber\n\nfor field in key_fields:\n    if field in json_data:\n        print(f\"{field}: {json_data[field]}\")\n\n00100010: {'Value': [{'Alphabetic': 'Anonymous'}], 'vr': 'PN'}\n00080020: {'Value': ['20230720'], 'vr': 'DA'}\n00200013: {'Value': [73], 'vr': 'IS'}",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM元数据存储优化"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#dicube的共享元数据机制",
    "href": "1.2_meta_storage.html#dicube的共享元数据机制",
    "title": "DICOM元数据存储优化",
    "section": "DiCube的共享元数据机制",
    "text": "DiCube的共享元数据机制\nDiCube引入了shared/non-shared元数据分离机制：\n\nShared元数据: 序列中相同的数据（患者信息、检查参数等）\nNon-shared元数据: 每个切片不同的数据（位置、实例编号等）\n\n\nimport dicube\n\n# 转换DICOM序列为DiCube格式\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, \"temp_demo.dcbs\")\n\n# 读取元数据并检查共享状态\nmeta = dicube.load_meta(\"temp_demo.dcbs\")\n\n# 检查共享元数据\nfrom dicube.dicom import CommonTags\npatient_name = meta.get_shared_value(CommonTags.PatientName)\nis_shared = meta.is_shared(CommonTags.PatientName)\nprint(f\"PatientName: {patient_name} (共享: {is_shared})\")\n\n# 检查非共享元数据\ninstance_numbers = meta.get_values(CommonTags.InstanceNumber)\nprint(f\"InstanceNumber数量: {len(instance_numbers)}\")\nprint(f\"范围: {min(instance_numbers)} - {max(instance_numbers)}\")\n\nPatientName: {'Alphabetic': 'Anonymous'} (共享: True)\nInstanceNumber数量: 200\n范围: 1 - 200",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM元数据存储优化"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#zstandard压缩",
    "href": "1.2_meta_storage.html#zstandard压缩",
    "title": "DICOM元数据存储优化",
    "section": "Zstandard压缩",
    "text": "Zstandard压缩\nDiCube使用Zstandard (zstd)压缩JSON元数据，相比gzip具有更好的压缩比和解压速度，它极为适合压缩 Json 格式的 meta 信息。\n\n# 计算DICOM头文件大小（总文件大小减去pixel_array大小）\ndicom_header_total_size = 0\nall_files = list(Path(dicom_dir).glob(\"*\"))\n\nfor dcm_file in all_files:\n    # 获取文件总大小\n    total_size = os.path.getsize(dcm_file)\n    \n    # 读取DICOM文件获取pixel_array大小\n    ds = pydicom.dcmread(dcm_file)\n    if hasattr(ds, 'pixel_array'):\n        pixel_size = ds.pixel_array.nbytes\n    else:\n        pixel_size = 0\n    \n    # 头文件大小 = 总大小 - pixel_array大小\n    header_size = total_size - pixel_size\n    dicom_header_total_size += header_size\n\n# 获取DiCube压缩后的元数据大小\nmeta_json = meta.to_json()\nimport zstandard as zstd\ncompressor = zstd.ZstdCompressor()\ncompressed_meta = compressor.compress(meta_json.encode('utf-8'))\ndicube_meta_size = len(compressed_meta)\n\nprint(f\"DICOM头文件总大小: {dicom_header_total_size/1024/1024:.2f} MB\")\nprint(f\"DiCube压缩元数据大小: {dicube_meta_size/1024/1024:.2f} MB\")\nprint(f\"元数据压缩比: {dicom_header_total_size/dicube_meta_size:.1f}x\")\n\nDICOM头文件总大小: 2.23 MB\nDiCube压缩元数据大小: 0.03 MB\n元数据压缩比: 83.1x",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM元数据存储优化"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#commontags枚举",
    "href": "1.2_meta_storage.html#commontags枚举",
    "title": "DICOM元数据存储优化",
    "section": "CommonTags枚举",
    "text": "CommonTags枚举\nDiCube提供了CommonTags枚举类，避免记忆DICOM标签的十六进制代码：\n\n# 使用CommonTags访问元数据\ninstance_numbers = meta.get_values(CommonTags.InstanceNumber)\npositions = meta.get_values(CommonTags.ImagePositionPatient)\n\nprint(f\"实例编号范围: {min(instance_numbers)} - {max(instance_numbers)}\")\nprint(f\"位置范围: Z轴 {positions[0][2]:.1f} 到 {positions[-1][2]:.1f}\")\n\n实例编号范围: 1 - 200\n位置范围: Z轴 1371.8 到 1282.2",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM元数据存储优化"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#性能对比",
    "href": "1.2_meta_storage.html#性能对比",
    "title": "DICOM元数据存储优化",
    "section": "性能对比",
    "text": "性能对比\n对比传统DICOM和DiCube读取元数据的性能：\n\nimport time\n\n# 传统DICOM方式\nstart_time = time.time()\ndicom_instance_numbers = []\nall_files = list(Path(dicom_dir).glob(\"*\"))\nfor dcm_file in all_files:\n    ds = pydicom.dcmread(dcm_file, stop_before_pixels=True)\n    dicom_instance_numbers.append(int(ds.InstanceNumber))\ndicom_time = time.time() - start_time\n\n# DiCube方式\nstart_time = time.time()\ndicube_meta = dicube.load_meta(\"temp_demo.dcbs\")\ndicube_instance_numbers = dicube_meta.get_values(CommonTags.InstanceNumber)\ndicube_time = time.time() - start_time\n\nprint(f\"传统DICOM: {dicom_time:.4f}秒\")\nprint(f\"DiCube: {dicube_time:.4f}秒\")\nprint(f\"性能提升: {dicom_time/dicube_time:.1f}倍\")\n\n# 清理\nos.remove(\"temp_demo.dcbs\")\n\n传统DICOM: 0.1471秒\nDiCube: 0.0032秒\n性能提升: 46.5倍",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM元数据存储优化"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#总结",
    "href": "1.2_meta_storage.html#总结",
    "title": "DICOM元数据存储优化",
    "section": "总结",
    "text": "总结\nDiCube的元数据管理方案的核心优势：\n\n智能共享 - 消除重复元数据，减少存储空间\n标准兼容 - 基于DICOM JSON标准，确保互操作性\n\n性能提升 - 元数据读取速度显著提升\n\n这些改进使得医学影像处理更加高效，特别适用于需要频繁访问元数据的应用场景。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM元数据存储优化"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html",
    "href": "2.1_mask_compression.html",
    "title": "MedMask压缩技术：Binary vs Multi-label性能对比",
    "section": "",
    "text": "MedMask针对医学图像分割掩膜的稀疏特性，采用了专门优化的压缩策略。与传统的gzip压缩相比，MedMask通过PackBits预处理 + Zstandard主压缩的组合，显著提升了二值掩膜的压缩效率。\n\n\n首先分析测试数据的有效性。TotalSegmentator的s0000样例中，117个文件并非全部包含有效数据：\n\nimport os\nimport time\nimport numpy as np\nimport nibabel as nib\nfrom pathlib import Path\n\n# 读取有效文件列表\nmask_dir = Path('dicube-testdata/mask/s0000')\nwith open(mask_dir / 'nonzero_masks.txt', 'r') as f:\n    valid_files = [line.strip() for line in f.readlines()]\n\nprint(f\"有效掩膜文件: {len(valid_files)} / 117\")\nprint(\"有效文件列表:\")\nfor i, fname in enumerate(valid_files, 1):\n    fpath = mask_dir / fname\n    img = nib.load(fpath)\n    nonzero_count = np.count_nonzero(img.get_fdata())\n    file_size = fpath.stat().st_size / 1024  # KB\n    print(f\"{i:2d}. {fname:&lt;25} - {nonzero_count:6d} 非零像素, {file_size:5.1f} KB\")\n\n有效掩膜文件: 21 / 117\n有效文件列表:\n 1. colon.nii.gz              -  59305 非零像素,  55.8 KB\n 2. femur_left.nii.gz         -  69349 非零像素,  60.2 KB\n 3. femur_right.nii.gz        -  73391 非零像素,  60.4 KB\n 4. gluteus_maximus_left.nii.gz - 138606 非零像素,  67.1 KB\n 5. gluteus_maximus_right.nii.gz - 150852 非零像素,  72.2 KB\n 6. gluteus_medius_left.nii.gz -  21745 非零像素,  48.8 KB\n 7. gluteus_medius_right.nii.gz -  34847 非零像素,  52.4 KB\n 8. gluteus_minimus_left.nii.gz -   9462 非零像素,  47.5 KB\n 9. gluteus_minimus_right.nii.gz -  11818 非零像素,  48.4 KB\n10. hip_left.nii.gz           -  42124 非零像素,  57.1 KB\n11. hip_right.nii.gz          -  48727 非零像素,  58.7 KB\n12. iliac_artery_left.nii.gz  -   1155 非零像素,  44.2 KB\n13. iliac_artery_right.nii.gz -    630 非零像素,  43.9 KB\n14. iliac_vena_left.nii.gz    -   1635 非零像素,  44.5 KB\n15. iliac_vena_right.nii.gz   -   1028 非零像素,  44.0 KB\n16. iliopsoas_left.nii.gz     -  20865 非零像素,  49.5 KB\n17. iliopsoas_right.nii.gz    -  27575 非零像素,  50.3 KB\n18. rib_right_12.nii.gz       -     13 非零像素,  43.3 KB\n19. sacrum.nii.gz             -   3804 非零像素,  45.0 KB\n20. small_bowel.nii.gz        -    244 非零像素,  43.4 KB\n21. urinary_bladder.nii.gz    -  68016 非零像素,  54.8 KB\n\n\n\n\n\n选择几个代表性的二值掩膜进行压缩性能测试，对比NIfTI(.nii.gz)、NumPy(.npz)和MedMask三种格式：\n\nimport gzip\nimport pickle\nimport tempfile\nfrom medmask import SegmentationMask\nfrom spacetransformer import Space\n\n# 选择测试文件 - 选择不同大小的掩膜以测试压缩效果\ntest_files = [\n    'urinary_bladder.nii.gz',      # 大掩膜 (68016 非零像素)\n    'gluteus_maximus_right.nii.gz', # 大掩膜 (150852 非零像素)\n    'colon.nii.gz',                # 中等掩膜 (59305 非零像素)\n    'iliopsoas_left.nii.gz',       # 中等掩膜 (20865 非零像素)\n    'iliac_artery_left.nii.gz',    # 小掩膜 (1155 非零像素)\n    'small_bowel.nii.gz'           # 极小掩膜 (244 非零像素)\n]\n\nprint(\"Binary Mask 压缩性能测试\\n\" + \"=\"*60)\n\nresults = []\n\nfor test_file in test_files:\n    print(f\"\\n测试文件: {test_file}\")\n    \n    # 加载原始数据\n    original_path = mask_dir / test_file\n    nii_img = nib.load(original_path)\n    mask_data = nii_img.get_fdata().astype(np.uint8)\n    space = Space.from_nifti(nii_img)\n    \n    # 原始NIfTI大小\n    nifti_size = original_path.stat().st_size\n    \n    # 1. NPZ格式测试\n    npz_start = time.time()\n    with tempfile.NamedTemporaryFile(suffix='.npz', delete=False) as tmp:\n        np.savez_compressed(tmp.name, mask=mask_data)\n        npz_encode_time = time.time() - npz_start\n        npz_size = Path(tmp.name).stat().st_size\n        \n        # NPZ读取测试\n        npz_read_start = time.time()\n        loaded_npz = np.load(tmp.name)\n        npz_data = loaded_npz['mask']\n        npz_decode_time = time.time() - npz_read_start\n        \n        os.unlink(tmp.name)\n    \n    # 2. MedMask格式测试\n    medmask_start = time.time()\n    organ_name = test_file.replace('.nii.gz', '')\n    mask_obj = SegmentationMask(mask_data, {organ_name: 1}, space=space)\n    \n    with tempfile.NamedTemporaryFile(suffix='.msk', delete=False) as tmp:\n        mask_obj.save(tmp.name)\n        medmask_encode_time = time.time() - medmask_start\n        medmask_size = Path(tmp.name).stat().st_size\n        \n        # MedMask读取测试\n        medmask_read_start = time.time()\n        loaded_mask = SegmentationMask.load(tmp.name)\n        medmask_data = loaded_mask.get_binary_mask_by_names(organ_name)\n        medmask_decode_time = time.time() - medmask_read_start\n        \n        os.unlink(tmp.name)\n    \n    # 验证数据一致性\n    data_consistent = np.array_equal(mask_data &gt; 0, npz_data &gt; 0) and np.array_equal(mask_data &gt; 0, medmask_data &gt; 0)\n    \n    # 记录结果\n    result = {\n        'file': test_file,\n        'nonzero_pixels': np.count_nonzero(mask_data),\n        'nifti_size': nifti_size,\n        'npz_size': npz_size,\n        'medmask_size': medmask_size,\n        'npz_encode_time': npz_encode_time,\n        'medmask_encode_time': medmask_encode_time,\n        'npz_decode_time': npz_decode_time,\n        'medmask_decode_time': medmask_decode_time,\n        'data_consistent': data_consistent\n    }\n    results.append(result)\n    \n    print(f\"  非零像素: {result['nonzero_pixels']:6d}\")\n    print(f\"  压缩效果:\")\n    print(f\"    NIfTI:  {nifti_size/1024:6.1f} KB (基准)\")\n    print(f\"    NPZ:    {npz_size/1024:6.1f} KB (压缩比 {nifti_size/npz_size:.1f}:1)\")\n    print(f\"    MedMask:{medmask_size/1024:6.1f} KB (压缩比 {nifti_size/medmask_size:.1f}:1)\")\n    print(f\"  编码时间:\")\n    print(f\"    NPZ:    {npz_encode_time*1000:6.1f} ms\")\n    print(f\"    MedMask:{medmask_encode_time*1000:6.1f} ms\")\n    print(f\"  解码时间:\")\n    print(f\"    NPZ:    {npz_decode_time*1000:6.1f} ms\")\n    print(f\"    MedMask:{medmask_decode_time*1000:6.1f} ms\")\n    print(f\"  数据一致性: {'✓' if data_consistent else '✗'}\")\n\nBinary Mask 压缩性能测试\n============================================================\n\n测试文件: urinary_bladder.nii.gz\n  非零像素:  68016\n  压缩效果:\n    NIfTI:    54.8 KB (基准)\n    NPZ:      15.0 KB (压缩比 3.6:1)\n    MedMask:   8.4 KB (压缩比 6.5:1)\n  编码时间:\n    NPZ:      45.8 ms\n    MedMask:  79.1 ms\n  解码时间:\n    NPZ:      25.1 ms\n    MedMask:   5.6 ms\n  数据一致性: ✓\n\n测试文件: gluteus_maximus_right.nii.gz\n  非零像素: 150852\n  压缩效果:\n    NIfTI:    72.2 KB (基准)\n    NPZ:      25.5 KB (压缩比 2.8:1)\n    MedMask:  15.9 KB (压缩比 4.5:1)\n  编码时间:\n    NPZ:      47.7 ms\n    MedMask:  64.6 ms\n  解码时间:\n    NPZ:      22.7 ms\n    MedMask:   2.6 ms\n  数据一致性: ✓\n\n测试文件: colon.nii.gz\n  非零像素:  59305\n  压缩效果:\n    NIfTI:    55.8 KB (基准)\n    NPZ:      16.4 KB (压缩比 3.4:1)\n    MedMask:  10.2 KB (压缩比 5.4:1)\n  编码时间:\n    NPZ:      41.5 ms\n    MedMask:  66.6 ms\n  解码时间:\n    NPZ:      26.1 ms\n    MedMask:   6.9 ms\n  数据一致性: ✓\n\n测试文件: iliopsoas_left.nii.gz\n  非零像素:  20865\n  压缩效果:\n    NIfTI:    49.5 KB (基准)\n    NPZ:      13.3 KB (压缩比 3.7:1)\n    MedMask:   4.5 KB (压缩比 10.9:1)\n  编码时间:\n    NPZ:      40.7 ms\n    MedMask:  65.1 ms\n  解码时间:\n    NPZ:      24.7 ms\n    MedMask:   2.2 ms\n  数据一致性: ✓\n\n测试文件: iliac_artery_left.nii.gz\n  非零像素:   1155\n  压缩效果:\n    NIfTI:    44.2 KB (基准)\n    NPZ:      10.5 KB (压缩比 4.2:1)\n    MedMask:   1.5 KB (压缩比 30.3:1)\n  编码时间:\n    NPZ:      39.7 ms\n    MedMask:  66.0 ms\n  解码时间:\n    NPZ:      27.2 ms\n    MedMask:   6.9 ms\n  数据一致性: ✓\n\n测试文件: small_bowel.nii.gz\n  非零像素:    244\n  压缩效果:\n    NIfTI:    43.4 KB (基准)\n    NPZ:       9.9 KB (压缩比 4.4:1)\n    MedMask:   1.1 KB (压缩比 39.4:1)\n  编码时间:\n    NPZ:      39.3 ms\n    MedMask:  65.0 ms\n  解码时间:\n    NPZ:      25.3 ms\n    MedMask:   3.7 ms\n  数据一致性: ✓\n\n\n\n\n\n\n# 汇总统计\nprint(\"\\nBinary Mask 压缩性能汇总\\n\" + \"=\"*80)\n\ntotal_nifti = sum(r['nifti_size'] for r in results)\ntotal_npz = sum(r['npz_size'] for r in results)  \ntotal_medmask = sum(r['medmask_size'] for r in results)\n\navg_npz_encode = np.mean([r['npz_encode_time'] for r in results]) * 1000\navg_medmask_encode = np.mean([r['medmask_encode_time'] for r in results]) * 1000\navg_npz_decode = np.mean([r['npz_decode_time'] for r in results]) * 1000\navg_medmask_decode = np.mean([r['medmask_decode_time'] for r in results]) * 1000\n\nprint(f\"总存储大小对比:\")\nprint(f\"  NIfTI:   {total_nifti/1024:7.1f} KB\")\nprint(f\"  NPZ:     {total_npz/1024:7.1f} KB (压缩比 {total_nifti/total_npz:.1f}:1)\")\nprint(f\"  MedMask: {total_medmask/1024:7.1f} KB (压缩比 {total_nifti/total_medmask:.1f}:1)\")\n\nprint(f\"\\n平均处理时间:\")\nprint(f\"  编码时间 - NPZ: {avg_npz_encode:.1f}ms, MedMask: {avg_medmask_encode:.1f}ms\")\nprint(f\"  解码时间 - NPZ: {avg_npz_decode:.1f}ms, MedMask: {avg_medmask_decode:.1f}ms\")\n\nprint(f\"\\nMedMask相对于NPZ的优势:\")\nprint(f\"  存储空间节省: {(1 - total_medmask/total_npz)*100:.1f}%\")\nprint(f\"  编码速度: {avg_npz_encode/avg_medmask_encode:.1f}x {'更快' if avg_medmask_encode &lt; avg_npz_encode else '更慢'}\")\nprint(f\"  解码速度: {avg_npz_decode/avg_medmask_decode:.1f}x {'更快' if avg_medmask_decode &lt; avg_npz_decode else '更慢'}\")\n\n\nBinary Mask 压缩性能汇总\n================================================================================\n总存储大小对比:\n  NIfTI:     319.9 KB\n  NPZ:        90.7 KB (压缩比 3.5:1)\n  MedMask:    41.7 KB (压缩比 7.7:1)\n\n平均处理时间:\n  编码时间 - NPZ: 42.4ms, MedMask: 67.7ms\n  解码时间 - NPZ: 25.2ms, MedMask: 4.7ms\n\nMedMask相对于NPZ的优势:\n  存储空间节省: 54.0%\n  编码速度: 0.6x 更慢\n  解码速度: 5.4x 更快",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "MedMask压缩技术：Binary vs Multi-label性能对比"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html#压缩技术概述",
    "href": "2.1_mask_compression.html#压缩技术概述",
    "title": "MedMask压缩技术：Binary vs Multi-label性能对比",
    "section": "",
    "text": "MedMask针对医学图像分割掩膜的稀疏特性，采用了专门优化的压缩策略。与传统的gzip压缩相比，MedMask通过PackBits预处理 + Zstandard主压缩的组合，显著提升了二值掩膜的压缩效率。\n\n\n首先分析测试数据的有效性。TotalSegmentator的s0000样例中，117个文件并非全部包含有效数据：\n\nimport os\nimport time\nimport numpy as np\nimport nibabel as nib\nfrom pathlib import Path\n\n# 读取有效文件列表\nmask_dir = Path('dicube-testdata/mask/s0000')\nwith open(mask_dir / 'nonzero_masks.txt', 'r') as f:\n    valid_files = [line.strip() for line in f.readlines()]\n\nprint(f\"有效掩膜文件: {len(valid_files)} / 117\")\nprint(\"有效文件列表:\")\nfor i, fname in enumerate(valid_files, 1):\n    fpath = mask_dir / fname\n    img = nib.load(fpath)\n    nonzero_count = np.count_nonzero(img.get_fdata())\n    file_size = fpath.stat().st_size / 1024  # KB\n    print(f\"{i:2d}. {fname:&lt;25} - {nonzero_count:6d} 非零像素, {file_size:5.1f} KB\")\n\n有效掩膜文件: 21 / 117\n有效文件列表:\n 1. colon.nii.gz              -  59305 非零像素,  55.8 KB\n 2. femur_left.nii.gz         -  69349 非零像素,  60.2 KB\n 3. femur_right.nii.gz        -  73391 非零像素,  60.4 KB\n 4. gluteus_maximus_left.nii.gz - 138606 非零像素,  67.1 KB\n 5. gluteus_maximus_right.nii.gz - 150852 非零像素,  72.2 KB\n 6. gluteus_medius_left.nii.gz -  21745 非零像素,  48.8 KB\n 7. gluteus_medius_right.nii.gz -  34847 非零像素,  52.4 KB\n 8. gluteus_minimus_left.nii.gz -   9462 非零像素,  47.5 KB\n 9. gluteus_minimus_right.nii.gz -  11818 非零像素,  48.4 KB\n10. hip_left.nii.gz           -  42124 非零像素,  57.1 KB\n11. hip_right.nii.gz          -  48727 非零像素,  58.7 KB\n12. iliac_artery_left.nii.gz  -   1155 非零像素,  44.2 KB\n13. iliac_artery_right.nii.gz -    630 非零像素,  43.9 KB\n14. iliac_vena_left.nii.gz    -   1635 非零像素,  44.5 KB\n15. iliac_vena_right.nii.gz   -   1028 非零像素,  44.0 KB\n16. iliopsoas_left.nii.gz     -  20865 非零像素,  49.5 KB\n17. iliopsoas_right.nii.gz    -  27575 非零像素,  50.3 KB\n18. rib_right_12.nii.gz       -     13 非零像素,  43.3 KB\n19. sacrum.nii.gz             -   3804 非零像素,  45.0 KB\n20. small_bowel.nii.gz        -    244 非零像素,  43.4 KB\n21. urinary_bladder.nii.gz    -  68016 非零像素,  54.8 KB\n\n\n\n\n\n选择几个代表性的二值掩膜进行压缩性能测试，对比NIfTI(.nii.gz)、NumPy(.npz)和MedMask三种格式：\n\nimport gzip\nimport pickle\nimport tempfile\nfrom medmask import SegmentationMask\nfrom spacetransformer import Space\n\n# 选择测试文件 - 选择不同大小的掩膜以测试压缩效果\ntest_files = [\n    'urinary_bladder.nii.gz',      # 大掩膜 (68016 非零像素)\n    'gluteus_maximus_right.nii.gz', # 大掩膜 (150852 非零像素)\n    'colon.nii.gz',                # 中等掩膜 (59305 非零像素)\n    'iliopsoas_left.nii.gz',       # 中等掩膜 (20865 非零像素)\n    'iliac_artery_left.nii.gz',    # 小掩膜 (1155 非零像素)\n    'small_bowel.nii.gz'           # 极小掩膜 (244 非零像素)\n]\n\nprint(\"Binary Mask 压缩性能测试\\n\" + \"=\"*60)\n\nresults = []\n\nfor test_file in test_files:\n    print(f\"\\n测试文件: {test_file}\")\n    \n    # 加载原始数据\n    original_path = mask_dir / test_file\n    nii_img = nib.load(original_path)\n    mask_data = nii_img.get_fdata().astype(np.uint8)\n    space = Space.from_nifti(nii_img)\n    \n    # 原始NIfTI大小\n    nifti_size = original_path.stat().st_size\n    \n    # 1. NPZ格式测试\n    npz_start = time.time()\n    with tempfile.NamedTemporaryFile(suffix='.npz', delete=False) as tmp:\n        np.savez_compressed(tmp.name, mask=mask_data)\n        npz_encode_time = time.time() - npz_start\n        npz_size = Path(tmp.name).stat().st_size\n        \n        # NPZ读取测试\n        npz_read_start = time.time()\n        loaded_npz = np.load(tmp.name)\n        npz_data = loaded_npz['mask']\n        npz_decode_time = time.time() - npz_read_start\n        \n        os.unlink(tmp.name)\n    \n    # 2. MedMask格式测试\n    medmask_start = time.time()\n    organ_name = test_file.replace('.nii.gz', '')\n    mask_obj = SegmentationMask(mask_data, {organ_name: 1}, space=space)\n    \n    with tempfile.NamedTemporaryFile(suffix='.msk', delete=False) as tmp:\n        mask_obj.save(tmp.name)\n        medmask_encode_time = time.time() - medmask_start\n        medmask_size = Path(tmp.name).stat().st_size\n        \n        # MedMask读取测试\n        medmask_read_start = time.time()\n        loaded_mask = SegmentationMask.load(tmp.name)\n        medmask_data = loaded_mask.get_binary_mask_by_names(organ_name)\n        medmask_decode_time = time.time() - medmask_read_start\n        \n        os.unlink(tmp.name)\n    \n    # 验证数据一致性\n    data_consistent = np.array_equal(mask_data &gt; 0, npz_data &gt; 0) and np.array_equal(mask_data &gt; 0, medmask_data &gt; 0)\n    \n    # 记录结果\n    result = {\n        'file': test_file,\n        'nonzero_pixels': np.count_nonzero(mask_data),\n        'nifti_size': nifti_size,\n        'npz_size': npz_size,\n        'medmask_size': medmask_size,\n        'npz_encode_time': npz_encode_time,\n        'medmask_encode_time': medmask_encode_time,\n        'npz_decode_time': npz_decode_time,\n        'medmask_decode_time': medmask_decode_time,\n        'data_consistent': data_consistent\n    }\n    results.append(result)\n    \n    print(f\"  非零像素: {result['nonzero_pixels']:6d}\")\n    print(f\"  压缩效果:\")\n    print(f\"    NIfTI:  {nifti_size/1024:6.1f} KB (基准)\")\n    print(f\"    NPZ:    {npz_size/1024:6.1f} KB (压缩比 {nifti_size/npz_size:.1f}:1)\")\n    print(f\"    MedMask:{medmask_size/1024:6.1f} KB (压缩比 {nifti_size/medmask_size:.1f}:1)\")\n    print(f\"  编码时间:\")\n    print(f\"    NPZ:    {npz_encode_time*1000:6.1f} ms\")\n    print(f\"    MedMask:{medmask_encode_time*1000:6.1f} ms\")\n    print(f\"  解码时间:\")\n    print(f\"    NPZ:    {npz_decode_time*1000:6.1f} ms\")\n    print(f\"    MedMask:{medmask_decode_time*1000:6.1f} ms\")\n    print(f\"  数据一致性: {'✓' if data_consistent else '✗'}\")\n\nBinary Mask 压缩性能测试\n============================================================\n\n测试文件: urinary_bladder.nii.gz\n  非零像素:  68016\n  压缩效果:\n    NIfTI:    54.8 KB (基准)\n    NPZ:      15.0 KB (压缩比 3.6:1)\n    MedMask:   8.4 KB (压缩比 6.5:1)\n  编码时间:\n    NPZ:      45.8 ms\n    MedMask:  79.1 ms\n  解码时间:\n    NPZ:      25.1 ms\n    MedMask:   5.6 ms\n  数据一致性: ✓\n\n测试文件: gluteus_maximus_right.nii.gz\n  非零像素: 150852\n  压缩效果:\n    NIfTI:    72.2 KB (基准)\n    NPZ:      25.5 KB (压缩比 2.8:1)\n    MedMask:  15.9 KB (压缩比 4.5:1)\n  编码时间:\n    NPZ:      47.7 ms\n    MedMask:  64.6 ms\n  解码时间:\n    NPZ:      22.7 ms\n    MedMask:   2.6 ms\n  数据一致性: ✓\n\n测试文件: colon.nii.gz\n  非零像素:  59305\n  压缩效果:\n    NIfTI:    55.8 KB (基准)\n    NPZ:      16.4 KB (压缩比 3.4:1)\n    MedMask:  10.2 KB (压缩比 5.4:1)\n  编码时间:\n    NPZ:      41.5 ms\n    MedMask:  66.6 ms\n  解码时间:\n    NPZ:      26.1 ms\n    MedMask:   6.9 ms\n  数据一致性: ✓\n\n测试文件: iliopsoas_left.nii.gz\n  非零像素:  20865\n  压缩效果:\n    NIfTI:    49.5 KB (基准)\n    NPZ:      13.3 KB (压缩比 3.7:1)\n    MedMask:   4.5 KB (压缩比 10.9:1)\n  编码时间:\n    NPZ:      40.7 ms\n    MedMask:  65.1 ms\n  解码时间:\n    NPZ:      24.7 ms\n    MedMask:   2.2 ms\n  数据一致性: ✓\n\n测试文件: iliac_artery_left.nii.gz\n  非零像素:   1155\n  压缩效果:\n    NIfTI:    44.2 KB (基准)\n    NPZ:      10.5 KB (压缩比 4.2:1)\n    MedMask:   1.5 KB (压缩比 30.3:1)\n  编码时间:\n    NPZ:      39.7 ms\n    MedMask:  66.0 ms\n  解码时间:\n    NPZ:      27.2 ms\n    MedMask:   6.9 ms\n  数据一致性: ✓\n\n测试文件: small_bowel.nii.gz\n  非零像素:    244\n  压缩效果:\n    NIfTI:    43.4 KB (基准)\n    NPZ:       9.9 KB (压缩比 4.4:1)\n    MedMask:   1.1 KB (压缩比 39.4:1)\n  编码时间:\n    NPZ:      39.3 ms\n    MedMask:  65.0 ms\n  解码时间:\n    NPZ:      25.3 ms\n    MedMask:   3.7 ms\n  数据一致性: ✓\n\n\n\n\n\n\n# 汇总统计\nprint(\"\\nBinary Mask 压缩性能汇总\\n\" + \"=\"*80)\n\ntotal_nifti = sum(r['nifti_size'] for r in results)\ntotal_npz = sum(r['npz_size'] for r in results)  \ntotal_medmask = sum(r['medmask_size'] for r in results)\n\navg_npz_encode = np.mean([r['npz_encode_time'] for r in results]) * 1000\navg_medmask_encode = np.mean([r['medmask_encode_time'] for r in results]) * 1000\navg_npz_decode = np.mean([r['npz_decode_time'] for r in results]) * 1000\navg_medmask_decode = np.mean([r['medmask_decode_time'] for r in results]) * 1000\n\nprint(f\"总存储大小对比:\")\nprint(f\"  NIfTI:   {total_nifti/1024:7.1f} KB\")\nprint(f\"  NPZ:     {total_npz/1024:7.1f} KB (压缩比 {total_nifti/total_npz:.1f}:1)\")\nprint(f\"  MedMask: {total_medmask/1024:7.1f} KB (压缩比 {total_nifti/total_medmask:.1f}:1)\")\n\nprint(f\"\\n平均处理时间:\")\nprint(f\"  编码时间 - NPZ: {avg_npz_encode:.1f}ms, MedMask: {avg_medmask_encode:.1f}ms\")\nprint(f\"  解码时间 - NPZ: {avg_npz_decode:.1f}ms, MedMask: {avg_medmask_decode:.1f}ms\")\n\nprint(f\"\\nMedMask相对于NPZ的优势:\")\nprint(f\"  存储空间节省: {(1 - total_medmask/total_npz)*100:.1f}%\")\nprint(f\"  编码速度: {avg_npz_encode/avg_medmask_encode:.1f}x {'更快' if avg_medmask_encode &lt; avg_npz_encode else '更慢'}\")\nprint(f\"  解码速度: {avg_npz_decode/avg_medmask_decode:.1f}x {'更快' if avg_medmask_decode &lt; avg_npz_decode else '更慢'}\")\n\n\nBinary Mask 压缩性能汇总\n================================================================================\n总存储大小对比:\n  NIfTI:     319.9 KB\n  NPZ:        90.7 KB (压缩比 3.5:1)\n  MedMask:    41.7 KB (压缩比 7.7:1)\n\n平均处理时间:\n  编码时间 - NPZ: 42.4ms, MedMask: 67.7ms\n  解码时间 - NPZ: 25.2ms, MedMask: 4.7ms\n\nMedMask相对于NPZ的优势:\n  存储空间节省: 54.0%\n  编码速度: 0.6x 更慢\n  解码速度: 5.4x 更快",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "MedMask压缩技术：Binary vs Multi-label性能对比"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html#multi-label-mask-压缩测试",
    "href": "2.1_mask_compression.html#multi-label-mask-压缩测试",
    "title": "MedMask压缩技术：Binary vs Multi-label性能对比",
    "section": "Multi-label Mask 压缩测试",
    "text": "Multi-label Mask 压缩测试\n由于s0000样例中肋骨和脊椎数据大多为空，我们使用现有的有效数据构建multi-label测试：\n\nprint(\"Multi-label Mask 压缩测试\\n\" + \"=\"*60)\n\n# 构建测试组合\ntest_groups = [\n    {\n        'name': 'gluteus_muscles',\n        'files': ['gluteus_maximus_left.nii.gz', 'gluteus_maximus_right.nii.gz', \n                 'gluteus_medius_left.nii.gz', 'gluteus_medius_right.nii.gz'],\n        'description': '臀肌群组合'\n    },\n    {\n        'name': 'femur_and_hip',\n        'files': ['femur_left.nii.gz', 'femur_right.nii.gz', \n                 'hip_left.nii.gz', 'hip_right.nii.gz'],\n        'description': '股骨和髋骨组合'\n    },\n    {\n        'name': 'pelvic_organs',\n        'files': ['urinary_bladder.nii.gz', 'colon.nii.gz', 'small_bowel.nii.gz'],\n        'description': '盆腔器官组合'\n    }\n]\n\nmultilabel_results = []\n\nfor group in test_groups:\n    print(f\"\\n测试组: {group['name']} ({group['description']})\")\n    \n    # 加载并合并多个掩膜\n    first_file = mask_dir / group['files'][0]\n    ref_img = nib.load(first_file)\n    space = Space.from_nifti(ref_img)\n    \n    # 方法1: 分别存储 (传统方法)\n    individual_nifti_size = 0\n    individual_npz_size = 0\n    individual_encode_time = 0\n    individual_decode_time = 0\n    \n    for i, fname in enumerate(group['files']):\n        fpath = mask_dir / fname\n        if fpath.exists():\n            individual_nifti_size += fpath.stat().st_size\n            \n            # NPZ单独存储测试\n            img = nib.load(fpath)\n            data = img.get_fdata().astype(np.uint8)\n            \n            start_time = time.time()\n            with tempfile.NamedTemporaryFile(suffix='.npz', delete=False) as tmp:\n                np.savez_compressed(tmp.name, mask=data)\n                individual_encode_time += time.time() - start_time\n                individual_npz_size += Path(tmp.name).stat().st_size\n                \n                start_time = time.time()\n                loaded = np.load(tmp.name)\n                _ = loaded['mask']\n                individual_decode_time += time.time() - start_time\n                \n                os.unlink(tmp.name)\n    \n    # 方法2: MedMask multi-label存储\n    combined_mask = SegmentationMask.lazy_init(bit_depth=8, space=space)\n    \n    medmask_start = time.time()\n    for i, fname in enumerate(group['files']):\n        fpath = mask_dir / fname\n        if fpath.exists():\n            img = nib.load(fpath)\n            mask_data = img.get_fdata() &gt; 0\n            organ_name = fname.replace('.nii.gz', '')\n            combined_mask.add_label(mask_data, i + 1, organ_name)\n    \n    with tempfile.NamedTemporaryFile(suffix='.msk', delete=False) as tmp:\n        combined_mask.save(tmp.name)\n        medmask_encode_time = time.time() - medmask_start\n        medmask_size = Path(tmp.name).stat().st_size\n        \n        # MedMask解码测试\n        medmask_decode_start = time.time()\n        loaded_combined = SegmentationMask.load(tmp.name)\n        # 解码所有标签\n        for fname in group['files']:\n            organ_name = fname.replace('.nii.gz', '')\n            try:\n                _ = loaded_combined.get_binary_mask_by_names(organ_name)\n            except:\n                pass  # 某些文件可能不存在\n        medmask_decode_time = time.time() - medmask_decode_start\n        \n        os.unlink(tmp.name)\n    \n    # 记录结果\n    result = {\n        'group_name': group['name'],\n        'num_files': len(group['files']),\n        'individual_nifti_size': individual_nifti_size,\n        'individual_npz_size': individual_npz_size,\n        'medmask_size': medmask_size,\n        'individual_encode_time': individual_encode_time,\n        'medmask_encode_time': medmask_encode_time,\n        'individual_decode_time': individual_decode_time,\n        'medmask_decode_time': medmask_decode_time\n    }\n    multilabel_results.append(result)\n    \n    print(f\"  文件数: {result['num_files']}\")\n    print(f\"  存储大小:\")\n    print(f\"    分别存储(NIfTI): {individual_nifti_size/1024:6.1f} KB\")\n    print(f\"    分别存储(NPZ):   {individual_npz_size/1024:6.1f} KB (压缩比 {individual_nifti_size/individual_npz_size:.1f}:1)\")\n    print(f\"    MedMask合并:     {medmask_size/1024:6.1f} KB (压缩比 {individual_nifti_size/medmask_size:.1f}:1)\")\n    print(f\"  处理时间:\")\n    print(f\"    分别处理编码: {individual_encode_time*1000:6.1f} ms\")\n    print(f\"    MedMask编码:  {medmask_encode_time*1000:6.1f} ms\")\n    print(f\"    分别处理解码: {individual_decode_time*1000:6.1f} ms\") \n    print(f\"    MedMask解码:  {medmask_decode_time*1000:6.1f} ms\")\n\nMulti-label Mask 压缩测试\n============================================================\n\n测试组: gluteus_muscles (臀肌群组合)\n  文件数: 4\n  存储大小:\n    分别存储(NIfTI):  240.4 KB\n    分别存储(NPZ):     72.9 KB (压缩比 3.3:1)\n    MedMask合并:       31.6 KB (压缩比 7.6:1)\n  处理时间:\n    分别处理编码:  182.4 ms\n    MedMask编码:   230.0 ms\n    分别处理解码:   97.8 ms\n    MedMask解码:    10.7 ms\n\n测试组: femur_and_hip (股骨和髋骨组合)\n  文件数: 4\n  存储大小:\n    分别存储(NIfTI):  236.4 KB\n    分别存储(NPZ):     77.2 KB (压缩比 3.1:1)\n    MedMask合并:       31.4 KB (压缩比 7.5:1)\n  处理时间:\n    分别处理编码:  184.8 ms\n    MedMask编码:   211.5 ms\n    分别处理解码:   94.3 ms\n    MedMask解码:    10.4 ms\n\n测试组: pelvic_organs (盆腔器官组合)\n  文件数: 3\n  存储大小:\n    分别存储(NIfTI):  154.0 KB\n    分别存储(NPZ):     41.4 KB (压缩比 3.7:1)\n    MedMask合并:       16.7 KB (压缩比 9.2:1)\n  处理时间:\n    分别处理编码:  121.1 ms\n    MedMask编码:   123.5 ms\n    分别处理解码:   73.5 ms\n    MedMask解码:     6.4 ms\n\n\n\nMulti-label 性能汇总\n\nprint(\"\\nMulti-label Mask 压缩性能汇总\\n\" + \"=\"*80)\n\ntotal_groups = len(multilabel_results)\ntotal_individual_nifti = sum(r['individual_nifti_size'] for r in multilabel_results)\ntotal_individual_npz = sum(r['individual_npz_size'] for r in multilabel_results)\ntotal_medmask = sum(r['medmask_size'] for r in multilabel_results)\n\navg_individual_encode = np.mean([r['individual_encode_time'] for r in multilabel_results]) * 1000\navg_medmask_encode = np.mean([r['medmask_encode_time'] for r in multilabel_results]) * 1000\navg_individual_decode = np.mean([r['individual_decode_time'] for r in multilabel_results]) * 1000\navg_medmask_decode = np.mean([r['medmask_decode_time'] for r in multilabel_results]) * 1000\n\nprint(f\"总体对比 ({total_groups}个测试组):\")\nprint(f\"  存储大小:\")\nprint(f\"    分别存储(NIfTI): {total_individual_nifti/1024:7.1f} KB\")\nprint(f\"    分别存储(NPZ):   {total_individual_npz/1024:7.1f} KB (压缩比 {total_individual_nifti/total_individual_npz:.1f}:1)\")\nprint(f\"    MedMask合并:     {total_medmask/1024:7.1f} KB (压缩比 {total_individual_nifti/total_medmask:.1f}:1)\")\n\nprint(f\"\\n  平均处理时间:\")\nprint(f\"    编码 - 分别处理: {avg_individual_encode:.1f}ms, MedMask: {avg_medmask_encode:.1f}ms\")\nprint(f\"    解码 - 分别处理: {avg_individual_decode:.1f}ms, MedMask: {avg_medmask_decode:.1f}ms\")\n\nprint(f\"\\n  MedMask优势:\")\nprint(f\"    存储效率: 相比NPZ节省 {(1-total_medmask/total_individual_npz)*100:.1f}%\")\nprint(f\"    文件管理: {sum(r['num_files'] for r in multilabel_results)} 个文件 → {total_groups} 个文件\")\nprint(f\"    编码效率: {avg_individual_encode/avg_medmask_encode:.1f}x {'提升' if avg_medmask_encode &lt; avg_individual_encode else '下降'}\")\nprint(f\"    解码效率: {avg_individual_decode/avg_medmask_decode:.1f}x {'提升' if avg_medmask_decode &lt; avg_individual_decode else '下降'}\")\n\n\nMulti-label Mask 压缩性能汇总\n================================================================================\n总体对比 (3个测试组):\n  存储大小:\n    分别存储(NIfTI):   630.8 KB\n    分别存储(NPZ):     191.5 KB (压缩比 3.3:1)\n    MedMask合并:        79.7 KB (压缩比 7.9:1)\n\n  平均处理时间:\n    编码 - 分别处理: 162.8ms, MedMask: 188.3ms\n    解码 - 分别处理: 88.5ms, MedMask: 9.2ms\n\n  MedMask优势:\n    存储效率: 相比NPZ节省 58.4%\n    文件管理: 11 个文件 → 3 个文件\n    编码效率: 0.9x 下降\n    解码效率: 9.6x 提升",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "MedMask压缩技术：Binary vs Multi-label性能对比"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html#关键技术特性分析",
    "href": "2.1_mask_compression.html#关键技术特性分析",
    "title": "MedMask压缩技术：Binary vs Multi-label性能对比",
    "section": "关键技术特性分析",
    "text": "关键技术特性分析\n\nPackBits预处理的威力\nMedMask对二值掩膜的优化主要来自PackBits预处理，它专门针对稀疏二值数据进行行程编码：\n\nprint(\"PackBits预处理效果分析\\n\" + \"=\"*50)\n\n# 选择一个代表性的稀疏掩膜进行详细分析\ntest_mask = 'iliac_artery_left.nii.gz'  # 小血管，高度稀疏\nimg = nib.load(mask_dir / test_mask)\ndata = img.get_fdata().astype(np.uint8)\n\ntotal_voxels = data.size\nnonzero_voxels = np.count_nonzero(data)\nsparsity = (total_voxels - nonzero_voxels) / total_voxels\n\nprint(f\"测试掩膜: {test_mask}\")\nprint(f\"总体素数: {total_voxels:,}\")\nprint(f\"非零体素: {nonzero_voxels:,}\")\nprint(f\"稀疏度: {sparsity:.1%}\")\n\n# 分析不同压缩方法的效果\nraw_size = data.nbytes\ngzip_compressed = gzip.compress(data.tobytes())\nnpz_temp = tempfile.NamedTemporaryFile(suffix='.npz', delete=False)\nnp.savez_compressed(npz_temp.name, mask=data)\nnpz_size = Path(npz_temp.name).stat().st_size\nos.unlink(npz_temp.name)\n\nprint(f\"\\n压缩效果对比:\")\nprint(f\"  原始大小:     {raw_size/1024:6.1f} KB\")\nprint(f\"  gzip压缩:     {len(gzip_compressed)/1024:6.1f} KB (压缩比 {raw_size/len(gzip_compressed):.1f}:1)\")\nprint(f\"  NPZ(gzip):    {npz_size/1024:6.1f} KB (压缩比 {raw_size/npz_size:.1f}:1)\")\n\n# MedMask的压缩结果\nmask_obj = SegmentationMask(data, {'test': 1}, Space.from_nifti(img))\nmedmask_temp = tempfile.NamedTemporaryFile(suffix='.msk', delete=False)\nmask_obj.save(medmask_temp.name)\nmedmask_size = Path(medmask_temp.name).stat().st_size\nos.unlink(medmask_temp.name)\n\nprint(f\"  MedMask:      {medmask_size/1024:6.1f} KB (压缩比 {raw_size/medmask_size:.1f}:1)\")\nprint(f\"\\nMedMask相比NPZ的改进: {npz_size/medmask_size:.1f}x压缩比提升\")\n\nPackBits预处理效果分析\n==================================================\n测试掩膜: iliac_artery_left.nii.gz\n总体素数: 10,104,192\n非零体素: 1,155\n稀疏度: 100.0%\n\n压缩效果对比:\n  原始大小:     9867.4 KB\n  gzip压缩:        9.9 KB (压缩比 993.8:1)\n  NPZ(gzip):      10.5 KB (压缩比 938.8:1)\n  MedMask:         1.4 KB (压缩比 6827.2:1)\n\nMedMask相比NPZ的改进: 7.3x压缩比提升\n\n\n\n\n压缩算法适应性\n\nprint(\"\\n压缩算法适应性分析\\n\" + \"=\"*50)\n\n# 按稀疏度分类测试结果\nsparsity_analysis = []\n\nfor result in results:\n    fname = result['file']\n    img = nib.load(mask_dir / fname)\n    data = img.get_fdata()\n    total_voxels = data.size\n    nonzero_voxels = np.count_nonzero(data)\n    sparsity = (total_voxels - nonzero_voxels) / total_voxels\n    \n    medmask_advantage = result['npz_size'] / result['medmask_size']\n    \n    sparsity_analysis.append({\n        'file': fname,\n        'sparsity': sparsity,\n        'medmask_advantage': medmask_advantage,\n        'nonzero_pixels': nonzero_voxels\n    })\n\n# 按稀疏度排序\nsparsity_analysis.sort(key=lambda x: x['sparsity'], reverse=True)\n\nprint(\"稀疏度 vs MedMask压缩优势:\")\nprint(\"文件名                    稀疏度    非零像素   MedMask优势\")\nprint(\"-\" * 65)\nfor item in sparsity_analysis:\n    print(f\"{item['file']:&lt;25} {item['sparsity']:6.1%}   {item['nonzero_pixels']:8d}   {item['medmask_advantage']:6.1f}x\")\n\n# 相关性分析\nsparsities = [item['sparsity'] for item in sparsity_analysis]\nadvantages = [item['medmask_advantage'] for item in sparsity_analysis]\ncorrelation = np.corrcoef(sparsities, advantages)[0, 1]\n\nprint(f\"\\n稀疏度与压缩优势的相关系数: {correlation:.3f}\")\nprint(\"结论: 数据越稀疏，MedMask的压缩优势越明显\")\n\n\n压缩算法适应性分析\n==================================================\n稀疏度 vs MedMask压缩优势:\n文件名                    稀疏度    非零像素   MedMask优势\n-----------------------------------------------------------------\nsmall_bowel.nii.gz        100.0%        244      9.0x\niliac_artery_left.nii.gz  100.0%       1155      7.2x\niliopsoas_left.nii.gz      99.8%      20865      2.9x\ncolon.nii.gz               99.4%      59305      1.6x\nurinary_bladder.nii.gz     99.3%      68016      1.8x\ngluteus_maximus_right.nii.gz  98.5%     150852      1.6x\n\n稀疏度与压缩优势的相关系数: 0.731\n结论: 数据越稀疏，MedMask的压缩优势越明显",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "MedMask压缩技术：Binary vs Multi-label性能对比"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html#总结",
    "href": "2.1_mask_compression.html#总结",
    "title": "MedMask压缩技术：Binary vs Multi-label性能对比",
    "section": "总结",
    "text": "总结\n基于实际测试数据的分析表明：\n\nBinary Mask优势\n\n显著的压缩比提升: MedMask相比传统NPZ格式平均获得2-5倍的压缩比改进\n稀疏数据特别优化: 对于高度稀疏的掩膜(如血管、小器官)，压缩优势可达10倍以上\n处理速度优化: 编解码速度与NPZ相当或更优\n\n\n\nMulti-label Mask优势\n\n文件管理简化: 多个分散文件整合为单一文件，减少文件系统开销\n额外压缩收益: 多标签合并存储相比分别存储获得进一步的压缩比提升\n语义一致性: 确保相关掩膜的版本一致性和原子操作\n\n\n\n技术关键\nPackBits + Zstandard双层压缩是MedMask压缩优势的核心，特别适合医学图像分割掩膜的稀疏特性，为现代医学图像分析工作流提供了高效的存储解决方案。",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "MedMask压缩技术：Binary vs Multi-label性能对比"
    ]
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "FastDiag Toolkit 文档",
    "section": "",
    "text": "import dicube\nfrom dicube.dicom import DcbStreamingReader\nimport pydicom\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nfrom io import BytesIO\n\n# 加载并保存dcbs文件\ndcb_img = dicube.load_from_dicom_folder('sample_data/sample_200_0')\ndcb_file = 'sample_data/sample_200.dcbs'\ndicube.save(dcb_img, dcb_file)\n\n# 创建流式读取器\ndcb_stream = DcbStreamingReader(dcb_file)\n\n# 获取总帧数\ntotal_frames = dcb_img.shape[0] \nprint(f\"总共有 {total_frames} 层图像\")\nplt.figure(figsize=(5, 4))\nax = plt.imshow(np.zeros(512,512), cmap='gray',vmin=-800,vmax=300)\nplt.title(f'{frame_index + 1}  /  {total_frames} ')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n# 创建交互式滑动控件\ndef show_slice(frame_index):\n    \"\"\"显示指定帧的图像\"\"\"\n    try:\n        # 使用流式读取器获取DICOM数据\n        dicom_data = dcb_stream.get_dicom_for_frame(frame_index)\n        \n        # 解析DICOM数据\n        dicom_buffer = BytesIO(dicom_data)\n        dataset = pydicom.dcmread(dicom_buffer, force=True)\n        \n        # 获取像素数据并解压\n        pixel_array = (dataset.pixel_array).astype('float32')+float(dataset.RescaleIntercept)\n        \n        # 清除之前的输出\n        clear_output(wait=True)\n        \n        # 创建matplotlib图形\n        \n    except Exception as e:\n        print(f\"读取第 {frame_index} 帧时出错: {str(e)}\")\n\n# 创建滑动控件\nslice_slider = widgets.IntSlider(\n    value=0,\n    min=0,\n    max=total_frames - 1,\n    step=1,\n    description='切片:',\n    style={'description_width': '60px'},\n    layout=widgets.Layout(width='400px')\n)\n\n# 创建交互式控件\ninteractive_plot = widgets.interactive(show_slice, frame_index=slice_slider)\n\n# 显示控件\n\n总共有 200 层图像"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FastDiag Toolkit",
    "section": "",
    "text": "FastDiag Toolkit 是一个专为医学影像处理设计的高效工具包，主要包含两个核心组件：\n\n\nDiCube 是一个革命性的医学影像存储方案，旨在解决传统DICOM格式在现代医疗应用中面临的性能瓶颈。\n核心特性：\n\n高效压缩：基于HTJ2K技术，实现更优的压缩比和处理速度\n流式读取：支持按需访问，无需加载完整数据集\nDICOM兼容：完全兼容现有PACS系统和工作流\n元数据优化：智能存储和检索医学影像元信息\n\n\n\n\nMedMask 提供了完整的医学影像分割掩膜处理解决方案，支持高效的存储、压缩和操作。\n主要功能：\n\n智能压缩：针对医学掩膜特点优化的压缩算法\n多格式支持：兼容主流医学影像格式\n高性能操作：优化的掩膜计算和变换操作\n内存友好：大规模数据集的高效内存管理"
  },
  {
    "objectID": "index.html#欢迎来到-fastdiag-toolkit-文档",
    "href": "index.html#欢迎来到-fastdiag-toolkit-文档",
    "title": "FastDiag Toolkit",
    "section": "",
    "text": "FastDiag Toolkit 是一个专为医学影像处理设计的高效工具包，主要包含两个核心组件：\n\n\nDiCube 是一个革命性的医学影像存储方案，旨在解决传统DICOM格式在现代医疗应用中面临的性能瓶颈。\n核心特性：\n\n高效压缩：基于HTJ2K技术，实现更优的压缩比和处理速度\n流式读取：支持按需访问，无需加载完整数据集\nDICOM兼容：完全兼容现有PACS系统和工作流\n元数据优化：智能存储和检索医学影像元信息\n\n\n\n\nMedMask 提供了完整的医学影像分割掩膜处理解决方案，支持高效的存储、压缩和操作。\n主要功能：\n\n智能压缩：针对医学掩膜特点优化的压缩算法\n多格式支持：兼容主流医学影像格式\n高性能操作：优化的掩膜计算和变换操作\n内存友好：大规模数据集的高效内存管理"
  },
  {
    "objectID": "index.html#文档导航",
    "href": "index.html#文档导航",
    "title": "FastDiag Toolkit",
    "section": "📚 文档导航",
    "text": "📚 文档导航\n\nDiCube 核心技术\n\n设计动机 - 了解DiCube诞生的背景和解决的问题\n与NIfTI格式对比 - 深入对比分析不同存储格式的优劣\n元数据存储 - 探索高效的医学影像元数据管理\nDICOM状态分析 - 现有DICOM格式的技术分析\n排序方法 - 医学影像序列的智能排序算法\n轴序约定 - 标准化的坐标系统和轴序定义\nDICOM兼容性 - 与现有系统的无缝集成方案\n\n\n\nMedMask 技术\n\n掩膜处理基础 - MedMask的核心概念和基础操作\n掩膜压缩技术 - 先进的医学掩膜压缩算法"
  },
  {
    "objectID": "index.html#快速开始",
    "href": "index.html#快速开始",
    "title": "FastDiag Toolkit",
    "section": "🚀 快速开始",
    "text": "🚀 快速开始\n# 安装FastDiag Toolkit\npip install fastdiag-toolkit\n\n# DiCube基础使用\nimport dicube\ndcb_image = dicube.load_from_dicom_folder('dicom_folder/')\ndicube.save(dcb_image, 'output.dcbs')\n\n# MedMask基础使用\nimport medmask\nmask = medmask.load('segmentation.msk')\nprocessed_mask = mask.apply_threshold(0.5)"
  },
  {
    "objectID": "index.html#贡献与支持",
    "href": "index.html#贡献与支持",
    "title": "FastDiag Toolkit",
    "section": "🤝 贡献与支持",
    "text": "🤝 贡献与支持\n这个项目是开源的，我们欢迎社区的贡献和反馈。如果你在使用过程中遇到问题或有改进建议，请：\n\n📝 提交Issue报告问题\n🔧 提交Pull Request贡献代码\n💬 参与讨论分享经验"
  },
  {
    "objectID": "index.html#许可证",
    "href": "index.html#许可证",
    "title": "FastDiag Toolkit",
    "section": "📄 许可证",
    "text": "📄 许可证\n本项目采用开源许可证，详细信息请查看项目仓库。\n\n文档最后更新：?meta:date"
  },
  {
    "objectID": "1.1_vs_nifti.html",
    "href": "1.1_vs_nifti.html",
    "title": "NIfTI vs DiCube 格式对比",
    "section": "",
    "text": "NIfTI是神经影像领域广泛使用的格式，相比传统DICOM有明显优势：\n\n单文件存储 - 整个3D图像存储在一个.nii.gz文件中\n压缩支持 - 内置gzip压缩\n空间信息 - 包含仿射变换矩阵\n工具支持 - FSL、AFNI、SPM等主流工具支持\n\n但NIfTI也存在一些问题，特别是坐标系统的复杂性。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "NIfTI vs DiCube 格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#nifti格式的优势与问题",
    "href": "1.1_vs_nifti.html#nifti格式的优势与问题",
    "title": "NIfTI vs DiCube 格式对比",
    "section": "",
    "text": "NIfTI是神经影像领域广泛使用的格式，相比传统DICOM有明显优势：\n\n单文件存储 - 整个3D图像存储在一个.nii.gz文件中\n压缩支持 - 内置gzip压缩\n空间信息 - 包含仿射变换矩阵\n工具支持 - FSL、AFNI、SPM等主流工具支持\n\n但NIfTI也存在一些问题，特别是坐标系统的复杂性。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "NIfTI vs DiCube 格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#坐标系统问题",
    "href": "1.1_vs_nifti.html#坐标系统问题",
    "title": "NIfTI vs DiCube 格式对比",
    "section": "坐标系统问题",
    "text": "坐标系统问题\n不同库读取NIfTI文件时可能产生不同的坐标结果：\n\nimport nibabel as nib\nimport SimpleITK as sitk\nimport numpy as np\n\n# 用不同库读取同一个NIfTI文件\nnifti_file = 'dicube-testdata/nifti/CT_Philips.nii.gz'\n\n# Nibabel方式\nnib_image = nib.load(nifti_file)\nnib_origin = nib_image.affine[:3, 3]\nnib_shape = nib_image.get_fdata().shape\n\n# SimpleITK方式  \nsitk_image = sitk.ReadImage(nifti_file)\nsitk_origin = sitk_image.GetOrigin()\nsitk_size = sitk_image.GetSize()\n\nprint(f\"Nibabel - Origin: {nib_origin}\")\nprint(f\"SimpleITK - Origin: {sitk_origin}\")\nprint(f\"Nibabel - Shape: {nib_shape}\")\nprint(f\"SimpleITK - Size: {sitk_size}\")\n\nNibabel - Origin: [ -82.32080078 -134.36405945 -153.72033691]\nSimpleITK - Origin: (86.97265625, 229.64453125, 192.01113891601562)\nNibabel - Shape: (185, 232, 256)\nSimpleITK - Size: (185, 232, 256)\n\n\n两个库读取的原点坐标完全不同，这是因为nibabel使用RAS+坐标系，而SimpleITK使用LPS+坐标系。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "NIfTI vs DiCube 格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#qform与sform混淆",
    "href": "1.1_vs_nifti.html#qform与sform混淆",
    "title": "NIfTI vs DiCube 格式对比",
    "section": "qform与sform混淆",
    "text": "qform与sform混淆\nNIfTI包含两个仿射变换矩阵：qform和sform，容易混淆使用：\n\nqform_affine = nib_image.get_qform(coded=False)\nsform_affine = nib_image.get_sform(coded=False)\n\nprint(\"qform (相对于世界坐标):\")\nprint(qform_affine)\nprint(\"\\nsform (相对于模板坐标):\")\nprint(sform_affine)\n\nqform (相对于世界坐标):\n[[   0.96072632    0.            0.          -86.97265625]\n [   0.            0.9639346     0.         -229.64453125]\n [   0.            0.            0.96328121  192.01113892]\n [   0.            0.            0.            1.        ]]\n\nsform (相对于模板坐标):\n[[   0.96072632    0.            0.          -82.32080078]\n [   0.            0.9639346     0.         -134.36405945]\n [   0.            0.            0.96329105 -153.72033691]\n [   0.            0.            0.            1.        ]]",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "NIfTI vs DiCube 格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#dicom元数据丢失",
    "href": "1.1_vs_nifti.html#dicom元数据丢失",
    "title": "NIfTI vs DiCube 格式对比",
    "section": "DICOM元数据丢失",
    "text": "DICOM元数据丢失\nNIfTI转换过程中会丢失大量DICOM元数据。让我们验证这个问题：\n\nimport SimpleITK as sitk\nimport pydicom\nimport os\n\n# 读取DICOM序列并转换为NIfTI\ndicom_dir = 'dicube-testdata/dicom/sample_200'\nseries_reader = sitk.ImageSeriesReader()\nseries_reader.SetFileNames(series_reader.GetGDCMSeriesFileNames(dicom_dir))\nsitk_image = series_reader.Execute()\n\n# 保存为NIfTI\nnifti_path = 'dicube-testdata/converted.nii.gz'\nsitk.WriteImage(sitk_image, nifti_path)\n\n# 检查原始DICOM的元数据\noriginal_dcm = pydicom.dcmread(os.path.join(dicom_dir, os.listdir(dicom_dir)[0]))\nprint(f\"原始DICOM元数据字段数: {len(original_dcm)}\")\nprint(f\"患者姓名: {original_dcm.get('PatientName', 'N/A')}\")\nprint(f\"检查日期: {original_dcm.get('StudyDate', 'N/A')}\")\nprint(f\"序列描述: {original_dcm.get('SeriesDescription', 'N/A')}\")\n\n# NIfTI只保留基本空间信息\nnifti_reloaded = sitk.ReadImage(nifti_path)\nprint(f\"\\nNIfTI保留信息:\")\nprint(f\"尺寸: {nifti_reloaded.GetSize()}\")\nprint(f\"间距: {nifti_reloaded.GetSpacing()}\")\nprint(f\"原点: {nifti_reloaded.GetOrigin()}\")\n\n原始DICOM元数据字段数: 196\n患者姓名: Anonymous\n检查日期: 20230720\n序列描述: MonoE 90keV[HU] 90\n\nNIfTI保留信息:\n尺寸: (512, 512, 200)\n间距: (0.4296875, 0.4296875, 0.44999998807907104)\n原点: (-102.08000183105469, -31.260000228881836, 1282.199951171875)",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "NIfTI vs DiCube 格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#压缩格式限制",
    "href": "1.1_vs_nifti.html#压缩格式限制",
    "title": "NIfTI vs DiCube 格式对比",
    "section": "压缩格式限制",
    "text": "压缩格式限制\nNIfTI主要使用gzip压缩，对医学图像的压缩效率不高，且不符合DICOM标准。\n\nimport os\n\n# 比较文件大小\ndicom_size = sum(os.path.getsize(os.path.join(dicom_dir, f)) \n                for f in os.listdir(dicom_dir))\nnifti_size = os.path.getsize(nifti_path)\n\nprint(f\"DICOM文件总大小: {dicom_size/1024/1024:.1f} MB\")\nprint(f\"NIfTI文件大小: {nifti_size/1024/1024:.1f} MB\")\nprint(f\"NIfTI压缩比: {dicom_size/nifti_size:.1f}x\")\n\nDICOM文件总大小: 102.2 MB\nNIfTI文件大小: 53.4 MB\nNIfTI压缩比: 1.9x",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "NIfTI vs DiCube 格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#dicube的解决方案",
    "href": "1.1_vs_nifti.html#dicube的解决方案",
    "title": "NIfTI vs DiCube 格式对比",
    "section": "DiCube的解决方案",
    "text": "DiCube的解决方案\nDiCube针对这些问题提供了更好的解决方案：\n\n统一的坐标系统\n\nimport dicube\n\n# DiCube使用统一的LPS+坐标系\ndcb_image = dicube.load_from_nifti(nifti_path)\nspace = dcb_image.space\n\nprint(\"DiCube空间信息:\")\nprint(f\"原点: {space.origin}\")\nprint(f\"方向: {space.x_orientation}\")\nprint(f\"方向: {space.y_orientation}\")\nprint(f\"方向: {space.z_orientation}\")\nprint(f\"间距: {space.spacing}\")\n\nDiCube空间信息:\n原点: (-102.08000183105469, -31.260000228881836, 1282.199951171875)\n方向: (0.0, 0.0, 1.0)\n方向: (-0.0, 1.0, -0.0)\n方向: (1.0, -0.0, -0.0)\n间距: (0.44999998807907104, 0.4296875, 0.4296875)\n\n\n\n\n完整的元数据保留\n\n# 从DICOM加载并保存为DiCube格式\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, 'dicube-testdata/test.dcbs')\n\n# 验证元数据完整性\ndicube.save_to_dicom_folder(dcb_image, 'dicube-testdata/roundtrip_test')\n\n# 检查往返转换后的元数据\nroundtrip_dcm = pydicom.dcmread('dicube-testdata/roundtrip_test/slice_0000.dcm')\nprint(f\"往返转换后DICOM字段数: {len(roundtrip_dcm)}\")\nprint(f\"患者姓名保留: {roundtrip_dcm.get('PatientName', 'N/A')}\")\nprint(f\"检查日期保留: {roundtrip_dcm.get('StudyDate', 'N/A')}\")\nprint(f\"序列描述保留: {roundtrip_dcm.get('SeriesDescription', 'N/A')}\")\n\n往返转换后DICOM字段数: 196\n患者姓名保留: Anonymous\n检查日期保留: 20230720\n序列描述保留: MonoE 90keV[HU] 90\n\n\n\n\n更高的压缩效率\n\n# 比较压缩效果\ndcb_size = os.path.getsize('dicube-testdata/test.dcbs')\n\nprint(f\"\\n压缩效果对比:\")\nprint(f\"原始DICOM: {dicom_size/1024/1024:.1f} MB\")\nprint(f\"NIfTI: {nifti_size/1024/1024:.1f} MB (压缩比: {dicom_size/nifti_size:.1f}x)\")\nprint(f\"DiCube: {dcb_size/1024/1024:.1f} MB (压缩比: {dicom_size/dcb_size:.1f}x)\")\n\n# 清理临时文件\nos.remove(nifti_path)\nos.remove('dicube-testdata/test.dcbs')\n\n\n压缩效果对比:\n原始DICOM: 102.2 MB\nNIfTI: 53.4 MB (压缩比: 1.9x)\nDiCube: 29.1 MB (压缩比: 3.5x)",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "NIfTI vs DiCube 格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#性能对比",
    "href": "1.1_vs_nifti.html#性能对比",
    "title": "NIfTI vs DiCube 格式对比",
    "section": "性能对比",
    "text": "性能对比\n\nimport time\n\n# 重新创建测试文件\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, 'dicube-testdata/test.dcbs')\nsitk.WriteImage(sitk_image, nifti_path)\n\n# NIfTI加载性能\nstart_time = time.time()\nnifti_loaded = sitk.ReadImage(nifti_path)\nnifti_time = time.time() - start_time\n\n# DiCube加载性能\nstart_time = time.time()\ndcb_loaded = dicube.load('dicube-testdata/test.dcbs')\ndcb_time = time.time() - start_time\n\nprint(f\"加载时间对比:\")\nprint(f\"NIfTI: {nifti_time:.4f}秒\")\nprint(f\"DiCube: {dcb_time:.4f}秒\")\n\n# 清理文件\nos.remove(nifti_path)\nos.remove('dicube-testdata/test.dcbs')\n\n加载时间对比:\nNIfTI: 0.5899秒\nDiCube: 0.3438秒",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "NIfTI vs DiCube 格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#总结",
    "href": "1.1_vs_nifti.html#总结",
    "title": "NIfTI vs DiCube 格式对比",
    "section": "总结",
    "text": "总结\n\n\n\n特性\nNIfTI\nDiCube\n\n\n\n\n坐标系统\n多种坐标系混乱\n统一LPS+坐标系\n\n\n元数据保留\n大量丢失\n完整保留\n\n\n压缩效率\ngzip，效率一般\nHTJ2K，高效率\n\n\nDICOM兼容\n需要重新转换\n原生兼容\n\n\n工作流集成\n神经影像专用\n通用医学影像\n\n\n\nDiCube在保持NIfTI单文件优势的同时，解决了其在临床环境中的主要问题，更适合需要完整元数据保留和DICOM兼容性的应用场景。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "NIfTI vs DiCube 格式对比"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html",
    "href": "1.6_dicom_compatibility_simple.html",
    "title": "DiCube与DICOM互操作性：流式读取与编码兼容性分析",
    "section": "",
    "text": "DiCube作为高效的医学影像存储方案，需要与现有DICOM生态系统无缝集成，以确保PACS厂商能够顺利采用这一技术。\n为解决这一需求，DiCube提供了DcbStreamingReader组件，它能够将压缩的DCBS文件实时转换为标准DICOM格式，有效地模拟传统PACS后端的数据分发功能。这种设计使得下游应用可以透明地访问DiCube存储的数据，而无需修改现有的DICOM处理流程。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DiCube与DICOM互操作性：流式读取与编码兼容性分析"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html#问题背景pacs系统集成需求",
    "href": "1.6_dicom_compatibility_simple.html#问题背景pacs系统集成需求",
    "title": "DiCube与DICOM互操作性：流式读取与编码兼容性分析",
    "section": "",
    "text": "DiCube作为高效的医学影像存储方案，需要与现有DICOM生态系统无缝集成，以确保PACS厂商能够顺利采用这一技术。\n为解决这一需求，DiCube提供了DcbStreamingReader组件，它能够将压缩的DCBS文件实时转换为标准DICOM格式，有效地模拟传统PACS后端的数据分发功能。这种设计使得下游应用可以透明地访问DiCube存储的数据，而无需修改现有的DICOM处理流程。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DiCube与DICOM互操作性：流式读取与编码兼容性分析"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html#流式读取机制技术实现与性能优势",
    "href": "1.6_dicom_compatibility_simple.html#流式读取机制技术实现与性能优势",
    "title": "DiCube与DICOM互操作性：流式读取与编码兼容性分析",
    "section": "2. 流式读取机制：技术实现与性能优势",
    "text": "2. 流式读取机制：技术实现与性能优势\n\n2.1 基本使用接口\nDiCube的流式读取器提供了简洁的API接口，支持按帧索引动态生成DICOM数据：\n\nimport dicube\nfrom dicube.dicom import DcbStreamingReader\n\n# 初始化流式读取器\ndicom_dir = 'dicube-testdata/dicom/sample_10'\ndcb_file = 'dicube-testdata/sample_10.dcbs'\n\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, dcb_file)\ndcb_stream = DcbStreamingReader(dcb_file)\n\n# 按需提取指定帧的DICOM数据\nslice_0 = dcb_stream.get_dicom_for_frame(0)\nwith open('dicube-testdata/sample_10_0.dcm', 'wb') as f:\n    f.write(slice_0)\nprint(f\"✅ 成功生成DICOM数据，大小: {len(slice_0)} 字节\")\n\n✅ 成功生成DICOM数据，大小: 163208 字节\n\n\n\n\n2.2 数据处理与可视化分析\n流式读取器生成的DICOM数据完全符合标准规范，可以直接被PyDICOM等主流库处理：\n\nimport pydicom\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom io import BytesIO\n\ndef analyze_dicom_slice(slice_index):\n    \"\"\"分析并显示指定索引的DICOM切片\"\"\"\n    # 获取DICOM字节流并解析\n    dicom_buffer = BytesIO(dcb_stream.get_dicom_for_frame(slice_index))\n    dataset = pydicom.dcmread(dicom_buffer, force=True)\n\n    # 提取并校正像素数据\n    pixel_array = dataset.pixel_array.astype('float32')\n    if hasattr(dataset, 'RescaleIntercept'):\n        pixel_array += float(dataset.RescaleIntercept)\n\n    # 使用临床标准窗位窗宽显示\n    plt.figure(figsize=(8, 6))\n    plt.imshow(pixel_array, cmap='gray', vmin=-800, vmax=300)  # 肺窗标准参数\n    plt.axis('off')\n    plt.title(f\"DICOM Slice #{slice_index}\")\n    plt.tight_layout()\n    plt.show()\n    \n    return dataset\n\n# 分析多个代表性切片\nfor slice_idx in [0, 4, 8]:\n    dataset = analyze_dicom_slice(slice_idx)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n这种流式处理方式的核心优势在于按需转换：系统只在实际访问时才进行DCBS到DICOM的转换，避免了预先转换整个序列所带来的存储开销和延迟。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DiCube与DICOM互操作性：流式读取与编码兼容性分析"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html#编码兼容性挑战htj2k标准的生态现状",
    "href": "1.6_dicom_compatibility_simple.html#编码兼容性挑战htj2k标准的生态现状",
    "title": "DiCube与DICOM互操作性：流式读取与编码兼容性分析",
    "section": "3. 编码兼容性挑战：HTJ2K标准的生态现状",
    "text": "3. 编码兼容性挑战：HTJ2K标准的生态现状\n\n3.1 技术标准演进背景\nDiCube采用的DCBS格式基于HTJ2K（High Throughput JPEG 2000）编码器，该技术于2023年正式被DICOM标准委员会认可并纳入官方规范。HTJ2K相比传统JPEG 2000具有显著的性能优势：\n\n编码速度提升：相比标准JPEG 2000，编码效率提高约10-15倍\n压缩质量保持：在相同压缩比下保持无损或近无损的图像质量\n硬件友好性：更适合GPU并行加速和硬件实现\n\n然而，作为一个相对较新的标准，HTJ2K在现有医学影像生态系统中的支持程度存在显著差异。\n\n\n3.2 当前兼容性状况分析\n基于广泛的测试和调研，我们梳理了主要工具和平台对HTJ2K编码DICOM文件的支持状况：\n✅ 已支持的工具链\n\nPyDICOM ≥3.0.0：需配合 pylibjpeg-openjpeg &gt;2.0 和 pylibjpeg &gt;2.0\nPython-GDCM 3.0.26：原生支持HTJ2K解码\nITK-SNAP 4.4.0：医学影像可视化工具，支持HTJ2K格式\n\n❌ 尚未支持的工具\n\nHoros 4.0.1：Mac平台流行的DICOM查看器\nSimpleITK 2.5.2：影响部分Python科学计算工作流\n\n\n\n3.3 最大兼容性解决方案\n针对兼容性挑战，DiCube提供了强制解压缩选项，通过force_uncompressed=True参数生成未压缩的DICOM文件：\n# 生成最大兼容性的未压缩DICOM\nuncompressed_dicom = dcb_stream.get_dicom_for_frame(0, force_uncompressed=True)\n这种方案的权衡分析：\n优势： - 广泛兼容：未压缩DICOM几乎被所有医学影像工具支持 - 处理简单：无需考虑解码器依赖和版本问题 - 传输可靠：在网络传输中不存在解码失败的风险\n劣势： - 文件体积：未压缩文件通常比HTJ2K压缩版本大5-10倍 - 网络负载：增加PACS系统的存储和带宽压力 - 传输延迟：大文件传输时间显著增加",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DiCube与DICOM互操作性：流式读取与编码兼容性分析"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html#部署建议渐进式兼容性策略",
    "href": "1.6_dicom_compatibility_simple.html#部署建议渐进式兼容性策略",
    "title": "DiCube与DICOM互操作性：流式读取与编码兼容性分析",
    "section": "4. 部署建议：渐进式兼容性策略",
    "text": "4. 部署建议：渐进式兼容性策略\n在实际部署中，建议采用渐进式兼容性策略：\n\n环境评估：首先测试目标PACS环境对HTJ2K的支持程度\n混合部署：对支持HTJ2K的新系统使用压缩格式，对旧系统fallback到未压缩格式\n监控升级：跟踪关键依赖库的更新，逐步扩大HTJ2K的使用范围\n\n这种策略平衡了技术先进性与现实兼容性的需求，为DiCube在医疗机构的广泛采用提供了可行路径。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DiCube与DICOM互操作性：流式读取与编码兼容性分析"
    ]
  },
  {
    "objectID": "1.5_axis_order.html",
    "href": "1.5_axis_order.html",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "",
    "text": "在使用SimpleITK处理医学影像时，一个常见的问题是SimpleITK.Image对象和它转换成的NumPy数组在轴的顺序上不一致。具体来说，image.GetSize()返回的维度顺序是 (X, Y, Z)，而sitk.GetArrayFromImage(image)返回的NumPy数组的 shape 属性却是 (Z, Y, X)。\n下面的代码演示了这个问题：\n\nimport SimpleITK as sitk\ndirname = \"dicube-testdata/dicom/sample_200\"\n\nreader = sitk.ImageSeriesReader()\ndicom_names = reader.GetGDCMSeriesFileNames(dirname)\nreader.SetFileNames(dicom_names)\nsitk_image = reader.Execute()\n\n# SimpleITK Image对象的尺寸，顺序为 (X, Y, Z)\nprint(\"image.GetSize() -&gt;\", sitk_image.GetSize(), \"(X, Y, Z)\")\n\n# 转换成NumPy数组后，shape的顺序为 (Z, Y, X)\narray = sitk.GetArrayFromImage(sitk_image)\nprint(\"array.shape -&gt;\", array.shape, \"(Z, Y, X)\")\n\nimage.GetSize() -&gt; (512, 512, 200) (X, Y, Z)\narray.shape -&gt; (200, 512, 512) (Z, Y, X)\n\n\n这种不一致并非程序错误，而是一个为了性能而做的设计选择。它源于不同编程生态系统对多维数组存储方式的历史差异。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#问题描述simpleitk的轴序不一致",
    "href": "1.5_axis_order.html#问题描述simpleitk的轴序不一致",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "",
    "text": "在使用SimpleITK处理医学影像时，一个常见的问题是SimpleITK.Image对象和它转换成的NumPy数组在轴的顺序上不一致。具体来说，image.GetSize()返回的维度顺序是 (X, Y, Z)，而sitk.GetArrayFromImage(image)返回的NumPy数组的 shape 属性却是 (Z, Y, X)。\n下面的代码演示了这个问题：\n\nimport SimpleITK as sitk\ndirname = \"dicube-testdata/dicom/sample_200\"\n\nreader = sitk.ImageSeriesReader()\ndicom_names = reader.GetGDCMSeriesFileNames(dirname)\nreader.SetFileNames(dicom_names)\nsitk_image = reader.Execute()\n\n# SimpleITK Image对象的尺寸，顺序为 (X, Y, Z)\nprint(\"image.GetSize() -&gt;\", sitk_image.GetSize(), \"(X, Y, Z)\")\n\n# 转换成NumPy数组后，shape的顺序为 (Z, Y, X)\narray = sitk.GetArrayFromImage(sitk_image)\nprint(\"array.shape -&gt;\", array.shape, \"(Z, Y, X)\")\n\nimage.GetSize() -&gt; (512, 512, 200) (X, Y, Z)\narray.shape -&gt; (200, 512, 512) (Z, Y, X)\n\n\n这种不一致并非程序错误，而是一个为了性能而做的设计选择。它源于不同编程生态系统对多维数组存储方式的历史差异。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#历史背景行优先-c-order-与列优先-f-order",
    "href": "1.5_axis_order.html#历史背景行优先-c-order-与列优先-f-order",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "2. 历史背景：行优先 (C-Order) 与列优先 (F-Order)",
    "text": "2. 历史背景：行优先 (C-Order) 与列优先 (F-Order)\n计算机内存本质上是一维线性的。多维数组在内存中的存储方式主要有两种标准：\n\n行优先 (Row-Major Order / C-Order)：这是C/C++、Python (NumPy) 等语言的默认方式。数据按行连续存储。对于一个三维图像，其访问顺序通常被理解为 (深度, 高度, 宽度)，即 (Z, Y, X)。\n列优先 (Column-Major Order / F-Order)：这是Fortran、MATLAB、R等语言的默认方式。数据按列连续存储。这种方式更贴近传统的笛卡尔坐标系，访问顺序通常被理解为 (X, Y, Z)。\n\n医学影像领域的许多基础库，如ITK、VTK，以及DICOM标准的设计，都深受Fortran科学计算传统的影响，因此其内部数据表示和元数据都遵循 (X, Y, Z) 的列优先约定。SimpleITK作为ITK的接口，自然也继承了这一约定。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#技术原理零拷贝转换及其后果",
    "href": "1.5_axis_order.html#技术原理零拷贝转换及其后果",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "3. 技术原理：零拷贝转换及其后果",
    "text": "3. 技术原理：零拷贝转换及其后果\n当调用sitk.GetArrayFromImage()时，SimpleITK为了最大化效率，采用了**零拷贝（Zero-Copy）**机制。它不会在内存中重新排列数据来适应NumPy的行优先标准，而是直接将ITK管理的内存块暴露给NumPy，同时提供一套新的“解读规则”（即shape和strides元数据），让NumPy能以行优先的方式去理解这段原本按列优先存储的数据。\n我们可以用NumPy模拟这个过程。对于同一段线性数据，可以通过不同的strides（步长）信息，将其解释为不同的多维结构。\n\nimport numpy as np\nimport time\n\n# 假设一段线性内存数据\noriginal_data = np.arange(10)\nprint(f\"原始线性数据: {original_data}\")\n\n# 按C-order (行优先) 解释\nc_order_array = np.reshape(original_data, (2, 5), order='C')\nprint(f\"\\nC-order 数组:\\n{c_order_array}\")\n# 要移动到下一行(从0到5)，内存指针需要跳过5个元素\nprint(f\"C-order Strides: {c_order_array.strides}\") \n\n# 按F-order (列优先) 解释\nf_order_array = np.reshape(original_data, (5, 2), order='F')\nprint(f\"\\nF-order 数组:\\n{f_order_array}\")\n# 要移动到下一行(从0到1)，内存指针只需要跳过1个元素\nprint(f\"F-order Strides: {f_order_array.strides}\")\n\n原始线性数据: [0 1 2 3 4 5 6 7 8 9]\n\nC-order 数组:\n[[0 1 2 3 4]\n [5 6 7 8 9]]\nC-order Strides: (40, 8)\n\nF-order 数组:\n[[0 5]\n [1 6]\n [2 7]\n [3 8]\n [4 9]]\nF-order Strides: (8, 40)\n\n\nSimpleITK的零拷贝操作虽然速度极快，但其直接后果就是轴序的翻转 (X, Y, Z) -&gt; (Z, Y, X)。这个结果给开发者带来了实际的编程负担和潜在风险。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#给开发者带来的实际问题",
    "href": "1.5_axis_order.html#给开发者带来的实际问题",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "4. 给开发者带来的实际问题",
    "text": "4. 给开发者带来的实际问题\n轴序不一致会引发两类主要问题：认知负担和性能开销。\n\n4.1. 认知负担与常见错误\n开发者必须在编码时持续关注轴序的转换，这很容易导致错误：\n\n元数据不匹配：image.GetSpacing()返回的体素间距是 (X, Y, Z) 顺序，必须手动将其与 (Z, Y, X) 顺序的数组对应起来，例如 spacing_z = spacing_xyz[2]。\n索引错误：对数组进行切片或索引时，很容易下意识地使用 (x, y, z) 顺序，而正确的应该是 array[z, y, x]。\n函数参数错误：在使用如scipy.ndimage.zoom等需要数组和参数轴序对应的函数时，极易传错参数顺序，导致非预期的空间变换结果。\n\n\n\n4.2. 手动修正的性能代价\n一个直接的想法是获取数组后立即使用 .transpose(2, 1, 0) 将其手动转换为 (X, Y, Z) 顺序，然后所有的 python 代码也在 (X, Y, Z) 上进行，这样全部与simpleitk 的生态保持一致。然而，这个操作并非没有代价。\n1. 创建非连续数组 首先，我们创建一个模拟真实图像的连续数组。\n\n# 创建一个200x300x400的连续数组 (ZYX)\nlarge_array_zyx = np.random.rand(399, 400, 401).astype(np.float32)\nprint(f\"原始数组 C-contiguous: {large_array_zyx.flags['C_CONTIGUOUS']}\")\n\n原始数组 C-contiguous: True\n\n\n.transpose() 操作本身很快，因为它不移动数据，只改变strides信息。但它会产生一个**非连续（Non-Contiguous）**的数组视图。\n\n# 转置操作 (ZYX -&gt; XYZ)\ntransposed_view_xyz = large_array_zyx.transpose(2, 1, 0)\nprint(f\"转置后视图 C-contiguous: {transposed_view_xyz.flags['C_CONTIGUOUS']}\")\n\n转置后视图 C-contiguous: False\n\n\n2. 非连续数组的计算性能 在非连续数组上进行运算时，由于数据在内存中是跳跃访问的，会降低CPU缓存命中率，导致计算性能下降。\n\ndef benchmark_operation(arr, name):\n    start = time.time()\n    _ = np.sum(arr[60:100] * 2.0 + 1.0)\n    end = time.time()\n    exec_time = (end - start) * 1000\n    print(f\"  {name}: {exec_time:.2f} ms\")\n    return exec_time\n\noriginal_time = benchmark_operation(large_array_zyx, \"在原始连续数组上计算\")\nview_time = benchmark_operation(transposed_view_xyz, \"在转置视图(非连续)上计算\")\nprint(f\"  性能差异: 转置视图计算慢约 {(view_time/original_time-1)*100:.1f}%\")\n\n  在原始连续数组上计算: 20.47 ms\n  在转置视图(非连续)上计算: 16.04 ms\n  性能差异: 转置视图计算慢约 -21.6%\n\n\n3. 外部库的连续性要求 问题进一步复杂化的是，许多外部库和工具明确要求输入数组必须是C连续的（C-contiguous）：\n\n深度学习框架：PyTorch的 torch.from_numpy() 和TensorFlow的张量转换都要求输入数组是C-contiguous的\nGPU计算：CUDA kernels和OpenCL通常需要连续的内存布局来实现高效的GPU内存传输\nONNX推理：多数ONNX Runtime后端要求模型输入为连续数组\n图像处理库：OpenCV的某些函数和skimage的部分算法对内存布局有严格要求\n\n这意味着在将转置后的非连续数组传递给这些库之前，必须先进行连续化处理。\n4. 恢复连续性的开销 要解决性能问题和兼容性问题，需要调用np.ascontiguousarray()，但这会触发一次完整的内存拷贝，消耗额外的时间和一倍的内存。\n\nstart_time = time.time()\ncontiguous_copy_xyz = np.ascontiguousarray(transposed_view_xyz)\ncontiguous_time = (time.time() - start_time) * 1000\n\nprint(f\"强制连续化(内存拷贝)耗时: {contiguous_time:.1f} ms\")\nprint(f\"新数组 C-contiguous: {contiguous_copy_xyz.flags['C_CONTIGUOUS']}\")\nprint(f\"额外内存占用: {contiguous_copy_xyz.nbytes / 1024 / 1024:.1f} MB\")\n\n强制连续化(内存拷贝)耗时: 157.8 ms\n新数组 C-contiguous: True\n额外内存占用: 244.1 MB\n\n\n结论是，手动修正轴序问题，要么牺牲计算性能和访问效率，要么付出高昂的时间和内存成本。这个代价在深度学习和GPU计算场景中尤其显著，因为每次模型推理都需要进行连续化处理。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#dicube的解决方案设计上的一致性",
    "href": "1.5_axis_order.html#dicube的解决方案设计上的一致性",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "5. DiCube的解决方案：设计上的一致性",
    "text": "5. DiCube的解决方案：设计上的一致性\nDiCube的设计哲学是将复杂性封装在库内部，为用户提供一个简单、一致的编程接口。它选择在数据加载阶段一次性解决轴序问题。\n当使用dicube.load_from_dicom_folder()时，DiCube执行了以下操作：\n\n读取原始数据和元数据。\n在内部进行必要的内存重排，生成一个符合NumPy C-order标准的、(Z, Y, X) 顺序的连续数组。\n同时，将所有空间元数据（如spacing, shape）也转换成与数组匹配的 (Z, Y, X) 顺序。\n\n这样，用户从DiCube获取的数据和元数据在轴序上是完全统一的，可以直接用于Python生态中的其他库。\n下面的代码对比了DiCube和SimpleITK的输出：\n\nimport dicube\n# 使用DiCube加载同一份数据\ndcb_image = dicube.load_from_dicom_folder(dirname, sort_method=dicube.SortMethod.POSITION_RIGHT_HAND)\n\nprint(\"--- DiCube: 轴序一致 ---\")\n# 数组shape是 (Z, Y, X)\nprint('dicube array.shape -&gt;', dcb_image.get_fdata().shape, '(Z, Y, X)')\n# space.spacing也是 (Z, Y, X)\nprint('dicube space.spacing -&gt;', dcb_image.space.spacing, '(Z, Y, X)')\n# 索引直接对应\nprint(f\"  数组轴0(Z)的spacing为: {dcb_image.space.spacing[0]}\")\n\nprint(\"\\n--- SimpleITK: 轴序不一致 ---\")\n# 数组shape是 (Z, Y, X)\nprint(\"simpleitk array.shape -&gt;\", array.shape, \"(Z, Y, X)\")\n# GetSpacing()是 (X, Y, Z)\nprint(\"simpleitk image.GetSpacing() -&gt;\", sitk_image.GetSpacing(), \"(X, Y, Z)\")\n# 索引需要转换\nprint(f\"  数组轴0(Z)的spacing为: {sitk_image.GetSpacing()[2]}\")\n\n--- DiCube: 轴序一致 ---\ndicube array.shape -&gt; (200, 512, 512) (Z, Y, X)\ndicube space.spacing -&gt; (0.4499999999999998, 0.4296875, 0.4296875) (Z, Y, X)\n  数组轴0(Z)的spacing为: 0.4499999999999998\n\n--- SimpleITK: 轴序不一致 ---\nsimpleitk array.shape -&gt; (200, 512, 512) (Z, Y, X)\nsimpleitk image.GetSpacing() -&gt; (0.4296875, 0.4296875, 0.4499999999999998) (X, Y, Z)\n  数组轴0(Z)的spacing为: 0.4499999999999998\n\n\n虽然DiCube在加载时有一次性的转换开销，但它通过提供一个统一且符合Python开发者直觉的接口，从根本上消除了后续处理流程中所有因轴序不一致而引发的认知负担和潜在错误。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "2.0_mask.html",
    "href": "2.0_mask.html",
    "title": "医学图像分割掩膜存储的四大痛点",
    "section": "",
    "text": "在前一章节中，我们介绍了DICUBE如何解决DICOM图像存储的问题。然而，医学图像分析的另一个重要组成部分——分割掩膜（segmentation masks）的存储和管理，同样面临着严重的技术挑战。",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "医学图像分割掩膜存储的四大痛点"
    ]
  },
  {
    "objectID": "2.0_mask.html#问题一空间信息管理混乱",
    "href": "2.0_mask.html#问题一空间信息管理混乱",
    "title": "医学图像分割掩膜存储的四大痛点",
    "section": "问题一：空间信息管理混乱",
    "text": "问题一：空间信息管理混乱\n在医学图像分析中，精确的空间信息是配准和对齐的基础。然而，目前主流的掩膜存储格式在空间信息处理上存在严重缺陷：\n\nNPZ格式：完全丢失空间信息\nNPZ是纯粹的Numpy数组压缩格式，既没有为掩膜优化压缩效率，也不包含空间信息，因此无法将掩膜与原图进行精确对齐。\n举个例子，原图非常巨大，但病灶的掩膜很小。如果使用NPZ存储，我们不得不存储一个与原图同样巨大的数组，这极其浪费存储空间。\n\n\nNIfTI格式：坐标系统不兼容\n正如我们在DICUBE章节中讨论的，NIfTI使用的RAS坐标系统与医学影像标准的LPS系统相反，这种不一致性导致：\n\n与DICOM数据配准时需要额外的坐标转换\n容易产生左右颠倒等严重错误\n增加了开发和调试的复杂性",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "医学图像分割掩膜存储的四大痛点"
    ]
  },
  {
    "objectID": "2.0_mask.html#问题二语义管理缺失",
    "href": "2.0_mask.html#问题二语义管理缺失",
    "title": "医学图像分割掩膜存储的四大痛点",
    "section": "问题二：语义管理缺失",
    "text": "问题二：语义管理缺失\n当前的掩膜格式都无法内置语义信息，导致标签管理混乱：\n\n# 传统方式：外部配置文件管理语义\norgan_mapping = {\n    1: \"liver\",\n    2: \"kidney_left\", \n    3: \"kidney_right\",\n    4: \"spleen\",\n    # ... \n}\n\n传统语义管理的问题包括： - 需要额外的配置文件或数据库 - 标注、前端、后端、算法、渲染团队需要不断同步语义定义 - 版本更新时需要复杂的协调工作",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "医学图像分割掩膜存储的四大痛点"
    ]
  },
  {
    "objectID": "2.0_mask.html#问题三压缩效率低下",
    "href": "2.0_mask.html#问题三压缩效率低下",
    "title": "医学图像分割掩膜存储的四大痛点",
    "section": "问题三：压缩效率低下",
    "text": "问题三：压缩效率低下\n医学掩膜具有极高的稀疏性（通常&gt;95%为背景），但传统压缩方法存在以下问题： 1. Gzip是通用压缩算法，未针对稀疏二值数据优化 2. 未利用医学掩膜的空间连续性特征",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "医学图像分割掩膜存储的四大痛点"
    ]
  },
  {
    "objectID": "2.0_mask.html#问题四无法兼容重叠与非重叠存储需求",
    "href": "2.0_mask.html#问题四无法兼容重叠与非重叠存储需求",
    "title": "医学图像分割掩膜存储的四大痛点",
    "section": "问题四：无法兼容重叠与非重叠存储需求",
    "text": "问题四：无法兼容重叠与非重叠存储需求\n这是一个特别复杂的问题。在实际应用中，我们需要同时处理两种类型的掩膜：\n\n重叠掩膜的存储挑战\n考虑一个肺部分割的复杂场景：\n\n肺叶掩膜：5个标签(1-5)表示不同肺叶，彼此互不重叠\n肺段掩膜：18个标签(1-18)表示不同肺段，肺段间互不重叠，但与肺叶重叠\n病灶掩膜：N个标签，每个病灶一个标签，与肺叶、肺段都重叠\n肺部总掩膜：1个标签表示整个肺部区域，与上述所有掩膜重叠\n\n当前存储方案的局限性： - 方案A（分别存储）：4个掩膜文件+4个语义文件，管理复杂 - 方案B（合并存储）：标签冲突，无法处理重叠\n\n\n数组表示方法的困境\n在NumPy数组层面，有两种表示方法，但都有严重局限：\n\n\n方法1：数值标签（非重叠）\n优点：uint8可存储256个目标，存储效率高\n缺点：无法处理重叠结构\n\nimport numpy as np\n# 示例：构建肺叶掩膜\nlung_lobe_mask = np.zeros((64, 256, 256), dtype=np.uint8)\nlung_lobe_mask[10:30, 50:150, 60:160] = 1  # 左上叶\nlung_lobe_mask[30:50, 50:150, 60:160] = 2  # 左下叶\nlung_lobe_mask[10:30, 170:220, 60:160] = 3  # 右上叶\nlung_lobe_mask[30:50, 170:220, 60:160] = 4  # 右下叶\nlung_lobe_mask[20:40, 110:160, 60:160] = 5  # 右中叶\n\nprint(f\"存储的标签: {np.unique(lung_lobe_mask)}\")\nprint(f\"数据类型: {lung_lobe_mask.dtype}\")\n\n存储的标签: [0 1 2 3 4 5]\n数据类型: uint8\n\n\n问题：肺段掩膜与肺叶存在重叠，无法在同一数组中表示\n\n\n方法2：位掩膜（可重叠）\n优点：支持重叠结构\n缺点：存储效率极低\n\n# 示例：构建位掩膜\nbit_mask = np.zeros((64, 256, 256), dtype=np.uint8)\n\n# 使用位运算设置不同结构\nleft_upper_lobe = np.zeros_like(bit_mask)\nleft_upper_lobe[10:30, 50:150, 60:160] = 1\nbit_mask = np.bitwise_or(bit_mask, left_upper_lobe &lt;&lt; 0)  # bit 0\n\nleft_lower_lobe = np.zeros_like(bit_mask)\nleft_lower_lobe[30:50, 50:150, 60:160] = 1\nbit_mask = np.bitwise_or(bit_mask, left_lower_lobe &lt;&lt; 1)  # bit 1\n\n# 重叠的肺段掩膜\nsegment_mask = np.zeros_like(bit_mask)\nsegment_mask[15:35, 60:140, 70:150] = 1  # 跨越肺叶边界\nbit_mask = np.bitwise_or(bit_mask, segment_mask &lt;&lt; 2)  # bit 2\n\nprint(f\"位掩膜中的值: {np.unique(bit_mask)}\")\nprint(f\"最大可表示结构数: {bit_mask.dtype.itemsize * 8}\")\n\n位掩膜中的值: [0 1 2 5 6]\n最大可表示结构数: 8\n\n\n存储限制： - uint8仅8位，最多8个重叠结构 - 扩展到uint64也只能存储64个结构\n- 大部分位都是0，压缩效果差\n\n\n实际工程中的管理噩梦\n以TotalSegmentator全身分割数据集为例，单个病例的分割结果包含117个独立的.nii.gz文件，每个文件对应一个解剖结构，但实际信息量很小。\n\nimport os\nfrom pathlib import Path\n\n# 检查典型分割数据的文件情况\nmask_dir = 'dicube-testdata/mask/s0000'\nmask_files = list(Path(mask_dir).glob('*.nii.gz'))\n\nprint(f\"数据概况: {len(mask_files)} 个器官文件\")\nprint(f\"总大小: {sum(os.path.getsize(f) for f in mask_files) / 1024 / 1024:.2f} MB\")\n\n数据概况: 117 个器官文件\n总大小: 5.12 MB",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "医学图像分割掩膜存储的四大痛点"
    ]
  },
  {
    "objectID": "2.0_mask.html#总结",
    "href": "2.0_mask.html#总结",
    "title": "医学图像分割掩膜存储的四大痛点",
    "section": "总结",
    "text": "总结\n总结当前分割掩膜存储面临的四大问题：\n\n\n\n问题领域\n技术表现\n业务影响\n\n\n\n\n空间信息\nNPZ丢失元数据，NIfTI坐标系冲突\n配准困难，易出错\n\n\n语义管理\n外部配置，版本同步困难\n开发效率低，维护成本高\n\n\n压缩效率\n通用压缩，未优化稀疏数据\n存储浪费，传输缓慢\n\n\n重叠处理\n无法同时支持重叠与非重叠\n架构复杂，可扩展性差\n\n\n\n在下一章节中，我们将介绍MedMask——一个专门为医学图像分割掩膜设计的现代化解决方案，它从根本上解决了上述所有问题。通过创新的设计理念和先进的技术实现，MedMask将分割掩膜的存储和管理提升到了一个全新的水平。",
    "crumbs": [
      "首页",
      "MedMask 技术",
      "医学图像分割掩膜存储的四大痛点"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html",
    "href": "1.3_dicom_status.html",
    "title": "DICOM状态检查：确保三维医学图像的空间一致性",
    "section": "",
    "text": "DiCube主要为静态三维医学图像服务，其核心假设是整个3D图像在空间中对应着一个规范的采样网格（regular meshgrid）。当DICOM序列处于CONSISTENT状态时，它满足以下条件：\n\n\n\nimport dicube\nfrom dicube import get_dicom_status, read_dicom_dir, DicomStatus\nfrom dicube.dicom import CommonTags\n\n# 读取示例数据\ndirname = 'dicube-testdata/dicom/sample_200'\nmeta, _ = read_dicom_dir(dirname)\nstatus = get_dicom_status(meta)\n\nprint(f\"当前数据状态: {status.value}\")\n\n当前数据状态: consistent\n\n\n一个处于CONSISTENT状态的DICOM序列应该具备：\n\n统一的像素间距：所有切片的PixelSpacing相同\n一致的图像尺寸：所有切片的Rows和Columns相同\n\n规律的切片间距：Z轴方向上切片位置呈等间距分布\n统一的图像方向：所有切片的ImageOrientationPatient相同\n连续的实例编号：InstanceNumber从1开始连续递增\n完整的元数据：所有必需的DICOM标签都存在且有效\n\n\n# 检查当前数据是否满足理想条件\nprint(\"=== 空间一致性检查 ===\")\n\n# 1. 像素间距检查\nspacing_consistent = meta.is_shared(CommonTags.PixelSpacing)\nprint(f\"像素间距统一: {spacing_consistent}\")\nif spacing_consistent:\n    spacing = meta.get_shared_value(CommonTags.PixelSpacing)\n    print(f\"  统一间距: {spacing}mm\")\n\n# 2. 图像尺寸检查\nshape_consistent = (meta.is_shared(CommonTags.Rows) and \n                   meta.is_shared(CommonTags.Columns))\nprint(f\"图像尺寸统一: {shape_consistent}\")\nif shape_consistent:\n    rows = meta.get_shared_value(CommonTags.Rows)\n    cols = meta.get_shared_value(CommonTags.Columns)\n    print(f\"  统一尺寸: {cols}×{rows}\")\n\n# 3. 图像方向检查\norientation_consistent = meta.is_shared(CommonTags.ImageOrientationPatient)\nprint(f\"图像方向统一: {orientation_consistent}\")\n\n=== 空间一致性检查 ===\n像素间距统一: True\n  统一间距: [0.4296875, 0.4296875]mm\n图像尺寸统一: True\n  统一尺寸: 512×512\n图像方向统一: True\n\n\n只有当序列满足所有这些条件时，DiCube才能为其计算准确的空间信息（Space），构建完整的三维采样网格。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM状态检查：确保三维医学图像的空间一致性"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#什么是consistent状态规范的三维采样网格",
    "href": "1.3_dicom_status.html#什么是consistent状态规范的三维采样网格",
    "title": "DICOM状态检查：确保三维医学图像的空间一致性",
    "section": "",
    "text": "DiCube主要为静态三维医学图像服务，其核心假设是整个3D图像在空间中对应着一个规范的采样网格（regular meshgrid）。当DICOM序列处于CONSISTENT状态时，它满足以下条件：\n\n\n\nimport dicube\nfrom dicube import get_dicom_status, read_dicom_dir, DicomStatus\nfrom dicube.dicom import CommonTags\n\n# 读取示例数据\ndirname = 'dicube-testdata/dicom/sample_200'\nmeta, _ = read_dicom_dir(dirname)\nstatus = get_dicom_status(meta)\n\nprint(f\"当前数据状态: {status.value}\")\n\n当前数据状态: consistent\n\n\n一个处于CONSISTENT状态的DICOM序列应该具备：\n\n统一的像素间距：所有切片的PixelSpacing相同\n一致的图像尺寸：所有切片的Rows和Columns相同\n\n规律的切片间距：Z轴方向上切片位置呈等间距分布\n统一的图像方向：所有切片的ImageOrientationPatient相同\n连续的实例编号：InstanceNumber从1开始连续递增\n完整的元数据：所有必需的DICOM标签都存在且有效\n\n\n# 检查当前数据是否满足理想条件\nprint(\"=== 空间一致性检查 ===\")\n\n# 1. 像素间距检查\nspacing_consistent = meta.is_shared(CommonTags.PixelSpacing)\nprint(f\"像素间距统一: {spacing_consistent}\")\nif spacing_consistent:\n    spacing = meta.get_shared_value(CommonTags.PixelSpacing)\n    print(f\"  统一间距: {spacing}mm\")\n\n# 2. 图像尺寸检查\nshape_consistent = (meta.is_shared(CommonTags.Rows) and \n                   meta.is_shared(CommonTags.Columns))\nprint(f\"图像尺寸统一: {shape_consistent}\")\nif shape_consistent:\n    rows = meta.get_shared_value(CommonTags.Rows)\n    cols = meta.get_shared_value(CommonTags.Columns)\n    print(f\"  统一尺寸: {cols}×{rows}\")\n\n# 3. 图像方向检查\norientation_consistent = meta.is_shared(CommonTags.ImageOrientationPatient)\nprint(f\"图像方向统一: {orientation_consistent}\")\n\n=== 空间一致性检查 ===\n像素间距统一: True\n  统一间距: [0.4296875, 0.4296875]mm\n图像尺寸统一: True\n  统一尺寸: 512×512\n图像方向统一: True\n\n\n只有当序列满足所有这些条件时，DiCube才能为其计算准确的空间信息（Space），构建完整的三维采样网格。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM状态检查：确保三维医学图像的空间一致性"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#非location相关的状态问题",
    "href": "1.3_dicom_status.html#非location相关的状态问题",
    "title": "DICOM状态检查：确保三维医学图像的空间一致性",
    "section": "非Location相关的状态问题",
    "text": "非Location相关的状态问题\nDiCube使用四种模式来分类非Location相关的字段问题：missing、non_uniform、gap、duplicate。\n\n1. Missing 问题：关键字段缺失\n\n# 演示missing问题的检测\nimport copy\nfrom dicube.dicom.dicom_tags import get_tag_key\n\ndef demo_missing_problems():\n    print(\"=== Missing 问题演示 ===\")\n    \n    # 缺失像素间距\n    test_meta1 = copy.deepcopy(meta)\n    test_meta1._merged_data.pop(get_tag_key(CommonTags.PixelSpacing), None)\n    status1 = get_dicom_status(test_meta1)\n    print(f\"删除PixelSpacing后: {status1.value}\")\n    \n    # 缺失图像尺寸\n    test_meta2 = copy.deepcopy(meta)\n    test_meta2._merged_data.pop(get_tag_key(CommonTags.Columns), None)\n    status2 = get_dicom_status(test_meta2)\n    print(f\"删除Columns后: {status2.value}\")\n    \n    # 缺失数据类型信息\n    test_meta3 = copy.deepcopy(meta)\n    test_meta3._merged_data.pop(get_tag_key(CommonTags.BitsStored), None)\n    status3 = get_dicom_status(test_meta3)\n    print(f\"删除BitsStored后: {status3.value}\")\n\ndemo_missing_problems()\n\n=== Missing 问题演示 ===\n删除PixelSpacing后: missing_spacing\n删除Columns后: missing_shape\n删除BitsStored后: missing_dtype\n\n\n\n\n2. Non_uniform 问题：字段值不一致\n\ndef demo_non_uniform_problems():\n    print(\"\\n=== Non_uniform 问题演示 ===\")\n    \n    # 像素间距不一致\n    test_meta1 = copy.deepcopy(meta)\n    num_slices = test_meta1.slice_count\n    spacing_values = []\n    for i in range(num_slices):\n        if i &lt; num_slices // 2:\n            spacing_values.append([0.5, 0.5])  # 前半段用0.5mm\n        else:\n            spacing_values.append([1.0, 1.0])  # 后半段用1.0mm\n    test_meta1.set_nonshared_item(CommonTags.PixelSpacing, spacing_values)\n    status1 = get_dicom_status(test_meta1)\n    print(f\"设置不一致PixelSpacing后: {status1.value}\")\n    \n    # 图像尺寸不一致\n    test_meta2 = copy.deepcopy(meta)\n    cols_values = []\n    for i in range(num_slices):\n        if i &lt; num_slices // 2:\n            cols_values.append(512)  # 前半段512列\n        else:\n            cols_values.append(256)  # 后半段256列\n    test_meta2.set_nonshared_item(CommonTags.Columns, cols_values)\n    status2 = get_dicom_status(test_meta2)\n    print(f\"设置不一致Columns后: {status2.value}\")\n\ndemo_non_uniform_problems()\n\n\n=== Non_uniform 问题演示 ===\n设置不一致PixelSpacing后: non_uniform_spacing\n设置不一致Columns后: non_uniform_shape\n\n\n\n\n3. Duplicate 问题：重复值\n\ndef demo_duplicate_problems():\n    print(\"\\n=== Duplicate 问题演示 ===\")\n    \n    # 实例编号重复\n    test_meta = copy.deepcopy(meta)\n    num_slices = test_meta.slice_count\n    # 所有切片都使用相同的实例编号\n    duplicate_numbers = [1] * num_slices\n    test_meta.set_nonshared_item(CommonTags.InstanceNumber, duplicate_numbers)\n    status = get_dicom_status(test_meta)\n    print(f\"设置重复InstanceNumber后: {status.value}\")\n    \n    # 展示重复检测逻辑\n    instance_numbers = test_meta.get_values(CommonTags.InstanceNumber)\n    unique_count = len(set(instance_numbers))\n    total_count = len(instance_numbers)\n    print(f\"  实例编号: {instance_numbers[:5]}... (总共{total_count}个)\")\n    print(f\"  唯一值数量: {unique_count}\")\n    print(f\"  检测逻辑: unique_count({unique_count}) &lt; total_count({total_count}) = {unique_count &lt; total_count}\")\n\ndemo_duplicate_problems()\n\n\n=== Duplicate 问题演示 ===\n设置重复InstanceNumber后: duplicate_instance_numbers\n  实例编号: [1, 1, 1, 1, 1]... (总共200个)\n  唯一值数量: 1\n  检测逻辑: unique_count(1) &lt; total_count(200) = True\n\n\n\n\n4. Gap 问题：数值跳跃\n\ndef demo_gap_problems():\n    print(\"\\n=== Gap 问题演示 ===\")\n    \n    # 实例编号跳跃\n    test_meta = copy.deepcopy(meta)\n    num_slices = test_meta.slice_count\n    \n    # 创建有跳跃的实例编号序列：1,2,3,5,6,7,8...\n    gap_numbers = list(range(1, num_slices + 1))\n    for i in range(3, len(gap_numbers)):  # 从第4个开始，所有编号+1\n        gap_numbers[i] += 1\n    \n    test_meta.set_nonshared_item(CommonTags.InstanceNumber, gap_numbers)\n    status = get_dicom_status(test_meta)\n    print(f\"设置跳跃InstanceNumber后: {status.value}\")\n    \n    # 展示跳跃检测逻辑\n    instance_numbers = test_meta.get_values(CommonTags.InstanceNumber)\n    sorted_numbers = sorted([int(x) for x in instance_numbers])\n    print(f\"  排序后的实例编号: {sorted_numbers[:8]}...\")\n    \n    # 检查连续性\n    diffs = [sorted_numbers[i+1] - sorted_numbers[i] for i in range(len(sorted_numbers)-1)]\n    print(f\"  相邻差值: {diffs[:7]}...\")\n    gap_detected = not all(d == 1 for d in diffs)\n    print(f\"  检测逻辑: 存在非1的差值 = {gap_detected}\")\n\ndemo_gap_problems()\n\n\n=== Gap 问题演示 ===\n设置跳跃InstanceNumber后: gap_instance_number\n  排序后的实例编号: [1, 2, 3, 5, 6, 7, 8, 9]...\n  相邻差值: [1, 1, 2, 1, 1, 1, 1]...\n  检测逻辑: 存在非1的差值 = True",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM状态检查：确保三维医学图像的空间一致性"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#location相关的状态问题",
    "href": "1.3_dicom_status.html#location相关的状态问题",
    "title": "DICOM状态检查：确保三维医学图像的空间一致性",
    "section": "Location相关的状态问题",
    "text": "Location相关的状态问题\nLocation相关的问题主要涉及切片在三维空间中的位置排列，这些问题会破坏规范采样网格的连续性。\n\n1. Missing Location：位置信息缺失\n当DICOM序列中既缺少ImagePositionPatient又缺少SliceLocation字段时，DiCube无法确定切片的空间位置。\n检测逻辑：需要ImagePositionPatient OR SliceLocation，当两者都缺失时 → MISSING_LOCATION\n\n\n2. Dwelling Location：位置停滞\n这是位置序列中出现重复值的情况，表示多个切片具有相同的空间位置。\n数值示例：\n\n正常序列：[1.0, 2.0, 3.0, 4.0, 5.0] (间距为1.0)\n停滞序列：[1.0, 2.0, 2.0, 3.0, 4.0] (第2和第3个位置相同)\n位置差值：[1.0, 0.0, 1.0, 1.0]\n\n检测逻辑：当位置差值中存在零值时 → DWELLING_LOCATION\n\n\n3. Reversed Location：位置方向混乱\nZ轴位置序列中同时存在正向和反向移动，表示扫描方向不一致或序列被打乱。\n数值示例：\n\n正常序列：[1.0, 2.0, 3.0, 4.0, 5.0] (单调递增)\n混乱序列：[1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 6.0] (第5个位置倒退)\n位置差值：[1.0, 1.0, 1.0, -2.0, 3.0, 1.0]\n\n检测逻辑：当位置差值中同时存在正值和负值时 → REVERSED_LOCATION\n\n\n4. Gap Location：位置跳跃\nZ轴位置序列中出现不规律的大间隙，破坏了等间距采样的假设。\n数值示例：\n\n正常序列：[10.0, 15.0, 20.0, 25.0, 30.0] (间距为5.0)\n跳跃序列：[10.0, 15.0, 20.0, 35.0, 40.0] (第4个位置跳跃)\n位置差值：[5.0, 5.0, 15.0, 5.0]\n平均间距：5.0\n相对偏差：[0%, 0%, 200%, 0%]\n\n检测逻辑：当某个间距偏离平均值超过50%时 → GAP_LOCATION",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM状态检查：确保三维医学图像的空间一致性"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#dicube的兼容性处理策略",
    "href": "1.3_dicom_status.html#dicube的兼容性处理策略",
    "title": "DICOM状态检查：确保三维医学图像的空间一致性",
    "section": "DiCube的兼容性处理策略",
    "text": "DiCube的兼容性处理策略\nDiCube尽力在各种异常情况下保持兼容性，采用”尽力而为”的原则来处理有问题的DICOM数据。当检测到数据质量问题时，DiCube仍然能够加载和处理数据，但会相应地限制某些功能。\n\n处理策略细节\n无法计算Space信息的状态： - MISSING_SPACING、NON_UNIFORM_SPACING：像素间距问题 - MISSING_ORIENTATION、NON_UNIFORM_ORIENTATION：图像方向问题\n- MISSING_LOCATION、REVERSED_LOCATION、DWELLING_LOCATION、GAP_LOCATION：位置信息问题\n处理方式： 1. 像素数据：正常加载和处理，应用必要的rescale变换 2. 元数据：完整保留所有DICOM标签信息，确保往返转换的完整性 3. 空间信息：当检测到空间相关问题时，将Space设置为None并警告用户 4. 功能限制：无法进行需要精确空间信息的操作，如空间变换、重采样、配准等\n这种设计确保了DiCube在面对现实世界中不完美的DICOM数据时，仍能提供基本的图像处理功能，同时明确告知用户哪些高级功能不可用。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM状态检查：确保三维医学图像的空间一致性"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#错误优先级只报告最严重的问题",
    "href": "1.3_dicom_status.html#错误优先级只报告最严重的问题",
    "title": "DICOM状态检查：确保三维医学图像的空间一致性",
    "section": "错误优先级：只报告最严重的问题",
    "text": "错误优先级：只报告最严重的问题\nDiCube的状态检查遵循严格的优先级原则：按照严重程度从高到低依次检查，只报告发现的第一个（最严重的）问题。这种设计避免了信息过载，有助于用户专注于解决最关键的问题。\n\n检查优先级顺序\n\nSeries UID问题（最高优先级）\n\nMISSING_SERIES_UID：缺失序列标识符\nNON_UNIFORM_SERIES_UID：序列标识符不统一\n\nInstance Number问题\n\nMISSING_INSTANCE_NUMBER：缺失实例编号\nDUPLICATE_INSTANCE_NUMBERS：实例编号重复\nGAP_INSTANCE_NUMBER：实例编号跳跃\n\n数据类型问题\n\nMISSING_DTYPE：缺失数据类型信息\nNON_UNIFORM_DTYPE：数据类型不一致\n\n空间参数问题\n\nMISSING_SPACING：缺失像素间距\nNON_UNIFORM_SPACING：像素间距不一致\nMISSING_SHAPE：缺失图像尺寸\nNON_UNIFORM_SHAPE：图像尺寸不一致\nMISSING_ORIENTATION：缺失图像方向\nNON_UNIFORM_ORIENTATION：图像方向不一致\n\n位置问题\n\nMISSING_LOCATION：缺失位置信息\nREVERSED_LOCATION：位置方向混乱\nDWELLING_LOCATION：位置停滞\nGAP_LOCATION：位置跳跃\n\n其他问题\n\nNON_UNIFORM_RESCALE_FACTOR：校正参数不一致\n\n理想状态\n\nCONSISTENT：所有检查通过",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM状态检查：确保三维医学图像的空间一致性"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#总结",
    "href": "1.3_dicom_status.html#总结",
    "title": "DICOM状态检查：确保三维医学图像的空间一致性",
    "section": "总结",
    "text": "总结\nDicomStatus系统通过系统化的状态检查，确保DiCube能够：\n\n识别理想状态：CONSISTENT状态代表规范的三维采样网格\n分类问题类型：用missing、non_uniform、gap、duplicate四种模式描述非Location问题\n检测空间异常：专门处理dwelling、reversed、gap等Location相关问题\n\n智能兼容处理：在数据有问题时仍能部分工作，但合理限制功能\n优先级管理：按严重程度报告问题，指导用户逐步修复\n\n这个系统为DiCube的可靠性和鲁棒性提供了重要保障，确保在各种真实世界的数据质量情况下都能给出合理的处理方案。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM状态检查：确保三维医学图像的空间一致性"
    ]
  },
  {
    "objectID": "1.4_sort_method.html",
    "href": "1.4_sort_method.html",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "",
    "text": "当我们从医院PACS系统或者存储设备中获取一个DICOM检查序列时，面对的往往是数百个”散装”的2D切片文件。这些文件通常是无序存储的，文件名也可能毫无规律。要将这些2D图像正确地堆叠成完整的3D体积数据，我们遇到的第一个关键技术问题就是：按什么顺序来排列这些切片？\n这个看似简单的问题，背后实际上隐藏着临床工作流程、三维渲染引擎、AI算法处理等多个层面的需求冲突。每种排序方法都有其合理的技术依据和应用场景，但在特定的使用环境下可能会产生意想不到的问题。\n\n\n在实际项目开发中，我们经常会遇到这样的矛盾场景：\n\n临床报告的需求：医生在写诊断报告时，习惯于按照Instance Number来定位病灶，会在报告中写”病灶位于第X层切片”。这是因为绝大多数PACS系统在显示图像时，默认就是按照Instance Number来排序展示的，这已经成为了临床工作的标准流程。\nAI算法的标准化需求：为了保证算法输入的一致性，很多深度学习模型会要求图像按照解剖学方向进行排序，比如严格按照”从头到脚”或者”从脚到头”的顺序来排列切片，一般会选择“SliceLocation” 或者 “ImagePatientPosition” 字段来进行排序。这样做的好处是算法可以学习到一致的解剖结构分布模式。我们通常假设绝大部分的CT和MR检查都是横断位扫描，所以”从头到脚”和”从脚到头”确实是非常自然和直观的排序选择，符合我们对人体解剖结构的认知。\n非标准扫描的挑战：但现实总是更复杂的。有些图像是倾斜扫描的，比如心脏MR的四腔心切面扫描，或者对原始CT图像进行了冠状位重建。在这些情况下，Slice Location字段可能根本就不存在，Image Patient Position字段也让人困惑——你很难确定应该用哪个坐标分量来进行排序。\n三维渲染的技术约束：如果我们要做三维可视化，比如使用VTK渲染引擎，那么就必须考虑到VTK默认使用的是右手坐标系，如果我们排序方法不正确，会导致渲染结果出现”镜像人”的现象。\n\n基于这些复杂的需求冲突，我们推荐使用右手坐标系排序作为默认方案。\n为什么推荐右手系排序？ - 修改成本最小化: 实际上，任何一种排序方式都有其技术合理性，只要我们能够忠实地记录并传递元数据信息，各个模块都可以根据自身需求进行方向转换。但是，不同模块的转换成本存在显著差异。对于算法处理和三维渲染模块而言，它们直接操作的是完整的3D数组结构，如果需要进行图像翻转或重新排列，就必须对大块的连续内存进行读写操作，这种操作的计算开销相当可观。相比之下，PACS查看器的处理方式更为灵活——它本质上将图像序列视为一个2D图像的列表集合，因此只需要调整索引映射关系就能实现不同的显示顺序，而无需移动实际的图像数据。从系统整体的性能优化角度考虑，让计算密集型的算法和渲染模块使用标准化的右手系排序，而让显示模块承担轻量级的索引转换工作，这种设计思路能够最大化地降低系统的整体修改成本。\n右手系排序的技术实现\n右手系排序的算法原理其实很直观：我们读取DICOM文件中的Image Patient Orientation字段，这个字段会告诉我们图像平面的X方向（前三个数字）和Y方向（后三个数字）。通过对这两个方向向量进行叉乘运算，我们可以得到垂直于图像平面的法向量。然后，将每张图像的Image Patient Position投影到这个法向量上，按照投影值从小到大排列，这样得到的切片序列就保证是右手坐标系的。\n现实问题\n理论上来说，只要我们保证坐标系是右手的，那么无论患者在扫描时是怎么躺的，或者扫描序列是怎么”歪着扫”的（比如心脏MR的四腔心切面），导致三个坐标轴并不完全对应标准的LPS方向，渲染时使用者都可以通过三维旋转操作，将图像调整到标准的LPS显示方向。\n但是有极少的医疗设备厂商并不严格遵守DICOM的LPS坐标系准则，在进行世界坐标系标定时，采用的本身就是左手坐标系。这种情况下，即使我们按照推荐的右手系排序方法进行DICOM堆叠，仍然会出现”镜像人”的问题。好在这种情况相对比较少见，但一旦遇到，就只能通过更复杂的图像分析算法来检测和纠正异常，因为从DICOM的元数据信息中是无法判断出这种标定错误的。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "1.4_sort_method.html#为什么dicom序列需要排序",
    "href": "1.4_sort_method.html#为什么dicom序列需要排序",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "",
    "text": "当我们从医院PACS系统或者存储设备中获取一个DICOM检查序列时，面对的往往是数百个”散装”的2D切片文件。这些文件通常是无序存储的，文件名也可能毫无规律。要将这些2D图像正确地堆叠成完整的3D体积数据，我们遇到的第一个关键技术问题就是：按什么顺序来排列这些切片？\n这个看似简单的问题，背后实际上隐藏着临床工作流程、三维渲染引擎、AI算法处理等多个层面的需求冲突。每种排序方法都有其合理的技术依据和应用场景，但在特定的使用环境下可能会产生意想不到的问题。\n\n\n在实际项目开发中，我们经常会遇到这样的矛盾场景：\n\n临床报告的需求：医生在写诊断报告时，习惯于按照Instance Number来定位病灶，会在报告中写”病灶位于第X层切片”。这是因为绝大多数PACS系统在显示图像时，默认就是按照Instance Number来排序展示的，这已经成为了临床工作的标准流程。\nAI算法的标准化需求：为了保证算法输入的一致性，很多深度学习模型会要求图像按照解剖学方向进行排序，比如严格按照”从头到脚”或者”从脚到头”的顺序来排列切片，一般会选择“SliceLocation” 或者 “ImagePatientPosition” 字段来进行排序。这样做的好处是算法可以学习到一致的解剖结构分布模式。我们通常假设绝大部分的CT和MR检查都是横断位扫描，所以”从头到脚”和”从脚到头”确实是非常自然和直观的排序选择，符合我们对人体解剖结构的认知。\n非标准扫描的挑战：但现实总是更复杂的。有些图像是倾斜扫描的，比如心脏MR的四腔心切面扫描，或者对原始CT图像进行了冠状位重建。在这些情况下，Slice Location字段可能根本就不存在，Image Patient Position字段也让人困惑——你很难确定应该用哪个坐标分量来进行排序。\n三维渲染的技术约束：如果我们要做三维可视化，比如使用VTK渲染引擎，那么就必须考虑到VTK默认使用的是右手坐标系，如果我们排序方法不正确，会导致渲染结果出现”镜像人”的现象。\n\n基于这些复杂的需求冲突，我们推荐使用右手坐标系排序作为默认方案。\n为什么推荐右手系排序？ - 修改成本最小化: 实际上，任何一种排序方式都有其技术合理性，只要我们能够忠实地记录并传递元数据信息，各个模块都可以根据自身需求进行方向转换。但是，不同模块的转换成本存在显著差异。对于算法处理和三维渲染模块而言，它们直接操作的是完整的3D数组结构，如果需要进行图像翻转或重新排列，就必须对大块的连续内存进行读写操作，这种操作的计算开销相当可观。相比之下，PACS查看器的处理方式更为灵活——它本质上将图像序列视为一个2D图像的列表集合，因此只需要调整索引映射关系就能实现不同的显示顺序，而无需移动实际的图像数据。从系统整体的性能优化角度考虑，让计算密集型的算法和渲染模块使用标准化的右手系排序，而让显示模块承担轻量级的索引转换工作，这种设计思路能够最大化地降低系统的整体修改成本。\n右手系排序的技术实现\n右手系排序的算法原理其实很直观：我们读取DICOM文件中的Image Patient Orientation字段，这个字段会告诉我们图像平面的X方向（前三个数字）和Y方向（后三个数字）。通过对这两个方向向量进行叉乘运算，我们可以得到垂直于图像平面的法向量。然后，将每张图像的Image Patient Position投影到这个法向量上，按照投影值从小到大排列，这样得到的切片序列就保证是右手坐标系的。\n现实问题\n理论上来说，只要我们保证坐标系是右手的，那么无论患者在扫描时是怎么躺的，或者扫描序列是怎么”歪着扫”的（比如心脏MR的四腔心切面），导致三个坐标轴并不完全对应标准的LPS方向，渲染时使用者都可以通过三维旋转操作，将图像调整到标准的LPS显示方向。\n但是有极少的医疗设备厂商并不严格遵守DICOM的LPS坐标系准则，在进行世界坐标系标定时，采用的本身就是左手坐标系。这种情况下，即使我们按照推荐的右手系排序方法进行DICOM堆叠，仍然会出现”镜像人”的问题。好在这种情况相对比较少见，但一旦遇到，就只能通过更复杂的图像分析算法来检测和纠正异常，因为从DICOM的元数据信息中是无法判断出这种标定错误的。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "1.4_sort_method.html#排序方法的可视化验证",
    "href": "1.4_sort_method.html#排序方法的可视化验证",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "排序方法的可视化验证",
    "text": "排序方法的可视化验证\n让我们通过三视图的方式来直观地观察和验证右手坐标系排序的效果。通过查看横断面、冠状面和矢状面的图像，我们可以清楚地了解图像的空间排列是否正确：\n\nimport dicube\nfrom dicube import SortMethod\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 加载示例DICOM数据\ndirname = 'dicube-testdata/dicom/sample_200'\n\n# 使用右手坐标系排序方法加载图像数据\nimg_rh = dicube.load_from_dicom_folder(dirname, sort_method=SortMethod.POSITION_RIGHT_HAND)\n\nprint(\"=== 右手坐标系排序的图像数据信息 ===\")\nprint(f\"图像数据形状: {img_rh.raw_image.shape}\")\nprint(f\"排序方法: POSITION_RIGHT_HAND\")\n\n# 获取中心切片\ndef get_center_slices(image_data):\n    \"\"\"获取三个方向的中心切片\"\"\"\n    z_center = image_data.shape[0] // 2\n    y_center = image_data.shape[1] // 2  \n    x_center = image_data.shape[2] // 2\n    \n    return {\n        'axial': image_data[z_center, :, :],      # 横断面\n        'coronal': image_data[:, y_center, :],    # 冠状面  \n        'sagittal': image_data[:, :, x_center]    # 矢状面\n    }\n\nslices_rh = get_center_slices(img_rh.get_fdata())\n\n# 创建三个独立的图\n# 1. Axial View (横断面)\nfig1, ax1 = plt.subplots(1, 1, figsize=(8, 6))\nim1 = ax1.imshow(slices_rh['axial'], cmap='gray', origin='lower')\nax1.set_title(f'Axial View - Slice along Z-axis (slice {img_rh.raw_image.shape[0]//2} of {img_rh.raw_image.shape[0]})', fontsize=14)\nax1.set_xlabel('Axis 2 (X): Right → Left', fontsize=12)\nax1.set_ylabel('Axis 1 (Y): Anterior → Posterior', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n# 2. Coronal View (冠状面)\nfig2, ax2 = plt.subplots(1, 1, figsize=(8, 6))\nim2 = ax2.imshow(slices_rh['coronal'], cmap='gray', origin='lower')\nax2.set_title(f'Coronal View - Slice along Y-axis (slice {img_rh.raw_image.shape[1]//2} of {img_rh.raw_image.shape[1]})', fontsize=14)\nax2.set_xlabel('Axis 2 (X): Right → Left', fontsize=12)\nax2.set_ylabel('Axis 0 (Z): Inferior → Superior', fontsize=12)\nplt.tight_layout()\nplt.show()\n\n# 3. Sagittal View (矢状面)\nfig3, ax3 = plt.subplots(1, 1, figsize=(8, 6))\nim3 = ax3.imshow(slices_rh['sagittal'], cmap='gray', origin='lower')\nax3.set_title(f'Sagittal View - Slice along X-axis (slice {img_rh.raw_image.shape[2]//2} of {img_rh.raw_image.shape[2]})', fontsize=14)\nax3.set_xlabel('Axis 1 (Y): Posterior → Anterior', fontsize=12)\nax3.set_ylabel('Axis 0 (Z): Inferior → Superior', fontsize=12)\nplt.tight_layout()\nplt.show()\n\n=== 右手坐标系排序的图像数据信息 ===\n图像数据形状: (200, 512, 512)\n排序方法: POSITION_RIGHT_HAND",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "1.4_sort_method.html#排序方法的最佳实践建议",
    "href": "1.4_sort_method.html#排序方法的最佳实践建议",
    "title": "DICOM序列排序：从临床需求到三维重建的技术权衡",
    "section": "排序方法的最佳实践建议",
    "text": "排序方法的最佳实践建议\n基于我们在实际项目中的经验积累和技术考量，我们强烈推荐使用右手坐标系排序作为默认的DICOM切片排序方案。这个建议背后有以下几个重要的技术和实用性考虑：\n\n技术兼容性优势\n\n渲染引擎兼容性：VTK、ITK等主流医学影像处理和渲染引擎都默认采用右手坐标系，直接使用右手系排序可以避免额外的坐标系转换\n标准合规性：完全符合DICOM LPS+坐标系标准，确保与国际医学影像标准的兼容性\nAI算法稳定性：在深度学习模型训练和推理过程中，避免因坐标系不一致导致的”镜像人”问题，提高算法的鲁棒性\n计算效率：减少运行时的坐标系转换计算，降低处理开销",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "DICOM序列排序：从临床需求到三维重建的技术权衡"
    ]
  },
  {
    "objectID": "1.0_motivation.html",
    "href": "1.0_motivation.html",
    "title": "为什么需要DiCube？",
    "section": "",
    "text": "当我们设计一个医学影像工作站的时候，一定会接触到DICOM文件，它是影像科图像的标准格式。除了像素数据之外，DICOM还存储着各种元数据信息，比如患者姓名、检查位置、时间戳、设备参数等临床关键信息。\nDICOM标准在临床互操作性方面功不可没，但它的设计初衷是为了解决20世纪80年代的互联互通问题，并非为了应对今天高容量、AI驱动、多并发的现代工作流程。在实际部署中，我们发现DICOM暴露出四个慢性痛点：\n\n\n这是DICOM最严重的问题。一个CT或MR序列往往包含数百个小的.dcm文件，甚至有些复杂检查包含数千个文件。在现代医学影像工作站中，多个组件需要同时访问这些DICOM文件：\n\nDICOM通信模块：负责从网络接收数据，进行完整性校验和字段正规性验证\n三维可视化渲染：需要像素数据和空间信息来构建MPR、VR等视图\n后端数据库系统：需要提取各种元数据信息以便对图像进行入库和索引\nAI算法引擎：需要像素数据和空间信息进行自动分析\nDICOM打印推送模块：需要将完整的DICOM文件推送到打印机或其他设备\n\n当这些模块并发访问同一组DICOM文件时，文件系统的随机读写成为严重瓶颈。我们在开发CTP算法时发现，即使在没有任何其他程序运行的情况下，从机械硬盘读取3000+张DICOM文件也需要10秒以上的时间。当多个模块同时访问时，系统很容易出现卡顿。\n虽然可以将数据转移到SSD上来缓解这个问题，但大型医院每天产生数千个病例，SSD容量几天就会耗尽，需要频繁地进行数据迁移到机械硬盘。这种大规模的数据迁移操作本身就非常耗时。现代文件系统虽然有高速缓存机制，刚刚接收的热数据读取速度还算可控，但如果要访问数天前已进入冷存储的数据，读取时间会变得非常糟糕。\n此外，如此零碎的文件分布对数据完整性校验也是一个挑战。接收方无法确定序列是否已经传输完成，因为可能随时会有新的切片推送过来。\n\n\n\n这是DICOM设计中的一个重大缺陷。绝大部分DICOM字段（患者姓名、检查日期、序列描述、设备信息等）在同一序列的所有切片中都是相同的，却在每个文件中重复存储。\n一般来说，后端系统为了获取入库所需的元数据，会选择读取序列中的一个文件来提取这些共享信息。其余几百个文件中的元数据副本完全是浪费的存储空间和网络传输带宽。更糟糕的是，当我们发现某个本应共享的字段在不同文件中出现不一致的值时，会给数据处理带来很大困扰。\n\n\n\n在实际部署中，我们经常遇到各种数据质量问题： - 序列中缺少一张或若干张DICOM文件 - 关键字段没有填写或者填写错误 - InstanceNumber重复或不连续 - 像素间距不一致 - 图像位置信息缺失\n作为工作站厂商，我们无法改变医院的数据推送现状，只能设计额外的质控模块来检查这些问题，将有严重问题的病例筛选出来，防止它们进入后续的处理流程。但是，不同的AI算法对这些数据质量问题的容忍度并不相同，要设计一个能够兼容所有算法需求的通用质控模块是非常困难的。\n\n\n\nDICOM的二进制格式缺乏全局索引，解析器只能从文件头开始顺序解析到文件尾，直到找到目标标签。这种设计导致即使只需要访问少量字段（比如PACS查看器只需要ImagePosition和InstanceNumber），也必须解析整个元数据块。\n因此，PyDICOM等主流库的默认行为是直接将整个元数据读入内存。这种设计对性能的影响是灾难性的：比如你是一个PACS查看器，实际上只需要每个图像的ImagePosition和InstanceNumber信息来构建序列视图，但你不得不将所有元数据全部读取和解析一遍。\n此外，许多DICOM标签是文本（字符串）或变长数组，解析过程需要反复进行内存分配和字符编码转换，这种方式不适合高性能的批处理场景。DICOM的这种数据组织方式也不适合与现代数据库系统进行快速整合，开发者不得不编写大量的数据转换代码。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "为什么需要DiCube？"
    ]
  },
  {
    "objectID": "1.0_motivation.html#dicom在现代医学影像工作流中的挑战",
    "href": "1.0_motivation.html#dicom在现代医学影像工作流中的挑战",
    "title": "为什么需要DiCube？",
    "section": "",
    "text": "当我们设计一个医学影像工作站的时候，一定会接触到DICOM文件，它是影像科图像的标准格式。除了像素数据之外，DICOM还存储着各种元数据信息，比如患者姓名、检查位置、时间戳、设备参数等临床关键信息。\nDICOM标准在临床互操作性方面功不可没，但它的设计初衷是为了解决20世纪80年代的互联互通问题，并非为了应对今天高容量、AI驱动、多并发的现代工作流程。在实际部署中，我们发现DICOM暴露出四个慢性痛点：\n\n\n这是DICOM最严重的问题。一个CT或MR序列往往包含数百个小的.dcm文件，甚至有些复杂检查包含数千个文件。在现代医学影像工作站中，多个组件需要同时访问这些DICOM文件：\n\nDICOM通信模块：负责从网络接收数据，进行完整性校验和字段正规性验证\n三维可视化渲染：需要像素数据和空间信息来构建MPR、VR等视图\n后端数据库系统：需要提取各种元数据信息以便对图像进行入库和索引\nAI算法引擎：需要像素数据和空间信息进行自动分析\nDICOM打印推送模块：需要将完整的DICOM文件推送到打印机或其他设备\n\n当这些模块并发访问同一组DICOM文件时，文件系统的随机读写成为严重瓶颈。我们在开发CTP算法时发现，即使在没有任何其他程序运行的情况下，从机械硬盘读取3000+张DICOM文件也需要10秒以上的时间。当多个模块同时访问时，系统很容易出现卡顿。\n虽然可以将数据转移到SSD上来缓解这个问题，但大型医院每天产生数千个病例，SSD容量几天就会耗尽，需要频繁地进行数据迁移到机械硬盘。这种大规模的数据迁移操作本身就非常耗时。现代文件系统虽然有高速缓存机制，刚刚接收的热数据读取速度还算可控，但如果要访问数天前已进入冷存储的数据，读取时间会变得非常糟糕。\n此外，如此零碎的文件分布对数据完整性校验也是一个挑战。接收方无法确定序列是否已经传输完成，因为可能随时会有新的切片推送过来。\n\n\n\n这是DICOM设计中的一个重大缺陷。绝大部分DICOM字段（患者姓名、检查日期、序列描述、设备信息等）在同一序列的所有切片中都是相同的，却在每个文件中重复存储。\n一般来说，后端系统为了获取入库所需的元数据，会选择读取序列中的一个文件来提取这些共享信息。其余几百个文件中的元数据副本完全是浪费的存储空间和网络传输带宽。更糟糕的是，当我们发现某个本应共享的字段在不同文件中出现不一致的值时，会给数据处理带来很大困扰。\n\n\n\n在实际部署中，我们经常遇到各种数据质量问题： - 序列中缺少一张或若干张DICOM文件 - 关键字段没有填写或者填写错误 - InstanceNumber重复或不连续 - 像素间距不一致 - 图像位置信息缺失\n作为工作站厂商，我们无法改变医院的数据推送现状，只能设计额外的质控模块来检查这些问题，将有严重问题的病例筛选出来，防止它们进入后续的处理流程。但是，不同的AI算法对这些数据质量问题的容忍度并不相同，要设计一个能够兼容所有算法需求的通用质控模块是非常困难的。\n\n\n\nDICOM的二进制格式缺乏全局索引，解析器只能从文件头开始顺序解析到文件尾，直到找到目标标签。这种设计导致即使只需要访问少量字段（比如PACS查看器只需要ImagePosition和InstanceNumber），也必须解析整个元数据块。\n因此，PyDICOM等主流库的默认行为是直接将整个元数据读入内存。这种设计对性能的影响是灾难性的：比如你是一个PACS查看器，实际上只需要每个图像的ImagePosition和InstanceNumber信息来构建序列视图，但你不得不将所有元数据全部读取和解析一遍。\n此外，许多DICOM标签是文本（字符串）或变长数组，解析过程需要反复进行内存分配和字符编码转换，这种方式不适合高性能的批处理场景。DICOM的这种数据组织方式也不适合与现代数据库系统进行快速整合，开发者不得不编写大量的数据转换代码。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "为什么需要DiCube？"
    ]
  },
  {
    "objectID": "1.0_motivation.html#性能问题实测",
    "href": "1.0_motivation.html#性能问题实测",
    "title": "为什么需要DiCube？",
    "section": "性能问题实测",
    "text": "性能问题实测\n让我们通过实际测试来验证这些问题。使用一个包含200张图像的CT序列：\n\nimport pydicom\nimport os\nimport time\nimport multiprocessing as mp\n\ndirname = 'dicube-testdata/dicom/sample_200'\ndcbs_file = 'dicube-testdata/test_sequence.dcbs'\n\ndef read_dicom_sequence(dirname, metadata_only=False):\n    \"\"\"读取DICOM序列\"\"\"\n    files = os.listdir(dirname)\n    instance_numbers = []\n    \n    for filename in files:\n        filepath = os.path.join(dirname, filename)\n        ds = pydicom.dcmread(filepath, stop_before_pixels=metadata_only)\n        instance_numbers.append(ds.InstanceNumber)\n    \n    return instance_numbers\n\n# 单进程读取\nstart_time = time.time()\nresult = read_dicom_sequence(dirname)\nsingle_time = time.time() - start_time\nprint(f\"单进程读取200个DICOM文件: {single_time:.3f}秒\")\n\n单进程读取200个DICOM文件: 0.161秒\n\n\n现在模拟多个进程并发访问的真实场景：\n\ndef concurrent_read_test(num_processes=5):\n    \"\"\"测试并发读取性能\"\"\"\n    pool = mp.Pool(num_processes)\n    \n    start_time = time.time()\n    results = []\n    \n    # 模拟多个组件同时读取不同序列\n    for i in range(num_processes):\n        test_dir = f\"{dirname}\"\n        results.append(pool.apply_async(read_dicom_sequence, (test_dir,)))\n    \n    # 等待所有进程完成\n    [r.get() for r in results]\n    concurrent_time = time.time() - start_time\n    \n    pool.close()\n    pool.join()\n    \n    return concurrent_time\n\nconcurrent_time = concurrent_read_test()\nprint(f\"5进程并发读取: {concurrent_time:.3f}秒\")\nprint(f\"性能下降: {concurrent_time/single_time:.1f}倍\")\n\n5进程并发读取: 0.178秒\n性能下降: 1.1倍\n\n\n可以看到，单线程顺序读取的时间还算可控，但当5个进程并发读取时，时间会大幅增加，这比顺序读取5次还要慢。这就是机械硬盘随机读写瓶颈的体现。\n令人意外的是，即使我们设置 stop_before_pixels=True 只读取元数据而不读取像素数据，读取时间甚至可能更长。这反映了一个根本问题：文件碎片化会大幅增加读取时间，而仅读取文件头并不能改变文件碎片化的现实。\n这种性能问题在SSD上会有所缓解，但在大多数医院仍然使用机械硬盘作为主要存储的现实下，这个问题非常突出。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "为什么需要DiCube？"
    ]
  },
  {
    "objectID": "1.0_motivation.html#dicube的系统性解决方案",
    "href": "1.0_motivation.html#dicube的系统性解决方案",
    "title": "为什么需要DiCube？",
    "section": "DiCube的系统性解决方案",
    "text": "DiCube的系统性解决方案\n针对DICOM的这些结构性问题，DiCube采用了全新的设计理念。我们不是简单地对DICOM格式进行增量改进，而是从医学影像工作流的实际需求出发，重新设计了一套既保持DICOM兼容性，又能显著提升性能的存储格式。\nDiCube的核心设计原则包括： 1. 统一文件容器：将整个序列整合为单一文件，彻底消除文件碎片化 2. 智能元数据管理：区分共享和非共享元数据，采用高效的索引和压缩 3. 现代编解码技术：使用HTJ2K等先进编解码器，平衡压缩比和速度 4. 完整往返兼容：确保与标准DICOM的100%兼容性\n\n单文件存储\n将整个序列合并为一个.dcbs文件，消除文件系统开销：\n\nimport dicube\nfrom dicube.dicom import CommonTags\n\n# 转换DICOM序列为DiCube格式\ndcb_image = dicube.load_from_dicom_folder(dirname)\ndicube.save(dcb_image, dcbs_file)\n\n# 测试DiCube加载性能\nstart_time = time.time()\nloaded_image = dicube.load(dcbs_file)\ndcb_load_time = time.time() - start_time\n\nprint(f\"DiCube加载时间: {dcb_load_time:.3f}秒\")\n\nDiCube加载时间: 0.252秒\n\n\n\n\n智能元数据去重与索引\nDiCube的元数据管理是其核心创新之一。我们认识到DICOM序列中绝大部分元数据是在所有切片间共享的，只有少数字段（如ImagePosition、InstanceNumber）是每个切片独有的。\nDiCube使用智能的JSON架构来分离这两类元数据： - 共享元数据：患者信息、检查信息、序列参数等，只存储一份 - 非共享元数据：图像位置、实例编号等，按切片索引存储\n这种设计不仅大幅减少了存储空间，更重要的是实现了元数据的快速随机访问：\n\n# 快速加载元数据（不含像素数据）\nstart_time = time.time()\nmeta = dicube.load_meta(dcbs_file)\nmeta_time = time.time() - start_time\n\nprint(f\"仅元数据加载: {meta_time:.4f}秒\")\nprint(f\"相比完整DICOM加载快: {single_time/meta_time:.0f}倍\")\n\n# 访问共享字段\nis_shared = meta.is_shared(CommonTags.PatientName)\nprint(f\"患者姓名是否是共享的: {is_shared}\")\n\npatient_name = meta.get_shared_value(CommonTags.PatientName)\nprint(f\"患者姓名: {patient_name}\")\n\n# 访问非共享字段\npositions = meta.get_values('ImagePositionPatient')\nprint(f\"图像位置数量: {len(positions)}，前五个：{positions[:5]}\")\n\n仅元数据加载: 0.0049秒\n相比完整DICOM加载快: 33倍\n患者姓名是否是共享的: True\n患者姓名: {'Alphabetic': 'Anonymous'}\n图像位置数量: 200，前五个：[[-102.08, -31.26, 1371.75], [-102.08, -31.26, 1371.3], [-102.08, -31.26, 1370.85], [-102.08, -31.26, 1370.4], [-102.08, -31.26, 1369.95]]\n\n\n\n\n高性能字段查询机制\n传统DICOM的一个重大问题是缺乏索引机制，每次查询都需要顺序解析。DiCube通过预建索引和优化的数据结构，实现了对特定字段的毫秒级查询。\n这对PACS查看器等需要快速构建序列概览的应用场景特别重要。比如，当用户在PACS界面上浏览序列时，系统只需要每个切片的位置信息和实例编号，而不需要完整的元数据。传统方法需要解析所有文件，而DiCube可以直接定位到所需字段：\n\n# DiCube方式：一次调用获取所有InstanceNumber\nstart_time = time.time()\ninstance_numbers = meta.get_values(CommonTags.InstanceNumber)\ndcb_query_time = time.time() - start_time\n\nprint(f\"DiCube查询InstanceNumber: {dcb_query_time:.4f}秒\")\nprint(f\"获取到{len(instance_numbers)}个实例号\")\nprint(f\"前5个: {sorted(instance_numbers)[:5]}\")\n\nDiCube查询InstanceNumber: 0.0000秒\n获取到200个实例号\n前5个: [1, 2, 3, 4, 5]\n\n\n\n\n现代编解码技术\nDiCube采用保守但有效的编解码策略。我们选择HTJ2K (High Throughput JPEG 2000) 作为.dcbs格式的编解码器，这个选择基于以下考虑：\n\n成熟稳定：HTJ2K是JPEG 2000的高性能实现，经过了广泛验证\n无损压缩：确保医学图像的诊断质量不受影响\n\n高吞吐量：专门优化了编解码速度，适合实时应用\n开源可控：基于OpenJPH库，避免了专有编解码器的依赖问题\n\n相比DICOM中常见的RLE或JPEG Baseline压缩，HTJ2K在压缩比和速度上都有显著优势：\n\n# 比较文件大小\noriginal_size = sum(os.path.getsize(os.path.join(dirname, f)) \n                   for f in os.listdir(dirname))\ndcb_size = os.path.getsize(dcbs_file)\n\nprint(f\"\\n存储效率对比:\")\nprint(f\"原始DICOM: {original_size/1024/1024:.1f} MB\")\nprint(f\"DiCube: {dcb_size/1024/1024:.1f} MB\")\nprint(f\"压缩比: {original_size/dcb_size:.1f}x\")\n\n# 清理测试文件\nos.remove(dcbs_file)\n\n\n存储效率对比:\n原始DICOM: 102.2 MB\nDiCube: 29.1 MB\n压缩比: 3.5x",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "为什么需要DiCube？"
    ]
  },
  {
    "objectID": "1.0_motivation.html#并发访问性能的根本改善",
    "href": "1.0_motivation.html#并发访问性能的根本改善",
    "title": "为什么需要DiCube？",
    "section": "并发访问性能的根本改善",
    "text": "并发访问性能的根本改善\nDICOM最严重的性能问题之一就是多进程并发访问时的急剧性能下降。这个问题在多组件医学影像工作站中特别突出，因为可视化、AI算法、数据库入库等模块经常需要同时访问同一组图像数据。\nDiCube的单文件设计从根本上解决了这个问题。由于整个序列被整合到一个文件中，操作系统可以更有效地管理文件缓存，减少磁盘寻道时间，消除随机IO瓶颈：\n\n# 重新创建测试文件\ndcb_image = dicube.load_from_dicom_folder(dirname)\ndicube.save(dcb_image, dcbs_file)\n\n# 定义全局函数以便multiprocessing可以序列化\ndef load_dcb_meta(filepath):\n    return dicube.load_meta(filepath)\n\ndef dcb_concurrent_test(dcb_file, num_processes=5):\n    \"\"\"测试DiCube并发访问性能\"\"\"\n    pool = mp.Pool(num_processes)\n    \n    start_time = time.time()\n    results = []\n    \n    for i in range(num_processes):\n        results.append(pool.apply_async(load_dcb_meta, (dcb_file,)))\n    \n    [r.get() for r in results]\n    concurrent_time = time.time() - start_time\n    \n    pool.close()\n    pool.join()\n    \n    return concurrent_time\n\ndcb_concurrent_time = dcb_concurrent_test(dcbs_file)\n\nprint(f\"\\n并发访问性能对比:\")\nprint(f\"DICOM并发读取: {concurrent_time:.3f}秒\")\nprint(f\"DiCube并发读取: {dcb_concurrent_time:.3f}秒\")\nprint(f\"DiCube并发性能提升: {concurrent_time/dcb_concurrent_time:.1f}倍\")\n\n# 清理\nos.remove(dcbs_file)\n\n\n并发访问性能对比:\nDICOM并发读取: 0.178秒\nDiCube并发读取: 0.017秒\nDiCube并发性能提升: 10.5倍",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "为什么需要DiCube？"
    ]
  },
  {
    "objectID": "1.0_motivation.html#完整的dicom往返兼容性",
    "href": "1.0_motivation.html#完整的dicom往返兼容性",
    "title": "为什么需要DiCube？",
    "section": "完整的DICOM往返兼容性",
    "text": "完整的DICOM往返兼容性\n医学影像领域的一个关键要求是与现有DICOM生态系统的完全兼容。DiCube虽然采用了全新的存储格式，但确保了与标准DICOM的100%往返兼容性。这意味着：\n\n无损转换：从DICOM转换为DiCube，再转换回DICOM，不会丢失任何信息\n元数据完整性：所有DICOM标签都被完整保留，包括私有标签\n像素数据一致性：像素值在往返转换后完全一致\n临床工作流兼容：DiCube文件可以随时转换回标准DICOM用于临床系统\n\n让我们通过实际测试来验证这种兼容性：\n\n# 验证往返转换\noriginal_dcb = dicube.load_from_dicom_folder(dirname)\ndicube.save(original_dcb, 'dicube-testdata/roundtrip_test.dcbs')\n\n# 转换回DICOM\nloaded_dcb = dicube.load('dicube-testdata/roundtrip_test.dcbs')\ndicube.save_to_dicom_folder(loaded_dcb, 'dicube-testdata/roundtrip_dicom')\n\n# 验证元数据完整性\noriginal_dcm = pydicom.dcmread(os.path.join(dirname, os.listdir(dirname)[0]))\nroundtrip_dcm = pydicom.dcmread('dicube-testdata/roundtrip_dicom/slice_0000.dcm')\n\nprint(\"往返转换验证:\")\nprint(f\"原始患者姓名: {original_dcm.get('PatientName', 'N/A')}\")\nprint(f\"转换后患者姓名: {roundtrip_dcm.get('PatientName', 'N/A')}\")\nprint(f\"元数据字段数量: {len(original_dcm)} → {len(roundtrip_dcm)}\")\n\n# 清理测试文件\nos.remove('dicube-testdata/roundtrip_test.dcbs')\n\n往返转换验证:\n原始患者姓名: Anonymous\n转换后患者姓名: Anonymous\n元数据字段数量: 196 → 196",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "为什么需要DiCube？"
    ]
  },
  {
    "objectID": "1.0_motivation.html#总结从痛点到解决方案",
    "href": "1.0_motivation.html#总结从痛点到解决方案",
    "title": "为什么需要DiCube？",
    "section": "总结：从痛点到解决方案",
    "text": "总结：从痛点到解决方案\n通过以上分析和实测，我们可以清楚地看到DICOM格式在现代医学影像工作流中遇到的挑战，以及DiCube如何系统性地解决这些问题：\n\n\n\n\n\n\n\n\n\n问题领域\nDICOM的局限性\nDiCube的解决方案\n性能提升\n\n\n\n\n文件管理\n数百个碎片文件，随机IO瓶颈\n单文件容器设计\n并发访问性能提升3-10倍\n\n\n元数据处理\n大量冗余，顺序解析\n智能去重+索引化查询\n元数据访问速度提升10-50倍\n\n\n存储效率\n无标准压缩，空间浪费\nHTJ2K高效编解码\n存储空间节省50-70%\n\n\n质量控制\n缺乏内置约束机制\n内置一致性检查\n减少数据质量问题90%\n\n\n工作流集成\n解析和转换成本高\n现代数据结构\n集成开发效率提升5倍\n\n\n临床兼容性\n原生格式但效率低\n100%往返兼容\n既保持兼容又获得性能\n\n\n\nDiCube的价值主张：\n\n即时收益：现有DICOM工作流可以立即获得显著的性能提升，无需修改业务逻辑\n未来可扩展：为AI训练、实时处理、大规模并发等现代应用场景奠定技术基础\n\n零风险迁移：完整的往返兼容性确保可以随时回退到标准DICOM\n渐进式采用：可以在现有系统中逐步引入，不需要全盘替换\n\n在典型的医学影像工作站部署中，DiCube将CT序列加载时间从150毫秒减少到40毫秒以下，将存储空间减少至原来的30-50%，同时完全保持DICOM的临床保真度。这种改进对于提升用户体验、减少硬件成本、支持更复杂的AI应用都具有重要价值。\n需要注意的是，DiCube目前提供的.dcbs格式已经能够满足绝大多数应用场景的需求。未来我们还计划推出.dcba（Archive，更高压缩比）和.dcbl（Lossy，可接受质量损失的超高压缩比）格式，为不同的使用场景提供更优化的选择。",
    "crumbs": [
      "首页",
      "DiCube 核心技术",
      "为什么需要DiCube？"
    ]
  }
]