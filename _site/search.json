[
  {
    "objectID": "1.0_motivation-en.html",
    "href": "1.0_motivation-en.html",
    "title": "Design Rationale and Motivation",
    "section": "",
    "text": "DICOM is the lingua franca of medical imaging. It unifies image format and enables interoperability across vendors and software. But its core design, born in the 1980s, did not anticipate today’s AI-, big‑data-, and high‑concurrency‑driven workflows.\nBuilding a next‑gen workstation that integrates AI, 3D visualization, and large‑scale data management, we found several DICOM design choices have become structural bottlenecks. This article outlines the challenges and introduces DiCube—a systematic redesign that remains 100% round‑trip compatible with the existing DICOM ecosystem.",
    "crumbs": [
      "首页",
      "DiCube",
      "Design Rationale and Motivation"
    ]
  },
  {
    "objectID": "1.0_motivation-en.html#introduction-classic-standard-modern-pressures",
    "href": "1.0_motivation-en.html#introduction-classic-standard-modern-pressures",
    "title": "Design Rationale and Motivation",
    "section": "",
    "text": "DICOM is the lingua franca of medical imaging. It unifies image format and enables interoperability across vendors and software. But its core design, born in the 1980s, did not anticipate today’s AI-, big‑data-, and high‑concurrency‑driven workflows.\nBuilding a next‑gen workstation that integrates AI, 3D visualization, and large‑scale data management, we found several DICOM design choices have become structural bottlenecks. This article outlines the challenges and introduces DiCube—a systematic redesign that remains 100% round‑trip compatible with the existing DICOM ecosystem.",
    "crumbs": [
      "首页",
      "DiCube",
      "Design Rationale and Motivation"
    ]
  },
  {
    "objectID": "1.0_motivation-en.html#four-core-challenges-in-modern-workflows",
    "href": "1.0_motivation-en.html#four-core-challenges-in-modern-workflows",
    "title": "Design Rationale and Motivation",
    "section": "Four Core Challenges in Modern Workflows",
    "text": "Four Core Challenges in Modern Workflows\n\n1. File Fragmentation: The Concurrency I/O Bottleneck\nTypical CT/MR series contain hundreds to thousands of individual .dcm files. Modern workstations need concurrent access (communication, 3D rendering, archiving, AI). Many small files under concurrency cause frequent random I/O and hammer performance. SSDs help, but for TB‑scale daily growth, HDDs remain the cost‑effective backbone; latency spikes as data turns cold.\n\n\n2. Redundant Metadata: Wasted Storage and Bandwidth\nMost per‑series metadata (patient, acquisition parameters, device model) is identical across slices, yet DICOM repeats it in every .dcm. A 500‑slice series replicates the same info 500 times—wasting storage and bandwidth. Worse, supposed‑to‑be‑shared fields may diverge across files, introducing downstream data‑quality risks.\n\n\n3. Missing Built‑in Constraints: Data Quality Uncertainty\nReal‑world DICOM often exhibits issues: missing files, empty/wrong tags, non‑contiguous or duplicate InstanceNumber, inconsistent pixel spacing, etc. Vendors add external QC modules to detect/patch. Tolerance varies by AI algorithm; universal QC rules are elusive, raising integration complexity and fragility.\n\n\n4. Sequential Parsing: Inefficient Metadata Access\nDICOM’s binary layout lacks a global index; parsers scan sequentially from the header to locate tags. Even to get a few fields like ImagePositionPatient or InstanceNumber, you must parse full metadata blocks for every file. Popular libraries (e.g., PyDICOM) often load full headers into memory—inefficient for batch AI or fast preview.",
    "crumbs": [
      "首页",
      "DiCube",
      "Design Rationale and Motivation"
    ]
  },
  {
    "objectID": "1.0_motivation-en.html#dicube-a-systemic-redesign-of-imaging-data",
    "href": "1.0_motivation-en.html#dicube-a-systemic-redesign-of-imaging-data",
    "title": "Design Rationale and Motivation",
    "section": "DiCube: A Systemic Redesign of Imaging Data",
    "text": "DiCube: A Systemic Redesign of Imaging Data\nDiCube is not an incremental tweak; it rethinks storage and access around modern workflows:\n\nUnified File Container: pack an image series into a single file to eliminate fragmentation.\nSmart Metadata: split shared vs per‑slice attributes and build efficient indices.\nModern Codecs: use HTJ2K, etc., for better compression and fast (de)coding.\n100% Round‑Trip: lossless conversion to/from standard DICOM.\n\n\nFrom Fragments to a Single File\nDiCube consolidates a DICOM series into one .dcbs (DiCube Binary Sequence) file—turning random I/O into efficient sequential I/O.\n\nimport dicube\nimport time\nimport os\n\ndicom_dir = 'dicube-testdata/dicom/sample_200'\ndcbs_file = 'dicube-testdata/test_sequence.dcbs'\n\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, dcbs_file)\n\n\n\nFrom Redundancy to Indexed Metadata\nDiCube separates metadata into:\n\nShared: e.g., patient ID, study date—stored once per .dcbs.\nPer‑slice: e.g., ImagePositionPatient—stored as compact arrays with indices.\n\nThis greatly reduces header size and enables millisecond‑level random access to specific fields.\n\nfrom dicube.dicom import CommonTags\n\nmeta = dicube.load_meta(dcbs_file)\n\npatient_name = meta.get_shared_value(CommonTags.PatientName)\nprint(f\"PatientName: {patient_name}\")\n\ninstance_numbers = meta.get_values(CommonTags.InstanceNumber)\nprint(f\"Loaded {len(instance_numbers)} InstanceNumber, first 5: {instance_numbers[:5]}\")",
    "crumbs": [
      "首页",
      "DiCube",
      "Design Rationale and Motivation"
    ]
  },
  {
    "objectID": "1.0_motivation-en.html#highconcurrency-benchmark-realistic-load",
    "href": "1.0_motivation-en.html#highconcurrency-benchmark-realistic-load",
    "title": "Design Rationale and Motivation",
    "section": "High‑Concurrency Benchmark: Realistic Load",
    "text": "High‑Concurrency Benchmark: Realistic Load\nWe measure DiCube under realistic concurrency:\n\nConcurrency: 10 processes\nWorkload: each handles 5 random series\nData: sample 50 series from a 1000‑series corpus to reduce cache bias\nScenarios:\n\nMetadata only (list/build views)\nMetadata + pixels (full load for 3D/AI)\n\n\n\nimport multiprocessing as mp\nimport random, time, os\nimport pydicom, dicube, numpy as np\n\ndicom_base_dir = '/data/manifest-NLST_allCT/sample_1000'\ndicube_base_dir = '/data/manifest-NLST_allCT/sample_1000_dcbs'\n\nnum_processes = 10\nseries_per_process = 5\ntotal_series_needed = num_processes * series_per_process\n\nall_dicom_dirs = [d for d in os.listdir(dicom_base_dir) if os.path.isdir(os.path.join(dicom_base_dir, d))]\nrandom.seed(time.time())\nselected_series_names = random.sample(all_dicom_dirs, total_series_needed)\nselected_dicom_paths = [os.path.join(dicom_base_dir, name) for name in selected_series_names]\nselected_dicube_paths = [os.path.join(dicube_base_dir, name + '.dcbs') for name in selected_series_names]\n\n\n1. Storage Footprint\n\ndef get_dir_size(path):\n    total = 0\n    with os.scandir(path) as it:\n        for entry in it:\n            if entry.is_file():\n                total += entry.stat().st_size\n    return total\n\ndicom_total_size = sum(get_dir_size(p) for p in selected_dicom_paths)\ndicube_total_size = sum(os.path.getsize(p) for p in selected_dicube_paths)\n\nprint(\"--- Space vs DICOM (50 series) ---\")\nprint(f\"DICOM:  {dicom_total_size / (1024**2):.2f} MB\")\nprint(f\"DiCube: {dicube_total_size / (1024**2):.2f} MB\")\nprint(f\"Saving: {(1 - dicube_total_size / dicom_total_size) * 100:.1f}%\")\n\n\n\n2. Concurrency Runtime\n\ndef read_dicom_series_meta_only(series_path):\n    files = [os.path.join(series_path, f) for f in os.listdir(series_path) if f.endswith('.dcm')]\n    for filepath in files:\n        pydicom.dcmread(filepath, stop_before_pixels=True)\n\ndef read_dicom_series_full(series_path):\n    dcm_series = [pydicom.dcmread(os.path.join(series_path, f)) for f in os.listdir(series_path) if f.endswith('.dcm')]\n    pixels = [ds.pixel_array for ds in dcm_series]\n    return (len(pixels), pixels[0].shape)\n\ndef read_dicube_meta_only(dcbs_path):\n    dicube.load_meta(dcbs_path)\n\ndef read_dicube_full(dcbs_path):\n    dcb_image = dicube.load(dcbs_path)\n    return dcb_image.raw_image.shape\n\ndef dicom_meta_worker(paths):\n    for path in paths:\n        read_dicom_series_meta_only(path)\n\ndef dicube_meta_worker(paths):\n    for path in paths:\n        read_dicube_meta_only(path)\n\ndef dicom_full_worker(paths):\n    for path in paths:\n        read_dicom_series_full(path)\n\ndef dicube_full_worker(paths):\n    for path in paths:\n        read_dicube_full(path)\n\ndef run_performance_test(paths, worker_function, num_processes, series_per_process):\n    tasks = [paths[i*series_per_process:(i+1)*series_per_process] for i in range(num_processes)]\n    pool = mp.Pool(processes=num_processes)\n    start_time = time.time()\n    pool.map(worker_function, tasks)\n    end_time = time.time()\n    pool.close(); pool.join()\n    return end_time - start_time\n\ndicom_meta_time  = run_performance_test(selected_dicom_paths,  dicom_meta_worker,  num_processes, series_per_process)\ndicube_meta_time = run_performance_test(selected_dicube_paths, dicube_meta_worker, num_processes, series_per_process)\ndicom_full_time  = run_performance_test(selected_dicom_paths,  dicom_full_worker,  num_processes, series_per_process)\ndicube_full_time = run_performance_test(selected_dicube_paths, dicube_full_worker, num_processes, series_per_process)\n\n\n\n3. Results and Notes\n\nprint(\"\\n--- Concurrency (10 procs × 5 series) ---\")\nprint(\"\\nMetadata only\")\nprint(f\"DICOM:  {dicom_meta_time:.2f}s\")\nprint(f\"DiCube: {dicube_meta_time:.2f}s\")\nprint(f\"Speedup: {dicom_meta_time / dicube_meta_time:.1f}×\")\n\nprint(\"\\nMetadata + Pixels\")\nprint(f\"DICOM:  {dicom_full_time:.2f}s\")\nprint(f\"DiCube: {dicube_full_time:.2f}s\")\nprint(f\"Speedup: {dicom_full_time / dicube_full_time:.1f}×\")\n\nDiCube avoids random I/O on many small files and redundant parsing, thus excels in metadata‑only scenarios. In full loads, single‑file sequential I/O and efficient compression also deliver strong gains. With higher concurrency, the gap typically widens. On HDD/object storage, the advantage can grow by orders of magnitude.",
    "crumbs": [
      "首页",
      "DiCube",
      "Design Rationale and Motivation"
    ]
  },
  {
    "objectID": "1.0_motivation-en.html#seamless-integration-100-dicom-roundtrip",
    "href": "1.0_motivation-en.html#seamless-integration-100-dicom-roundtrip",
    "title": "Design Rationale and Motivation",
    "section": "Seamless Integration: 100% DICOM Round‑Trip",
    "text": "Seamless Integration: 100% DICOM Round‑Trip\nDiCube guarantees lossless round‑trip to/from DICOM:\n\nLossless: pixels and metadata preserved across DICOM → DiCube → DICOM.\nMetadata integrity: all standard and private tags retained.\nWorkflow‑safe: export .dcbs to standard DICOM anytime for PACS/archive.\n\n\nimport shutil, os, pydicom, numpy as np\n\nroundtrip_dicom_dir = 'dicube-testdata/roundtrip_dicom'\ndicube.save_to_dicom_folder(dcb_image, roundtrip_dicom_dir)\n\noriginal_dcm = pydicom.dcmread(os.path.join(dicom_dir, os.listdir(dicom_dir)[0]))\nroundtrip_dcm = pydicom.dcmread(os.path.join(roundtrip_dicom_dir, 'slice_0000.dcm'))\n\nfields_to_check = ['PatientName','StudyInstanceUID','SeriesDescription','ImageOrientationPatient','PixelSpacing']\nfor tag in fields_to_check:\n    ov = original_dcm.get(tag, 'N/A')\n    rv = roundtrip_dcm.get(tag, 'N/A')\n    if isinstance(ov, (pydicom.multival.MultiValue, list)):\n        eq = np.allclose(np.array(ov, float), np.array(rv, float))\n    else:\n        eq = (ov == rv)\n    print(tag, '-&gt;', eq)\n\nos.remove(dcbs_file); shutil.rmtree(roundtrip_dicom_dir)",
    "crumbs": [
      "首页",
      "DiCube",
      "Design Rationale and Motivation"
    ]
  },
  {
    "objectID": "1.0_motivation-en.html#summary-from-bottleneck-to-enabler",
    "href": "1.0_motivation-en.html#summary-from-bottleneck-to-enabler",
    "title": "Design Rationale and Motivation",
    "section": "Summary: From Bottleneck to Enabler",
    "text": "Summary: From Bottleneck to Enabler\n\n\n\n\n\n\n\n\n\nArea\nDICOM Limitation\nDiCube Solution\nGain\n\n\n\n\nFile mgmt\nMany small files; I/O bottleneck\nSingle‑file container\n3–10× concurrency\n\n\nMetadata\nRedundant; sequential parsing\nDedup + indexed queries\n10–50× access\n\n\nStorage\nNo efficient standard compression\nHTJ2K integrated\n50–70% space\n\n\nIntegration\nComplex parsing/transform logic\nModern APIs and data structures\nFaster dev\n\n\n\nKey values:\n\nImmediate performance gains without changing business logic.\nStrong data foundation for AI training, real‑time analysis, and high concurrency.\nZero‑risk migration path via lossless round‑trip with DICOM.\n\nIntroduce DiCube as a high‑performance intermediate format and focus engineering effort on product logic—not fighting low‑level I/O and headers.",
    "crumbs": [
      "首页",
      "DiCube",
      "Design Rationale and Motivation"
    ]
  },
  {
    "objectID": "2.0_mask-en.html",
    "href": "2.0_mask-en.html",
    "title": "Segmentation Mask Pain Points",
    "section": "",
    "text": "DiCube solved raw DICOM storage; this chapter focuses on segmentation masks. Blocking issues in today’s mask formats (.npz, .nii.gz) include missing spatial context, decentralized semantics, inefficient compression, and poor handling of overlapping vs mutually exclusive structures.",
    "crumbs": [
      "首页",
      "MedMask",
      "Segmentation Mask Pain Points"
    ]
  },
  {
    "objectID": "2.0_mask-en.html#challenge-1-missing-inconsistent-spatial-reference",
    "href": "2.0_mask-en.html#challenge-1-missing-inconsistent-spatial-reference",
    "title": "Segmentation Mask Pain Points",
    "section": "Challenge 1: Missing / Inconsistent Spatial Reference",
    "text": "Challenge 1: Missing / Inconsistent Spatial Reference\n\nNPZ: stores pure arrays with no origin/spacing/orientation. A sparse lesion mask still needs a full‑size array and cannot auto‑align back to the source image.\nNIfTI: carries space info but often interpreted in RAS+, conflicting with DICOM’s LPS+. Extra transforms are required, risking mistakes and cognitive overhead.",
    "crumbs": [
      "首页",
      "MedMask",
      "Segmentation Mask Pain Points"
    ]
  },
  {
    "objectID": "2.0_mask-en.html#challenge-2-external-semantic-management",
    "href": "2.0_mask-en.html#challenge-2-external-semantic-management",
    "title": "Segmentation Mask Pain Points",
    "section": "Challenge 2: External Semantic Management",
    "text": "Challenge 2: External Semantic Management\nMasks must map pixel values to organ/lesion names. Existing workflows rely on external configs or filenames.\n\norgan_mapping = {\n    1: \"liver\",\n    2: \"kidney_left\",\n    3: \"kidney_right\",\n    4: \"spleen\",\n}\n\nIssues: - Non self‑describing data - Hard to sync across teams (annotation/ML/UI) - Painful versioning when labels change",
    "crumbs": [
      "首页",
      "MedMask",
      "Segmentation Mask Pain Points"
    ]
  },
  {
    "objectID": "2.0_mask-en.html#challenge-3-inefficient-compression-for-sparse-data",
    "href": "2.0_mask-en.html#challenge-3-inefficient-compression-for-sparse-data",
    "title": "Segmentation Mask Pain Points",
    "section": "Challenge 3: Inefficient Compression For Sparse Data",
    "text": "Challenge 3: Inefficient Compression For Sparse Data\n\n99% of voxels are background. Generic codecs (gzip/DEFLATE) do not exploit sparsity or spatial continuity. Files remain large and slow to transmit.",
    "crumbs": [
      "首页",
      "MedMask",
      "Segmentation Mask Pain Points"
    ]
  },
  {
    "objectID": "2.0_mask-en.html#challenge-4-overlap-vs-exclusivity",
    "href": "2.0_mask-en.html#challenge-4-overlap-vs-exclusivity",
    "title": "Segmentation Mask Pain Points",
    "section": "Challenge 4: Overlap vs Exclusivity",
    "text": "Challenge 4: Overlap vs Exclusivity\nClinical masks often mix:\n\nLobes (5 mutually exclusive labels)\nSegments (18 mutually exclusive but overlap lobes)\nLesions (N labels overlapping everything)\nWhole lung (1 label overlapping all)\n\n\nMethod 1: Value‑Based Mask\nSingle uint8 array, one label per voxel.\n\nimport numpy as np\nlung_lobe_mask = np.zeros((64,256,256), dtype=np.uint8)\nlung_lobe_mask[10:30, 50:150, 60:160] = 1  # Left upper lobe\nlung_lobe_mask[30:50, 50:150, 60:160] = 2  # Left lower lobe\nprint(\"Labels:\", np.unique(lung_lobe_mask))\n\nPros: compact. Cons: cannot represent overlaps.\n\n\nMethod 2: Bitmask\nTreat each bit as a label.\n\nbit_mask = np.zeros((64,256,256), dtype=np.uint8)\nleft_upper = np.zeros_like(bit_mask); left_upper[10:30, 50:150, 60:160] = 1\nbit_mask |= (left_upper &lt;&lt; 0)\nlesion = np.zeros_like(bit_mask); lesion[15:35, 60:140, 70:150] = 1\nbit_mask |= (lesion &lt;&lt; 2)\nprint(\"Max overlapping labels:\", bit_mask.dtype.itemsize * 8)\n\nPros: supports overlap. Cons: limited to number of bits (8 for uint8, 64 for uint64). Not scalable for &gt;100 structures.\n\n\nReal‑World Impact\nResulting workaround: store each organ as a separate file (*.nii.gz). A whole‑body case may contain dozens of files—fragmented and hard to manage.\n\nfrom pathlib import Path\nmask_dir = 'dicube-testdata/mask/s0000'\nmask_files = list(Path(mask_dir).glob('*.nii.gz'))\nprint(\"Files per study:\", len(mask_files))\nprint(\"Total size (MB):\", sum(f.stat().st_size for f in mask_files)/1024/1024)",
    "crumbs": [
      "首页",
      "MedMask",
      "Segmentation Mask Pain Points"
    ]
  },
  {
    "objectID": "2.0_mask-en.html#summary",
    "href": "2.0_mask-en.html#summary",
    "title": "Segmentation Mask Pain Points",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\nChallenge\nSymptom\nImpact\n\n\n\n\nSpatial reference\nNPZ: none; NIfTI: RAS+/LPS+ mismatch\nAdded complexity and risk\n\n\nSemantics\nExternal configs / filenames\nPoor self‑consistency; versioning burden\n\n\nCompression\nGeneric codecs ignore sparsity\nLarge storage + slow transfer\n\n\nOverlap vs exclusivity\nArrays can’t encode both simultaneously\nForces many files / fragile management",
    "crumbs": [
      "首页",
      "MedMask",
      "Segmentation Mask Pain Points"
    ]
  },
  {
    "objectID": "2.1_mask_compression-en.html",
    "href": "2.1_mask_compression-en.html",
    "title": "Efficient Compression",
    "section": "",
    "text": "Segmentation masks are highly sparse. We benchmark MedMask vs NIfTI (.nii.gz) and NumPy (.npz) for binary and multi-label masks, and explain why MedMask’s PackBits + Zstandard pipeline excels.",
    "crumbs": [
      "首页",
      "MedMask",
      "Efficient Compression"
    ]
  },
  {
    "objectID": "2.1_mask_compression-en.html#summary",
    "href": "2.1_mask_compression-en.html#summary",
    "title": "Efficient Compression",
    "section": "",
    "text": "Segmentation masks are highly sparse. We benchmark MedMask vs NIfTI (.nii.gz) and NumPy (.npz) for binary and multi-label masks, and explain why MedMask’s PackBits + Zstandard pipeline excels.",
    "crumbs": [
      "首页",
      "MedMask",
      "Efficient Compression"
    ]
  },
  {
    "objectID": "2.1_mask_compression-en.html#unified-benchmark-harness",
    "href": "2.1_mask_compression-en.html#unified-benchmark-harness",
    "title": "Efficient Compression",
    "section": "1. Unified Benchmark Harness",
    "text": "1. Unified Benchmark Harness\n\nimport os, time, gzip, tempfile\nimport numpy as np, nibabel as nib, pandas as pd\nimport zstandard as zstd\nfrom pathlib import Path\nfrom medmask import SegmentationMask\nfrom spacetransformer import Space\n\nmask_dir = Path('dicube-testdata/mask/s0000')\nwith open(mask_dir / 'nonzero_masks.txt') as f:\n    valid_files = [line.strip() for line in f]\nprint(f\"Loaded {len(valid_files)} masks\")\n\ndef run_benchmark(format_type, data, space=None, label_mapping=None, original_path=None):\n    stats = {'size': 0, 'encode_time': 0, 'decode_time': 0}\n    with tempfile.TemporaryDirectory() as tmpdir:\n        tmp_path = Path(tmpdir) / f\"tempfile.{format_type.split('_')[0]}\"\n        start = time.time()\n        if format_type == 'nifti':\n            if original_path:\n                stats['size'] = original_path.stat().st_size\n            else:\n                affine = np.eye(4)\n                nib.save(nib.Nifti1Image(data.astype(np.uint8), affine), tmp_path.with_suffix('.nii.gz'))\n                stats['size'] = tmp_path.with_suffix('.nii.gz').stat().st_size\n        elif format_type == 'npz':\n            np.savez_compressed(tmp_path, mask=data)\n            stats['size'] = tmp_path.stat().st_size\n        elif format_type == 'medmask':\n            SegmentationMask(data, label_mapping, space=space).save(tmp_path)\n            stats['size'] = tmp_path.stat().st_size\n        stats['encode_time'] = (time.time()-start)*1000\n\n        if stats['size'] &gt; 0:\n            start = time.time()\n            if format_type == 'npz':\n                _ = np.load(tmp_path)['mask']\n            elif format_type == 'medmask':\n                loaded = SegmentationMask.load(tmp_path)\n                if label_mapping:\n                    for name in label_mapping:\n                        _ = loaded.get_binary_mask_by_names(name)\n            stats['decode_time'] = (time.time()-start)*1000\n    return stats",
    "crumbs": [
      "首页",
      "MedMask",
      "Efficient Compression"
    ]
  },
  {
    "objectID": "2.1_mask_compression-en.html#binary-masks",
    "href": "2.1_mask_compression-en.html#binary-masks",
    "title": "Efficient Compression",
    "section": "2. Binary Masks",
    "text": "2. Binary Masks\n\nbinary_files = [\n    'gluteus_maximus_right.nii.gz',\n    'urinary_bladder.nii.gz',\n    'colon.nii.gz',\n    'iliopsoas_left.nii.gz',\n    'iliac_artery_left.nii.gz',\n    'small_bowel.nii.gz'\n]\n\nrows = []\nfor fname in binary_files:\n    original_path = mask_dir / fname\n    nii = nib.load(original_path)\n    data = nii.get_fdata().astype(np.uint8)\n    space = Space.from_nifti(nii)\n    organ = fname.replace('.nii.gz', '')\n\n    stats_nifti = run_benchmark('nifti', data=data, original_path=original_path)\n    stats_npz = run_benchmark('npz', data=data)\n    stats_medmask = run_benchmark('medmask', data=data, space=space, label_mapping={organ:1})\n\n    rows.append({\n        'Mask': organ,\n        'Nonzero': int(np.count_nonzero(data)),\n        'NIfTI (KB)': stats_nifti['size']/1024,\n        'NPZ (KB)': stats_npz['size']/1024,\n        'MedMask (KB)': stats_medmask['size']/1024,\n        'NPZ encode (ms)': stats_npz['encode_time'],\n        'MedMask encode (ms)': stats_medmask['encode_time'],\n        'NPZ decode (ms)': stats_npz['decode_time'],\n        'MedMask decode (ms)': stats_medmask['decode_time']\n    })\n\ndf_binary = pd.DataFrame(rows)\nif not df_binary.empty:\n    avg = df_binary.select_dtypes(include=np.number).mean()\n    avg['Mask'] = 'Average'\n    df_binary = pd.concat([df_binary, avg.to_frame().T], ignore_index=True)\n\ndf_binary['MedMask vs NIfTI'] = df_binary['NIfTI (KB)'] / df_binary['MedMask (KB)']\ndf_binary['NPZ vs NIfTI'] = df_binary['NIfTI (KB)'] / df_binary['NPZ (KB)']\n\ndisplay(df_binary.style.format({\n    'NIfTI (KB)': '{:.1f}', 'NPZ (KB)': '{:.1f}', 'MedMask (KB)': '{:.1f}',\n    'NPZ encode (ms)': '{:.1f}', 'MedMask encode (ms)': '{:.1f}',\n    'NPZ decode (ms)': '{:.1f}', 'MedMask decode (ms)': '{:.1f}',\n    'MedMask vs NIfTI': '{:.1f}×', 'NPZ vs NIfTI': '{:.1f}×',\n    'Nonzero': '{:,}'\n}).hide(axis='index'))\n\nMedMask dramatically shrinks sparse masks and matches NPZ timings.",
    "crumbs": [
      "首页",
      "MedMask",
      "Efficient Compression"
    ]
  },
  {
    "objectID": "2.1_mask_compression-en.html#multi-label-masks",
    "href": "2.1_mask_compression-en.html#multi-label-masks",
    "title": "Efficient Compression",
    "section": "3. Multi-Label Masks",
    "text": "3. Multi-Label Masks\n\ntest_groups = [\n    {'name': 'Gluteus muscles', 'files': ['gluteus_maximus_left.nii.gz','gluteus_maximus_right.nii.gz','gluteus_medius_left.nii.gz','gluteus_medius_right.nii.gz']},\n    {'name': 'Femur + Hip', 'files': ['femur_left.nii.gz','femur_right.nii.gz','hip_left.nii.gz','hip_right.nii.gz']},\n    {'name': 'Pelvic organs', 'files': ['urinary_bladder.nii.gz','colon.nii.gz','small_bowel.nii.gz']}\n]\n\nresults = []\nfor group in test_groups:\n    first_img = nib.load(mask_dir / group['files'][0])\n    space = Space.from_nifti(first_img)\n    multi = np.zeros(first_img.shape, dtype=np.uint8)\n    mapping = {}\n\n    for idx, fname in enumerate(group['files'], start=1):\n        fpath = mask_dir / fname\n        if not fpath.exists():\n            continue\n        data = nib.load(fpath).get_fdata().astype(np.uint8)\n        multi[data &gt; 0] = idx\n        mapping[fname.replace('.nii.gz','')] = idx\n\n    stats_nifti = run_benchmark('nifti', data=multi, space=space)\n    stats_npz = run_benchmark('npz', data=multi)\n    stats_medmask = run_benchmark('medmask', data=multi, space=space, label_mapping=mapping)\n\n    results.append({\n        'Group': group['name'],\n        'Labels': len(group['files']),\n        'NIfTI (KB)': stats_nifti['size']/1024,\n        'NPZ (KB)': stats_npz['size']/1024,\n        'MedMask (KB)': stats_medmask['size']/1024,\n        'NPZ encode (ms)': stats_npz['encode_time'],\n        'MedMask encode (ms)': stats_medmask['encode_time'],\n        'NPZ decode (ms)': stats_npz['decode_time'],\n        'MedMask decode (ms)': stats_medmask['decode_time']\n    })\n\ndf_multi = pd.DataFrame(results)\nif not df_multi.empty:\n    avg = df_multi.select_dtypes(include=np.number).mean()\n    avg['Group'] = 'Average'\n    df_multi = pd.concat([df_multi, avg.to_frame().T], ignore_index=True)\n\ndf_multi['MedMask vs NIfTI'] = df_multi['NIfTI (KB)'] / df_multi['MedMask (KB)']\ndf_multi['NPZ vs NIfTI'] = df_multi['NIfTI (KB)'] / df_multi['NPZ (KB)']\n\ndisplay(df_multi.style.format({\n    'NIfTI (KB)': '{:.1f}', 'NPZ (KB)': '{:.1f}', 'MedMask (KB)': '{:.1f}',\n    'NPZ encode (ms)': '{:.1f}', 'MedMask encode (ms)': '{:.1f}',\n    'NPZ decode (ms)': '{:.1f}', 'MedMask decode (ms)': '{:.1f}',\n    'MedMask vs NIfTI': '{:.1f}×', 'NPZ vs NIfTI': '{:.1f}×'\n}).hide(axis='index'))\n\nMedMask stays smaller even when storing many labels together.",
    "crumbs": [
      "首页",
      "MedMask",
      "Efficient Compression"
    ]
  },
  {
    "objectID": "2.1_mask_compression-en.html#packbits-zstandard",
    "href": "2.1_mask_compression-en.html#packbits-zstandard",
    "title": "Efficient Compression",
    "section": "4. PackBits + Zstandard",
    "text": "4. PackBits + Zstandard\nBinary masks benefit from bit packing before Zstd compression.\n\nmask_path = mask_dir / 'urinary_bladder.nii.gz'\nimg = nib.load(mask_path)\ndata = img.get_fdata()&gt;0\nraw = data.tobytes()\npackbits = np.packbits(data).tobytes()\n\nraw_size = len(raw)\npackbits_size = len(packbits)\n\ngzip_size = len(gzip.compress(raw))\nzstd_size = len(zstd.ZstdCompressor().compress(raw))\ncombo_size = len(zstd.ZstdCompressor().compress(packbits))\n\nprint(\"Raw (KB):\", raw_size/1024)\nprint(\"PackBits (KB):\", packbits_size/1024)\nprint(\"Gzip (KB):\", gzip_size/1024)\nprint(\"Zstd (KB):\", zstd_size/1024)\nprint(\"PackBits + Zstd (KB):\", combo_size/1024)\n\nPackBits removes the structural waste of storing booleans in bytes (~8× reduction). Zstd then compresses the compact stream further.",
    "crumbs": [
      "首页",
      "MedMask",
      "Efficient Compression"
    ]
  },
  {
    "objectID": "2.1_mask_compression-en.html#conclusion",
    "href": "2.1_mask_compression-en.html#conclusion",
    "title": "Efficient Compression",
    "section": "Conclusion",
    "text": "Conclusion\n\nBinary masks: PackBits preprocessing + Zstd delivers dramatic size reduction with comparable speed\nMulti-label masks: Zstd alone still beats gzip/NPZ\nMedMask adapts per mask type, yielding strong compression with fast encode/decode for clinical pipelines",
    "crumbs": [
      "首页",
      "MedMask",
      "Efficient Compression"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation.html",
    "href": "3.0_spacetransformer_motivation.html",
    "title": "空间变换库对比与动机",
    "section": "",
    "text": "结论：常见库在“裁剪 ROI → 重采样 → 分析 → 回传”的标准流程中，易出现坐标偏移、配置冗余与轴序混乱；SpaceTransformer 以声明式空间定义与统一变换接口，显著降低实现复杂度并保持精度。\n在医学图像分析流水线中，空间变换是一个核心且不可避免的环节。典型的工作流程包括：提取感兴趣区域（ROI）、重采样到标准尺寸、执行AI分析、将结果精确映射回原始图像空间。这一流程看似简单，但在实际实现中却充满了技术陷阱。\n本文通过一个具体对比实验，展示主流库在该流程中的问题，并介绍 SpaceTransformer 如何以统一设计解决这些挑战。",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "空间变换库对比与动机"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation.html#引言空间变换的普遍需求与实现困境",
    "href": "3.0_spacetransformer_motivation.html#引言空间变换的普遍需求与实现困境",
    "title": "空间变换库对比与动机",
    "section": "",
    "text": "结论：常见库在“裁剪 ROI → 重采样 → 分析 → 回传”的标准流程中，易出现坐标偏移、配置冗余与轴序混乱；SpaceTransformer 以声明式空间定义与统一变换接口，显著降低实现复杂度并保持精度。\n在医学图像分析流水线中，空间变换是一个核心且不可避免的环节。典型的工作流程包括：提取感兴趣区域（ROI）、重采样到标准尺寸、执行AI分析、将结果精确映射回原始图像空间。这一流程看似简单，但在实际实现中却充满了技术陷阱。\n本文通过一个具体对比实验，展示主流库在该流程中的问题，并介绍 SpaceTransformer 如何以统一设计解决这些挑战。",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "空间变换库对比与动机"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation.html#测试场景设计",
    "href": "3.0_spacetransformer_motivation.html#测试场景设计",
    "title": "空间变换库对比与动机",
    "section": "测试场景设计",
    "text": "测试场景设计\n为了客观评估不同库的表现，我们设计了一个简化但具有代表性的测试场景：\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef create_test_image():\n    \"\"\"\n    创建测试图像：35×35 背景 + 9×9 中心正方形 + 中心关键点\n    这个设计模拟了医学图像中的典型结构：器官边界 + 内部标志点\n    \"\"\"\n    img = np.zeros((35, 35), dtype=np.float32)\n    \n    # 9x9正方形物体（模拟器官）\n    center = 35 // 2\n    half_size = 4  # 9x9的一半\n    img[center-half_size:center+half_size+1, center-half_size:center+half_size+1] = 1.0\n    \n    # 中心关键点（模拟需要定位的解剖标志）\n    img[center, center] = 5\n    \n    return img\n\ndef get_segmentation(img, threshold=0.5):\n    \"\"\"提取分割掩膜\"\"\"\n    return (img &gt;= threshold).astype(np.uint8)\n\ndef get_keypoint(img):\n    \"\"\"检测关键点：输出(x,y)格式的2D点\"\"\"\n    candidates = np.array(np.where(img &gt;= 3))\n    if candidates.size &gt; 0:\n        # 返回(y,x)格式的点坐标\n        center_y = candidates[0].mean()\n        center_x = candidates[1].mean()\n        return np.array([center_y, center_x])\n    else:\n        return np.array([0.0, 0.0])\n\n# === 全局参数配置 ===\n# ROI 提取参数（偏移的 bbox，模拟实际检测中的偏移）\nROI_START_Y = 10\nROI_START_X = 10\nROI_SIZE = 15\nROI_END_Y = ROI_START_Y + ROI_SIZE  # 25\nROI_END_X = ROI_START_X + ROI_SIZE  # 25\n\n# 重采样目标尺寸\nTARGET_SIZE = 32\n\n# 创建测试数据\noriginal_img = create_test_image()\noriginal_shape = original_img.shape\n\nprint(f\"原始图像尺寸: {original_shape}\")\nprint(f\"目标物体覆盖范围: {np.argwhere(original_img &gt; 0.5).min(axis=0)} 到 {np.argwhere(original_img &gt; 0.5).max(axis=0)}\")\nprint(f\"ROI区域: ({ROI_START_Y}:{ROI_END_Y}, {ROI_START_X}:{ROI_END_X})\")\nprint(f\"目标尺寸: {TARGET_SIZE}x{TARGET_SIZE}\")\n\n# 计算真实关键点位置（理论值）\ntrue_keypoint = np.array([17, 17])  # 35x35图像的中心 (y, x)\n\ndef plot_result(original_img, segment_result, keypoint_result, method_name, true_keypoint):\n    \"\"\"统一的结果绘制函数\"\"\"\n    plt.figure(figsize=(8, 6))\n    plt.imshow(original_img, cmap='gray', alpha=0.7)\n    if segment_result is not None:\n        plt.contour(segment_result, levels=[0.5], colors='red', linewidths=2)\n    \n    # 显示检测到的关键点\n    if keypoint_result is not None and len(keypoint_result) &gt; 0:\n        if keypoint_result.ndim == 1:  # SpaceTransformer返回的是1D数组\n            plt.plot(keypoint_result[1], keypoint_result[0], 'ro', markersize=8, label='Detected Point')\n        else:  # 其他方法可能返回2D数组\n            plt.plot(keypoint_result[0, 1], keypoint_result[0, 0], 'ro', markersize=8, label='Detected Point')\n    \n    # 显示真实关键点\n    plt.plot(true_keypoint[1], true_keypoint[0], 'g+', markersize=12, \n           markeredgewidth=3, label='Ground Truth')\n    \n    plt.title(f'{method_name} Result')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    # 计算坐标误差\n    if keypoint_result is not None and len(keypoint_result) &gt; 0:\n        if keypoint_result.ndim == 1:\n            error = np.linalg.norm(keypoint_result - true_keypoint)\n        else:\n            error = np.linalg.norm(keypoint_result[0] - true_keypoint)\n        plt.text(0.02, 0.98, f'Error: {error:.3f} pixels', transform=plt.gca().transAxes, \n                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), verticalalignment='top')\n    \n    plt.tight_layout()\n    plt.show()\n\nplt.figure(figsize=(6, 5))\nplt.imshow(original_img, cmap='gray')\nplt.title('Test Image: 35×35 Background + 9×9 Square + Center Keypoint')\nplt.colorbar()\nplt.show()",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "空间变换库对比与动机"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation.html#测试流水线定义",
    "href": "3.0_spacetransformer_motivation.html#测试流水线定义",
    "title": "空间变换库对比与动机",
    "section": "测试流水线定义",
    "text": "测试流水线定义\n我们将实现以下标准的医学图像处理流水线：\n\nROI 提取：从 35×35 图像中提取 15×15 中心区域\n重采样：将 15×15 区域缩放到 32×32\n分析处理：执行分割与关键点检测\n结果回传：将 32×32 空间结果精确映射回 35×35 原始空间\n\n每个库的实现将被评估其代码复杂度、参数管理难度以及坐标变换的准确性。",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "空间变换库对比与动机"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation.html#方法一simpleitk-实现",
    "href": "3.0_spacetransformer_motivation.html#方法一simpleitk-实现",
    "title": "空间变换库对比与动机",
    "section": "方法一：SimpleITK 实现",
    "text": "方法一：SimpleITK 实现\nSimpleITK是医学图像处理的标准库，提供了完整的ITK功能接口。\n\nimport SimpleITK as sitk\n\ndef process_with_simpleitk(img):\n    \"\"\"使用 SimpleITK 实现完整流水线\"\"\"\n    \n    # 转换为 SimpleITK 图像\n    sitk_img = sitk.GetImageFromArray(img)\n    sitk_img.SetSpacing([1.0, 1.0])\n    sitk_img.SetOrigin([0.0, 0.0])\n    \n    # 步骤 1：ROI 提取（使用全局参数）\n    original_size = sitk_img.GetSize()\n    roi_size = [ROI_SIZE, ROI_SIZE] \n    roi_start = [ROI_START_X, ROI_START_Y]  # 注意 SimpleITK 使用 (X,Y) 顺序\n    \n    roi_img = sitk.RegionOfInterest(sitk_img, roi_size, roi_start)\n    \n    # 步骤 2：重采样到目标尺寸\n    target_size = [TARGET_SIZE, TARGET_SIZE]\n    \n    # 计算新的spacing以保持物理尺寸\n    original_spacing = roi_img.GetSpacing()\n    physical_size = [roi_size[i] * original_spacing[i] for i in range(2)]\n    target_spacing = [physical_size[i] / target_size[i] for i in range(2)]\n    \n    # 配置重采样器\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetOutputSpacing(target_spacing)\n    resampler.SetSize(target_size)\n    resampler.SetOutputOrigin(roi_img.GetOrigin())\n    resampler.SetOutputDirection(roi_img.GetDirection())\n    resampler.SetInterpolator(sitk.sitkLinear)\n    resampler.SetDefaultPixelValue(0)\n    \n    resampled_img = resampler.Execute(roi_img)\n    resampled_array = sitk.GetArrayFromImage(resampled_img)\n    \n    # 步骤 3：分析处理\n    segment_result = get_segmentation(resampled_array)\n    keypoint_result = get_keypoint(resampled_array)\n    \n    # 步骤 4：结果回传 - 这里是 SimpleITK 的复杂之处\n    # 需要手动计算多个坐标变换\n    \n    # 4a: 从目标尺寸回到ROI空间\n    scale_factor = np.array(roi_size) / np.array(target_size)\n    keypoint_in_roi = keypoint_result * scale_factor\n    \n    # 4b: 从ROI空间回到原始空间\n    keypoint_in_original = keypoint_in_roi + np.array([roi_start[1], roi_start[0]])\n    \n    # 分割结果回传需要再次重采样\n    segment_sitk = sitk.GetImageFromArray(segment_result.astype(np.float32))\n    segment_sitk.SetSpacing(target_spacing)\n    segment_sitk.SetOrigin(resampled_img.GetOrigin())\n    \n    # 重采样回 ROI 尺寸\n    back_resampler = sitk.ResampleImageFilter()\n    back_resampler.SetOutputSpacing(original_spacing)\n    back_resampler.SetSize(roi_size)\n    back_resampler.SetOutputOrigin(roi_img.GetOrigin())\n    back_resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n    back_resampler.SetDefaultPixelValue(0)\n    \n    segment_roi = back_resampler.Execute(segment_sitk)\n    segment_roi_array = sitk.GetArrayFromImage(segment_roi)\n    \n    # 将ROI结果放回原始图像\n    segment_original = np.zeros(original_shape, dtype=np.uint8)\n    segment_original[roi_start[1]:roi_start[1]+roi_size[1], \n                    roi_start[0]:roi_start[0]+roi_size[0]] = segment_roi_array\n    \n    return segment_original, keypoint_in_original\n\nprint(\"=== SimpleITK实现 ===\")\nsitk_segment, sitk_keypoint = process_with_simpleitk(original_img)\nprint(f\"检测到的关键点坐标: {sitk_keypoint}\")\nprint(f\"分割区域像素数: {np.sum(sitk_segment)}\")\n\n# 立即显示 SimpleITK 结果\nplot_result(original_img, sitk_segment, sitk_keypoint, \"SimpleITK\", true_keypoint)\n\nSimpleITK 的问题分析：\n\n重采样配置冗长：每次重采样都需要配置多个参数\n代码可读性差：业务逻辑被大量底层配置代码掩盖\n轴序问题：这张图xy对称，所以体现不出来，但实际上很容易出现轴序错误",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "空间变换库对比与动机"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation.html#方法二scipy.ndimage-实现",
    "href": "3.0_spacetransformer_motivation.html#方法二scipy.ndimage-实现",
    "title": "空间变换库对比与动机",
    "section": "方法二：scipy.ndimage 实现",
    "text": "方法二：scipy.ndimage 实现\nscipy.ndimage是通用的N维图像处理库，在科学计算社区广泛使用。\n\nfrom scipy import ndimage\nfrom scipy.ndimage import zoom\n\ndef process_with_scipy(img):\n    \"\"\"使用 scipy.ndimage 实现流水线\"\"\"\n    \n    # 步骤 1：ROI 提取（使用全局参数）\n    h, w = img.shape\n    roi_img = img[ROI_START_Y:ROI_END_Y, ROI_START_X:ROI_END_X]\n    \n    # 步骤 2：重采样到目标尺寸\n    zoom_factor = TARGET_SIZE / ROI_SIZE\n    \n    # 注意：scipy的zoom函数坐标处理容易出错\n    resampled_img = zoom(roi_img, zoom_factor, order=1, mode='constant', cval=0)\n    \n    # 步骤 3：分析处理\n    segment_result = get_segmentation(resampled_img)\n    keypoint_result = get_keypoint(resampled_img)\n    \n    # 步骤 4：结果回传\n    # 4a: 关键点坐标变换\n    keypoint_in_roi = keypoint_result / zoom_factor\n    keypoint_in_original = keypoint_in_roi + [ROI_START_Y, ROI_START_X]\n    \n    # 4b: 分割结果回传\n    # zoom函数的逆变换参数计算容易出错\n    segment_roi = zoom(segment_result.astype(np.float32), \n                      1.0 / zoom_factor, order=0, mode='constant', cval=0)\n        \n    # 放回原始图像\n    segment_original = np.zeros_like(img, dtype=np.uint8)\n    segment_original[ROI_START_Y:ROI_END_Y, ROI_START_X:ROI_END_X] = segment_roi\n    \n    return segment_original, keypoint_in_original\n\nprint(\"=== scipy.ndimage实现 ===\")\nscipy_segment, scipy_keypoint = process_with_scipy(original_img)\nprint(f\"检测到的关键点坐标: {scipy_keypoint}\")\nprint(f\"分割区域像素数: {np.sum(scipy_segment)}\")\n\n# 立即显示 scipy.ndimage 结果\nplot_result(original_img, scipy_segment, scipy_keypoint, \"scipy.ndimage\", true_keypoint)\n\nscipy.ndimage 的问题分析： - zoom函数：逆变换时尺寸计算容易出现舍入误差",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "空间变换库对比与动机"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation.html#方法三pytorch-interpolate-实现",
    "href": "3.0_spacetransformer_motivation.html#方法三pytorch-interpolate-实现",
    "title": "空间变换库对比与动机",
    "section": "方法三：PyTorch interpolate 实现",
    "text": "方法三：PyTorch interpolate 实现\nPyTorch的functional.interpolate是深度学习中最常用的图像变换工具。\n\nimport torch\nimport torch.nn.functional as F\n\ndef process_with_pytorch(img):\n    \"\"\"使用 PyTorch interpolate 实现流水线\"\"\"\n    \n    # 转换为 PyTorch 张量（需要添加 batch 与 channel 维度）\n    tensor_img = torch.from_numpy(img).unsqueeze(0).unsqueeze(0).float()\n    \n    # 步骤 1：ROI 提取（使用全局参数）\n    h, w = img.shape\n    roi_tensor = tensor_img[:, :, ROI_START_Y:ROI_END_Y, ROI_START_X:ROI_END_X]\n    \n    # 步骤 2：重采样到目标尺寸\n    \n    # PyTorch的align_corners参数经常导致混淆\n    resampled_tensor = F.interpolate(roi_tensor, size=(TARGET_SIZE, TARGET_SIZE), \n                                   mode='bilinear', align_corners=False)\n    \n    resampled_img = resampled_tensor.squeeze().numpy()\n    \n    # 步骤 3：分析处理\n    segment_result = get_segmentation(resampled_img)\n    keypoint_result = get_keypoint(resampled_img)\n    \n    # 步骤 4：结果回传\n    # PyTorch的坐标变换计算复杂，align_corners设置影响结果\n    scale_factor = ROI_SIZE / TARGET_SIZE\n    \n    keypoint_in_original = keypoint_result * scale_factor + [ROI_START_Y, ROI_START_X]\n    \n    # 分割结果回传\n    segment_tensor = torch.from_numpy(segment_result.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n    segment_roi_tensor = F.interpolate(segment_tensor, size=(ROI_SIZE, ROI_SIZE), \n                                     mode='nearest')\n    \n    segment_roi = segment_roi_tensor.squeeze().numpy().astype(np.uint8)\n    \n    # 放回原始图像\n    segment_original = np.zeros_like(img, dtype=np.uint8)\n    segment_original[ROI_START_Y:ROI_END_Y, ROI_START_X:ROI_END_X] = segment_roi\n    \n    return segment_original, keypoint_in_original\n\nprint(\"=== PyTorch interpolate实现 ===\")\ntorch_segment, torch_keypoint = process_with_pytorch(original_img)\nprint(f\"检测到的关键点坐标: {torch_keypoint}\")\nprint(f\"分割区域像素数: {np.sum(torch_segment)}\")\n\n# 立即显示 PyTorch 结果\nplot_result(original_img, torch_segment, torch_keypoint, \"PyTorch interpolate\", true_keypoint)\n\nPyTorch interpolate 的问题分析：\n\nalign_corners 混淆：True/False 产生不同坐标映射公式，易出错\n维度管理冗余：需手动添加/移除 batch、channel 维度\n最近邻偏移：可见预测的 mask 与原图存在偏移",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "空间变换库对比与动机"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation.html#方法四spacetransformer-实现",
    "href": "3.0_spacetransformer_motivation.html#方法四spacetransformer-实现",
    "title": "空间变换库对比与动机",
    "section": "方法四：SpaceTransformer 实现",
    "text": "方法四：SpaceTransformer 实现\n\nfrom spacetransformer.core import Space\nfrom spacetransformer.torch import warp_image\nfrom spacetransformer.core import warp_point\nimport torch\n\ndef process_with_spacetransformer(img):\n    \"\"\"使用 SpaceTransformer 实现流水线\"\"\"\n    \n    # 定义原始图像空间\n    original_space = Space(\n        shape=[1]+list(img.shape),\n        spacing=(1.0, 1.0, 1.0),\n        origin=(0.0, 0.0, 0.0)\n    )\n    \n    # 声明式定义目标空间：ROI 提取 + 重采样（使用全局参数）\n    target_space = (original_space\n        .apply_bbox([(0,1), (ROI_START_Y, ROI_END_Y), (ROI_START_X, ROI_END_X)])  # 偏移ROI\n        .apply_shape((1, TARGET_SIZE, TARGET_SIZE))             # 重采样到目标尺寸\n    )\n    \n    # 执行变换\n    resampled_img = warp_image(img[None], original_space, target_space, \n                                mode='trilinear', pad_value=0, cuda_device='cpu',\n                                numpy=True)[0]\n    \n    # 分析处理\n    segment_result = get_segmentation(resampled_img)\n    keypoint_2d = get_keypoint(resampled_img)\n    \n    # 将 2D 关键点转换为 3D 格式 (z=0, y, x) 供 SpaceTransformer 使用\n    keypoint_3d = np.array([[0, keypoint_2d[0], keypoint_2d[1]]])  # shape: (1, 3)\n    # 结果回传：一行代码完成逆变换\n    segment_original = warp_image(segment_result[None],     target_space, original_space,\n                                       mode='nearest', pad_value=0, cuda_device='cpu',numpy=True)[0]\n    keypoint_3d_original = warp_point(keypoint_3d, target_space, original_space)[0]\n    \n    # 转换回2D格式 (y, x)\n    keypoint_original = keypoint_3d_original[0, 1:3]  \n    \n    return segment_original, keypoint_original\n\nprint(\"=== SpaceTransformer实现 ===\")\nst_segment, st_keypoint = process_with_spacetransformer(original_img)\nprint(f\"检测到的关键点坐标: {st_keypoint}\")\nprint(f\"分割区域像素数: {np.sum(st_segment)}\")\n\n# 立即显示 SpaceTransformer 结果\nplot_result(original_img, st_segment, st_keypoint, \"SpaceTransformer\", true_keypoint)",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "空间变换库对比与动机"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation.html#实验结果分析与总结",
    "href": "3.0_spacetransformer_motivation.html#实验结果分析与总结",
    "title": "空间变换库对比与动机",
    "section": "实验结果分析与总结",
    "text": "实验结果分析与总结\n通过上述对比实验，我们可以清晰地观察到各个库在空间变换精度和实现复杂度方面的显著差异：\n精度对比：除 SpaceTransformer 外，其他主流库均存在不同程度的坐标偏移。其中 PyTorch 的实现甚至出现明显的分割掩膜偏移，医学场景下可能导致严重后果。SpaceTransformer 通过精确空间描述，有效避免这类损失。\n开发效率对比：从代码复杂度看，SpaceTransformer 优势明显。传统方法需手动管理坐标变换链、参数配置与维度处理，并针对不同元素维持不同变换；SpaceTransformer 以声明式空间定义与自动化计算，将几十行实现收敛为少量核心逻辑，显著提升可维护性。\n架构设计优势：SpaceTransformer 采用“计算逻辑与业务逻辑分离”，封装复杂、易错的底层计算，使空间变换对用户透明，开发者可专注算法而非坐标细节。\n在接下来的章节中，我们将分析问题根源，阐述 SpaceTransformer 的设计原理与技术实现，帮助读者理解其在医学图像空间变换中的优势。",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "空间变换库对比与动机"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html",
    "href": "2.1_mask_compression.html",
    "title": "高效压缩算法",
    "section": "",
    "text": "医学图像分割掩膜通常是高度稀疏的，这为专门的压缩算法提供了优化空间。本文旨在对比 MedMask 格式与常用的 NIfTI (.nii.gz) 和 NumPy (.npz) 格式在存储二值（Binary）和多标签（Multi-label）掩膜时的压缩效率、编码及解码速度。最后，我们将深入探究 MedMask 的核心技术——PackBits 预处理结合 Zstandard 压缩——为何能针对稀疏掩膜实现卓越的压缩性能。",
    "crumbs": [
      "MedMask",
      "高效压缩算法"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html#摘要",
    "href": "2.1_mask_compression.html#摘要",
    "title": "高效压缩算法",
    "section": "",
    "text": "医学图像分割掩膜通常是高度稀疏的，这为专门的压缩算法提供了优化空间。本文旨在对比 MedMask 格式与常用的 NIfTI (.nii.gz) 和 NumPy (.npz) 格式在存储二值（Binary）和多标签（Multi-label）掩膜时的压缩效率、编码及解码速度。最后，我们将深入探究 MedMask 的核心技术——PackBits 预处理结合 Zstandard 压缩——为何能针对稀疏掩膜实现卓越的压缩性能。",
    "crumbs": [
      "MedMask",
      "高效压缩算法"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html#统一基准测试框架",
    "href": "2.1_mask_compression.html#统一基准测试框架",
    "title": "高效压缩算法",
    "section": "1. 统一基准测试框架",
    "text": "1. 统一基准测试框架\n为了避免代码重复并确保测试的公平性，我们首先定义一个统一的基准测试框架。该框架可以处理不同的数据格式，并返回标准化的性能指标（文件大小、编码时间、解码时间）。\n\nimport os\nimport time\nimport gzip\nimport tempfile\nimport numpy as np\nimport nibabel as nib\nimport zstandard as zstd\nfrom pathlib import Path\nfrom medmask import SegmentationMask\nfrom spacetransformer import Space\nimport pandas as pd\n\n# --- 统一的基准测试函数 ---\ndef run_benchmark(format_type, data, space=None, label_mapping=None, original_path=None):\n    \"\"\"\n    对指定格式运行压缩和解压基准测试。\n\n    Args:\n        format_type (str): 'nifti', 'npz', 'medmask'\n        data (np.ndarray): 掩膜数据\n        space (Space, optional): MedMask/NIfTI所需的空间信息.\n        label_mapping (dict, optional): MedMask所需的多标签映射.\n        original_path (Path, optional): NIfTI格式的原始路径，用于直接获取文件大小.\n\n    Returns:\n        dict: 包含 size, encode_time, decode_time 的字典.\n    \"\"\"\n    stats = {'size': 0, 'encode_time': 0, 'decode_time': 0}\n    \n    with tempfile.TemporaryDirectory() as tmpdir:\n        tmp_path = Path(tmpdir) / f\"tempfile.{format_type.split('_')[0]}\"\n\n        # --- 编码过程 ---\n        encode_start = time.time()\n        if format_type == 'nifti':\n            if original_path:\n                stats['size'] = original_path.stat().st_size\n            else: # 用于创建新的多标签 NIfTI 文件\n                affine =  np.eye(4)\n                nii_img = nib.Nifti1Image(data.astype(np.uint8), affine)\n                tmp_path_nii = tmp_path.with_suffix('.nii.gz')\n                nib.save(nii_img, tmp_path_nii)\n                stats['size'] = tmp_path_nii.stat().st_size\n            # NIfTI 的编码/解码时间通常包含在加载过程中，这里不单独测量以简化对比\n            pass \n        elif format_type == 'npz':\n            np.savez_compressed(tmp_path, mask=data)\n            stats['size'] = tmp_path.stat().st_size\n        elif format_type == 'medmask':\n            mask_obj = SegmentationMask(data, label_mapping, space=space)\n            mask_obj.save(tmp_path)\n            stats['size'] = tmp_path.stat().st_size\n        stats['encode_time'] = (time.time() - encode_start) * 1000  # ms\n\n        # --- 解码过程 ---\n        if stats['size'] &gt; 0: # 仅在成功编码后解码\n            decode_start = time.time()\n            if format_type == 'nifti':\n                 # 为保持一致性，不单独测量 NIfTI 的解码时间\n                 pass\n            elif format_type == 'npz':\n                _ = np.load(tmp_path)['mask']\n            elif format_type == 'medmask':\n                loaded_mask = SegmentationMask.load(tmp_path)\n                # 模拟实际使用，提取所有标签\n                if label_mapping:\n                    for name in label_mapping.keys():\n                        _ = loaded_mask.get_binary_mask_by_names(name)\n            stats['decode_time'] = (time.time() - decode_start) * 1000 # ms\n            \n    return stats\n\n# --- 数据加载 ---\nmask_dir = Path('dicube-testdata/mask/s0000')\nwith open(mask_dir / 'nonzero_masks.txt', 'r') as f:\n    valid_files = [line.strip() for line in f.readlines()]\nprint(f\"加载了 {len(valid_files)} 个有效的掩膜文件用于测试。\")",
    "crumbs": [
      "MedMask",
      "高效压缩算法"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html#二值掩膜binary-mask性能对比",
    "href": "2.1_mask_compression.html#二值掩膜binary-mask性能对比",
    "title": "高效压缩算法",
    "section": "2. 二值掩膜（Binary Mask）性能对比",
    "text": "2. 二值掩膜（Binary Mask）性能对比\n在此部分，我们测试单个器官掩膜的压缩性能。这类掩膜只包含一个标签，是典型的二值稀疏数据。\n\n测试配置与执行\n我们选择一系列大小和稀疏度各不相同的掩膜文件进行测试。\n\n# 选择测试文件\nbinary_test_files = [\n    'gluteus_maximus_right.nii.gz', # 大掩膜\n    'urinary_bladder.nii.gz',       # 大掩膜\n    'colon.nii.gz',                 # 中等掩膜\n    'iliopsoas_left.nii.gz',        # 中等掩膜\n    'iliac_artery_left.nii.gz',     # 小掩膜\n    'small_bowel.nii.gz'            # 极小掩膜\n]\n\nbinary_results = []\n\nfor fname in binary_test_files:\n    original_path = mask_dir / fname\n    nii_img = nib.load(original_path)\n    mask_data = nii_img.get_fdata().astype(np.uint8)\n    space = Space.from_nifti(nii_img)\n    organ_name = fname.replace('.nii.gz', '')\n    \n    nifti_stats = run_benchmark('nifti', data=mask_data, original_path=original_path)\n    npz_stats = run_benchmark('npz', data=mask_data)\n    medmask_stats = run_benchmark('medmask', data=mask_data, space=space, label_mapping={organ_name: 1})\n    \n    binary_results.append({\n        '文件名': fname.replace('.nii.gz', ''),\n        '非零像素': np.count_nonzero(mask_data),\n        'NIfTI (KB)': nifti_stats['size'] / 1024,\n        'NPZ (KB)': npz_stats['size'] / 1024,\n        'MedMask (KB)': medmask_stats['size'] / 1024,\n        'NPZ 编码 (ms)': npz_stats['encode_time'],\n        'MedMask 编码 (ms)': medmask_stats['encode_time'],\n        'NPZ 解码 (ms)': npz_stats['decode_time'],\n        'MedMask 解码 (ms)': medmask_stats['decode_time']\n    })\n\ndf_binary = pd.DataFrame(binary_results)\n\n# --- 增加平均值行 ---\nif not df_binary.empty:\n    avg_row = df_binary.select_dtypes(include=np.number).mean()\n    avg_row['文件名'] = 'Average'\n    avg_row = avg_row.reindex(df_binary.columns, fill_value='-')\n    df_binary = pd.concat([df_binary, pd.DataFrame([avg_row])], ignore_index=True)\n\ndf_binary['MedMask压缩比 (vs NIfTI)'] = df_binary['NIfTI (KB)'] / df_binary['MedMask (KB)']\ndf_binary['NPZ压缩比 (vs NIfTI)'] = df_binary['NIfTI (KB)'] / df_binary['NPZ (KB)']\n\nprint(\"--- 二值掩膜压缩性能对比 ---\")\ndisplay(df_binary.style.format({\n    'NIfTI (KB)': '{:.1f}', 'NPZ (KB)': '{:.1f}', 'MedMask (KB)': '{:.1f}',\n    'NPZ 编码 (ms)': '{:.1f}', 'MedMask 编码 (ms)': '{:.1f}',\n    'NPZ 解码 (ms)': '{:.1f}', 'MedMask 解码 (ms)': '{:.1f}',\n    'MedMask压缩比 (vs NIfTI)': '{:.1f}x', 'NPZ压缩比 (vs NIfTI)': '{:.1f}x',\n    '非零像素': '{:,.0f}'\n}).hide(axis=\"index\"))\n\n\n\n二值掩膜结论\n从上表可以清晰地看出：\n\n压缩效率: MedMask 的压缩效率显著优于 NPZ 和 NIfTI。如 Average 行所示，MedMask 的平均文件大小远低于其他两者。对于稀疏程度高的小目标（如 iliac_artery_left），MedMask 的压缩比优势尤为突出。数据越稀疏，其优势越明显。\n存储大小: 总体而言，MedMask 能有效降低文件大小，通常能达到数倍乃至数十倍的压缩效果，将文件体积从几十KB量级降低到几KB甚至更低。\n处理速度: MedMask 的编解码速度与 NPZ 相当，有时甚至更快，完全满足高性能应用的需求。",
    "crumbs": [
      "MedMask",
      "高效压缩算法"
    ]
  },
  {
    "objectID": "2.1_mask_compression.html#多标签掩膜multi-label-mask性能对比",
    "href": "2.1_mask_compression.html#多标签掩膜multi-label-mask性能对比",
    "title": "高效压缩算法",
    "section": "3. 多标签掩膜（Multi-label Mask）性能对比",
    "text": "3. 多标签掩膜（Multi-label Mask）性能对比\n在实际应用中，常需要将多个器官掩膜存储在同一个文件中。我们构建一个包含多个标签的数组，然后对比 NIfTI、NPZ 和 MedMask 格式在存储这同一个多标签数组时的性能差异。\n\n测试配置与执行\n我们将相关的器官掩膜组合成逻辑分组，并融合成一个多标签数组进行测试。\n\ntest_groups = [\n    {\n        'name': '臀肌群',\n        'files': ['gluteus_maximus_left.nii.gz', 'gluteus_maximus_right.nii.gz', \n                  'gluteus_medius_left.nii.gz', 'gluteus_medius_right.nii.gz'],\n    },\n    {\n        'name': '股骨与髋骨',\n        'files': ['femur_left.nii.gz', 'femur_right.nii.gz', \n                  'hip_left.nii.gz', 'hip_right.nii.gz'],\n    },\n    {\n        'name': '盆腔器官',\n        'files': ['urinary_bladder.nii.gz', 'colon.nii.gz', 'small_bowel.nii.gz'],\n    }\n]\n\nmultilabel_results = []\n\nfor group in test_groups:\n    # 1. 创建多标签数据\n    first_img = nib.load(mask_dir / group['files'][0])\n    space = Space.from_nifti(first_img)\n    multilabel_array = np.zeros(first_img.shape, dtype=np.uint8)\n    label_mapping = {}\n    \n    for i, fname in enumerate(group['files']):\n        fpath = mask_dir / fname\n        if not fpath.exists(): continue\n        \n        data = nib.load(fpath).get_fdata().astype(np.uint8)\n        \n        # 构建多标签数组\n        label_value = i + 1\n        organ_name = fname.replace('.nii.gz', '')\n        multilabel_array[data &gt; 0] = label_value\n        label_mapping[organ_name] = label_value\n\n    # 2. 对同一个多标签数组，用不同格式进行基准测试\n    nifti_stats = run_benchmark('nifti', data=multilabel_array, space=space)\n    npz_stats = run_benchmark('npz', data=multilabel_array)\n    medmask_stats = run_benchmark('medmask', data=multilabel_array, space=space, label_mapping=label_mapping)\n    \n    multilabel_results.append({\n        '测试组': group['name'],\n        '标签数': len(group['files']),\n        'NIfTI (KB)': nifti_stats['size'] / 1024,\n        'NPZ (KB)': npz_stats['size'] / 1024,\n        'MedMask (KB)': medmask_stats['size'] / 1024,\n        'NPZ 编码 (ms)': npz_stats['encode_time'],\n        'MedMask 编码 (ms)': medmask_stats['encode_time'],\n        'NPZ 解码 (ms)': npz_stats['decode_time'],\n        'MedMask 解码 (ms)': medmask_stats['decode_time']\n    })\n\ndf_multi = pd.DataFrame(multilabel_results)\n\n# --- 增加平均值行 ---\nif not df_multi.empty:\n    avg_row = df_multi.select_dtypes(include=np.number).mean()\n    avg_row['测试组'] = 'Average'\n    avg_row = avg_row.reindex(df_multi.columns, fill_value='-')\n    df_multi = pd.concat([df_multi, pd.DataFrame([avg_row])], ignore_index=True)\n\ndf_multi['MedMask压缩比 (vs NIfTI)'] = df_multi['NIfTI (KB)'] / df_multi['MedMask (KB)']\ndf_multi['NPZ压缩比 (vs NIfTI)'] = df_multi['NIfTI (KB)'] / df_multi['NPZ (KB)']\n\nprint(\"--- 多标签掩膜压缩性能对比 ---\")\ndisplay(df_multi.style.format({\n    '独立NIfTI (KB)': '{:.1f}', '独立NPZ (KB)': '{:.1f}', 'MedMask合并 (KB)': '{:.1f}',\n    'NIfTI (KB)': '{:.1f}', 'NPZ (KB)': '{:.1f}', 'MedMask (KB)': '{:.1f}',\n    'NPZ 编码 (ms)': '{:.1f}', 'MedMask 编码 (ms)': '{:.1f}',\n    'NPZ 解码 (ms)': '{:.1f}', 'MedMask 解码 (ms)': '{:.1f}',\n    'MedMask压缩比 (vs NIfTI)': '{:.1f}x', 'NPZ压缩比 (vs NIfTI)': '{:.1f}x'\n}).hide(axis=\"index\"))\n\n\n\n多标签掩膜结论\n在处理包含多个标签的单一掩膜文件时，MedMask 同样展现出卓越的压缩性能。从上表可以看出，存储相同的多标签数据，MedMask 格式生成的文件体积显著小于 NIfTI 和 NPZ。\n\n\n4. 核心技术探究：PackBits + Zstandard 的威力\nMedMask 的高压缩率源于其针对不同掩膜类型的双层压缩策略。对于二值掩膜（Binary Mask），它采用 PackBits + Zstandard (Zstd) 的组合；而对于多标签掩膜，则直接使用 Zstd。本节将重点探究为何 PackBits 预处理能为二值掩膜带来显著的性能提升。\n\nPackBits 预处理机制\nMedMask 中使用的 PackBits 是一种针对二值稀疏数据的位打包（Bit Packing）技术，而非传统的游程编码（Run-Length Encoding）。其核心思想是将多个布尔值（在数组中通常以 uint8 的 0 或 1 存储）压缩到单个字节的位（bit）中。由于一个 uint8 字节包含8个位，该算法可以：\n\n将8个连续的 uint8 类型的掩膜像素值（每个占用1字节）打包成一个 uint8（占用1字节）。\n每个原始像素（0 或 1）映射到新字节中的一个位（0 或 1）。\n\n工作示例： 假设有8个连续的像素值 [0, 1, 0, 0, 0, 0, 0, 1]。在内存中，它们占用8个字节。经过 PackBits 处理后，它们会被编码成单个字节。该字节的二进制表示为 10000010（注：位的顺序取决于具体实现），在十进制中为 130。这样，仅此一步就实现了理论上接近8:1的数据压缩。\n这种机制决定了 PackBits 预处理仅适用于二值数据。对于多标签掩膜，像素值可以大于1（例如 2, 3, 4, ...），无法用单个位来表示，因此 MedMask 会跳过此步骤，直接对原始多标签数组应用 Zstd 压缩。这也解释了为何 MedMask 在处理二值掩膜时的压缩比通常优于处理多标签掩膜。\n为了量化 PackBits 预处理的有效性，我们对比纯 Zstd 压缩和 MedMask (PackBits + Zstd) 在处理同一个二值掩膜时的效果。\n\n# 加载中等大小的掩膜数据\nmask_path = mask_dir / 'urinary_bladder.nii.gz'\nimg = nib.load(mask_path)\ndata = img.get_fdata()&gt;0\ndata_bytes = data.tobytes()\ndata_packbit_bytes = np.packbits(data).tobytes()\n\n# 1. 原始大小\nraw_size = len(data_bytes)\npackbit_size = len(data_packbit_bytes)\n\n# 2. 纯 Gzip 压缩 (NIfTI/NPZ 使用)\ngzip_size = len(gzip.compress(data_bytes))\n\n# 3. 纯 Zstandard 压缩\nzstd_size = len(zstd.ZstdCompressor().compress(data_bytes))\n\n# 4. MedMask (PackBits + Zstd) 压缩\npackbit_zstd_size = len(zstd.ZstdCompressor().compress(data_packbit_bytes))\n\n\n# 结果汇总\npackbits_analysis = {\n    \"方法\": [\"原始数据 (Bytes)\",\"Packbits数据 (Bytes)\", \"纯 Gzip\", \"纯 Zstandard\", \"MedMask (PackBits + Zstd)\"],\n    \"大小 (KB)\": [raw_size / 1024, packbit_size/1024, gzip_size / 1024, zstd_size / 1024, packbit_zstd_size / 1024],\n    \"压缩比 (vs 原始)\": [1.0, raw_size/packbit_size, raw_size / gzip_size, raw_size / zstd_size, raw_size / packbit_zstd_size]\n}\ndf_packbits = pd.DataFrame(packbits_analysis)\n\nprint(\"--- 压缩策略对稀疏数据的效果对比 ---\")\nprint(f\"测试对象: {mask_path.name}, 稀疏度: {1 - np.count_nonzero(data) / data.size:.2%}\")\ndisplay(df_packbits.style.format({\n    \"大小 (KB)\": \"{:.2f}\",\n    \"压缩比 (vs 原始)\": \"{:.1f}x\"\n}).hide(axis=\"index\"))\n\n\n\n\n结论\n综合以上分析，MedMask 之所以能成为一种高效的医学分割掩膜存储格式，其核心在于它根据数据特性采用的自适应双层压缩策略。\n\n对于二值掩膜，MedMask 采用 PackBits 预处理 + Zstandard 压缩 的模式。\n\nPackBits 作为一种位打包预处理，首先消除了用整个字节（uint8）存储单个布尔值所带来的结构性冗余，实现了第一重压缩。\n经过预处理的紧凑数据流，再由高效的 Zstandard 算法进行第二重压缩。这种针对性的组合策略，使其压缩比远超仅依赖 Gzip (DEFLATE) 的 NIfTI 和 NPZ 格式，且性能与数据稀疏度正相关。\n\n对于多标签掩膜，由于无法进行位打包，MedMask 直接应用 Zstandard 进行压缩。虽然缺少了 PackBits 带来的巨额增益，但 Zstandard 本身的性能依然优于传统的 DEFLATE 算法，因此 MedMask 在存储多标签数据时仍比 NIfTI 和 NPZ 更具空间效率。\n\n总而言之，MedMask 的设计精髓在于它并非简单应用通用压缩，而是通过领域特定的预处理（位打包）来最大化后续通用压缩算法（Zstd）的效率。这种设计使其在显著降低存储空间的同时，保持了高性能的读写速度，为医学图像分析工作流提供了切实的优化。",
    "crumbs": [
      "MedMask",
      "高效压缩算法"
    ]
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "FastDiag Toolkit 文档",
    "section": "",
    "text": "import dicube\nfrom dicube.dicom import DcbStreamingReader\nimport pydicom\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nfrom io import BytesIO\n\n# 加载并保存dcbs文件\ndcb_img = dicube.load_from_dicom_folder('sample_data/sample_200_0')\ndcb_file = 'sample_data/sample_200.dcbs'\ndicube.save(dcb_img, dcb_file)\n\n# 创建流式读取器\ndcb_stream = DcbStreamingReader(dcb_file)\n\n# 获取总帧数\ntotal_frames = dcb_img.shape[0] \nprint(f\"总共有 {total_frames} 层图像\")\nplt.figure(figsize=(5, 4))\nax = plt.imshow(np.zeros(512,512), cmap='gray',vmin=-800,vmax=300)\nplt.title(f'{frame_index + 1}  /  {total_frames} ')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n# 创建交互式滑动控件\ndef show_slice(frame_index):\n    \"\"\"显示指定帧的图像\"\"\"\n    try:\n        # 使用流式读取器获取DICOM数据\n        dicom_data = dcb_stream.get_dicom_for_frame(frame_index)\n        \n        # 解析DICOM数据\n        dicom_buffer = BytesIO(dicom_data)\n        dataset = pydicom.dcmread(dicom_buffer, force=True)\n        \n        # 获取像素数据并解压\n        pixel_array = (dataset.pixel_array).astype('float32')+float(dataset.RescaleIntercept)\n        \n        # 清除之前的输出\n        clear_output(wait=True)\n        \n        # 创建matplotlib图形\n        \n    except Exception as e:\n        print(f\"读取第 {frame_index} 帧时出错: {str(e)}\")\n\n# 创建滑动控件\nslice_slider = widgets.IntSlider(\n    value=0,\n    min=0,\n    max=total_frames - 1,\n    step=1,\n    description='切片:',\n    style={'description_width': '60px'},\n    layout=widgets.Layout(width='400px')\n)\n\n# 创建交互式控件\ninteractive_plot = widgets.interactive(show_slice, frame_index=slice_slider)\n\n# 显示控件\n\n总共有 200 层图像"
  },
  {
    "objectID": "2.2_mask_label_mapping-en.html",
    "href": "2.2_mask_label_mapping-en.html",
    "title": "Semantic Mapping System",
    "section": "",
    "text": "Traditional mask workflows rely on external configs or filenames to map numeric labels to anatomy, leading to inconsistency and maintenance burden. MedMask embeds a bidirectional semantic mapping so masks are self-describing.",
    "crumbs": [
      "首页",
      "MedMask",
      "Semantic Mapping System"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping-en.html#summary",
    "href": "2.2_mask_label_mapping-en.html#summary",
    "title": "Semantic Mapping System",
    "section": "",
    "text": "Traditional mask workflows rely on external configs or filenames to map numeric labels to anatomy, leading to inconsistency and maintenance burden. MedMask embeds a bidirectional semantic mapping so masks are self-describing.",
    "crumbs": [
      "首页",
      "MedMask",
      "Semantic Mapping System"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping-en.html#problems-with-traditional-management",
    "href": "2.2_mask_label_mapping-en.html#problems-with-traditional-management",
    "title": "Semantic Mapping System",
    "section": "1. Problems With Traditional Management",
    "text": "1. Problems With Traditional Management\n\n1.1. External Config Files\n\nimport numpy as np, json\nmask = np.array([[0,0,1,1],[0,2,2,1],[3,3,0,0]])\nconfig = {\"1\": \"liver\", \"2\": \"spleen\", \"3\": \"kidney\"}\nwith open('label_config.json','w') as f:\n    json.dump(config, f)\nprint(\"Mask shape:\", mask.shape, \"labels:\", np.unique(mask))\nprint(\"Config:\", config)\n\nRisks: extra files, sync issues, no guarantee of completeness.\n\n\n1.2. Filenames / NPZ Keys\n\nnp.savez_compressed('multi_organ.npz',\n    liver = (mask == 1),\n    spleen = (mask == 2),\n    kidney = (mask == 3)\n)\nloaded = np.load('multi_organ.npz')\nprint(\"Keys:\", list(loaded.keys()))\n\nLimited expressiveness as label count grows; lacks standardization.",
    "crumbs": [
      "首页",
      "MedMask",
      "Semantic Mapping System"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping-en.html#medmask-solution",
    "href": "2.2_mask_label_mapping-en.html#medmask-solution",
    "title": "Semantic Mapping System",
    "section": "2. MedMask Solution",
    "text": "2. MedMask Solution\n\n2.1. Embedded Bidirectional Mapping\n\nfrom medmask.core.mapping import LabelMapping\n\nmapping = LabelMapping({\"liver\": 1, \"spleen\": 2, \"kidney\": 3})\nprint(\"Forward:\", mapping['liver'])\nprint(\"Inverse:\", mapping.inverse(1))\nprint(\"Attr access:\", mapping.spleen)\nprint(\"Callable:\", mapping('kidney'))\n\n\n\n2.2. Flexible Access Patterns\n\nliver = mapping['liver']\nspleen = mapping.spleen\nkidney = mapping('kidney')\norgan = mapping.inverse(1)\nprint(\"Lookup consistency:\", liver, spleen, kidney, organ)\n\n\n\n2.3. JSON Serialization\n\njson_repr = mapping.to_json()\nrestored = LabelMapping.from_json(json_repr)\nprint(\"Round-trip equal:\", mapping._name_to_label == restored._name_to_label)",
    "crumbs": [
      "首页",
      "MedMask",
      "Semantic Mapping System"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping-en.html#segmentationmask-integration",
    "href": "2.2_mask_label_mapping-en.html#segmentationmask-integration",
    "title": "Semantic Mapping System",
    "section": "3. SegmentationMask Integration",
    "text": "3. SegmentationMask Integration\n\nfrom medmask import SegmentationMask\nfrom spacetransformer import Space\n\nspace = Space(shape=(1,3,4), spacing=(1.0,1.0,1.0))\nsegmask = SegmentationMask(\n    mask_array = mask[np.newaxis, :, :],\n    mapping = {\"liver\":1,\"spleen\":2,\"kidney\":3},\n    space = space\n)\nprint(\"Shape:\", segmask.data.shape)\nprint(\"Space spacing:\", segmask.space.spacing)\nprint(\"Mapping:\", dict(segmask.mapping.items()))\n\n\nSemantic Queries\n\nliver_mask = segmask.get_binary_mask_by_names(\"liver\")\nprint(\"Liver nonzero:\", liver_mask.sum())\n\nabdominal = segmask.get_binary_mask_by_names([\"liver\",\"spleen\"])\nprint(\"Abdominal nonzero:\", abdominal.sum())\n\nprint(\"Label-based equal:\", np.array_equal(liver_mask, segmask.get_binary_mask_by_labels(1)))\n\n\n\nMaintenance Win\nCode references organ names, not label integers, so changing mappings no longer requires code edits.",
    "crumbs": [
      "首页",
      "MedMask",
      "Semantic Mapping System"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping-en.html#incremental-build-safety",
    "href": "2.2_mask_label_mapping-en.html#incremental-build-safety",
    "title": "Semantic Mapping System",
    "section": "4. Incremental Build + Safety",
    "text": "4. Incremental Build + Safety\n\nempty = SegmentationMask.lazy_init(bit_depth=8, space=space)\n\nliver_region = np.zeros((1,3,4), dtype=bool); liver_region[0,0:2,1:3] = True\nspleen_region = np.zeros((1,3,4), dtype=bool); spleen_region[0,1:3,2:4] = True\n\nempty.add_label(liver_region, label=1, name=\"liver\")\nempty.add_label(spleen_region, label=2, name=\"spleen\")\nprint(\"Labels:\", list(empty.mapping))\ncombined = empty.get_binary_mask_by_names([\"liver\",\"spleen\"])\nprint(\"Combined nonzero:\", combined.sum())\n\nDuplicate label detection prevents mistakes:\n\nfrom dicube.dicom import CommonTags\ntry:\n    test = SegmentationMask.lazy_init(8, space=Space(shape=(2,2,2)))\n    test.add_label(np.ones((2,2,2), dtype=bool), 1, \"organ_a\")\n    test.add_label(np.ones((2,2,2), dtype=bool), 1, \"organ_b\")\nexcept ValueError as e:\n    print(\"Duplicate prevented:\", e)",
    "crumbs": [
      "首页",
      "MedMask",
      "Semantic Mapping System"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping-en.html#summary-1",
    "href": "2.2_mask_label_mapping-en.html#summary-1",
    "title": "Semantic Mapping System",
    "section": "5. Summary",
    "text": "5. Summary\n\n\n\nTraditional\nMedMask\nBenefit\n\n\n\n\nExternal configs\nEmbedded mapping\nSelf-contained data\n\n\nManual validation\nRuntime consistency checks\nFewer human errors\n\n\nHard-coded labels\nSemantic queries\nReadable, maintainable code\n\n\nCross-team sync\nSelf-describing files\nEasier collaboration",
    "crumbs": [
      "首页",
      "MedMask",
      "Semantic Mapping System"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FastDiag Toolkit",
    "section": "",
    "text": "在笔者投身医学图像AI领域的这些年里，深刻体会到这个学科的独特魅力与挑战。Python与PyTorch无疑已成为我们探索未知、构建模型的通用语言，推动着整个领域的飞速发展。我们站在巨人的肩膀上，python 生态中的 pydicom、SimpleITK、nibabel 等经典工具链为我们处理复杂的医学影像数据提供了可能，前人的卓越贡献值得我们每一个人致敬。\n然而，我们也不得不承认，这些传统的轮子在面对今天的深度学习工作流时，显得有些“水土不服”。笔者和身边的许多同行，都曾或多或少地在一些基础问题上反复挣扎：老旧的数据格式与现代AI框架的接口难以严丝合缝地对接；新人需要耗费大量时间，在无数次踩坑和试错后，才能建立起对医学影像坐标系、数据加载等问题的基本认知。\n更让人难受的是，这个领域的“说明书”实在太少了。除了3D Slicer等少数项目提供了相对完善的文档外，大量的关键内容都深埋在ITK和VTK庞杂的代码库深处。很多时候，我们为了定位一个看似简单的bug，不得不翻遍GitHub issue、stackoverflow、各路神仙的博客，从零散的讨论中拼凑出问题的成因。这种探索过程虽然不乏“解谜”的乐趣，但对于追求高效研发的我们而言，无疑是一种巨大的时间成本。\n正是这些日常工作中的痛点，促使笔者开始思考：我们是否能有一套更现代、更高效、更符合AI时代开发习惯的基础工具，来将我们从这些重复性的泥潭中解放出来，从而能更专注于算法和模型本身的创新？这便是我们开发FastDiag Toolkit的初衷。"
  },
  {
    "objectID": "index.html#问题背景",
    "href": "index.html#问题背景",
    "title": "FastDiag Toolkit",
    "section": "",
    "text": "在笔者投身医学图像AI领域的这些年里，深刻体会到这个学科的独特魅力与挑战。Python与PyTorch无疑已成为我们探索未知、构建模型的通用语言，推动着整个领域的飞速发展。我们站在巨人的肩膀上，python 生态中的 pydicom、SimpleITK、nibabel 等经典工具链为我们处理复杂的医学影像数据提供了可能，前人的卓越贡献值得我们每一个人致敬。\n然而，我们也不得不承认，这些传统的轮子在面对今天的深度学习工作流时，显得有些“水土不服”。笔者和身边的许多同行，都曾或多或少地在一些基础问题上反复挣扎：老旧的数据格式与现代AI框架的接口难以严丝合缝地对接；新人需要耗费大量时间，在无数次踩坑和试错后，才能建立起对医学影像坐标系、数据加载等问题的基本认知。\n更让人难受的是，这个领域的“说明书”实在太少了。除了3D Slicer等少数项目提供了相对完善的文档外，大量的关键内容都深埋在ITK和VTK庞杂的代码库深处。很多时候，我们为了定位一个看似简单的bug，不得不翻遍GitHub issue、stackoverflow、各路神仙的博客，从零散的讨论中拼凑出问题的成因。这种探索过程虽然不乏“解谜”的乐趣，但对于追求高效研发的我们而言，无疑是一种巨大的时间成本。\n正是这些日常工作中的痛点，促使笔者开始思考：我们是否能有一套更现代、更高效、更符合AI时代开发习惯的基础工具，来将我们从这些重复性的泥潭中解放出来，从而能更专注于算法和模型本身的创新？这便是我们开发FastDiag Toolkit的初衷。"
  },
  {
    "objectID": "index.html#解决方案",
    "href": "index.html#解决方案",
    "title": "FastDiag Toolkit",
    "section": "解决方案",
    "text": "解决方案\nFastDiag Toolkit 提供了三个核心库：\n\n📦 DiCube - 医学影像存储库\n高效的 3D 医学影像存储格式，dicom 的上位替代。\n核心特性：\n\n单文件存储（.dcbs），消除 dicom 零散化给文件系统的负担\nHTJ2K 无损压缩，3倍存储压缩，5倍速度提升\n元数据去重，减少冗余信息\n完整 DICOM 往返转换支持\n\nGitHub： https://github.com/fastdiag-toolbox/dicube\n\n\n🎭 MedMask - 医学掩膜处理库\n专业的医学影像分割掩膜压缩和处理解决方案，nii.gz 的上位替代。\n核心特性：\n\n50+ 倍压缩比（Zstandard 算法）\n16 倍读取速度提升\n内嵌语义映射\n支持多粒度器官组合和重叠掩膜\n\nGitHub： https://github.com/fastdiag-toolbox/medmask\n\n\n🌐 SpaceTransformer - 3D 空间变换库\n优雅的 3D 医学影像几何变换处理方案，simpleitk 的上位替代。\n核心特性：\n\nSpace 优先几何抽象：通过形状/间距/原点/方向，自动推导精确坐标映射\n规划与执行分离：在抽象的 space 上链式描述各种空间变换，实际变换只要单次采样\n精准对齐零偏差：图像/掩膜/关键点严格一致，规避 align_corners 与轴序陷阱\nGPU 加速与生态互通：PyTorch 后端重采样\n\nGitHub：\n\nhttps://github.com/fastdiag-toolbox/spacetransformer-core\nhttps://github.com/fastdiag-toolbox/spacetransformer-torch"
  },
  {
    "objectID": "index.html#安装方法",
    "href": "index.html#安装方法",
    "title": "FastDiag Toolkit",
    "section": "安装方法",
    "text": "安装方法\n# 分别安装各个库\npip install dicube\npip install medmask\npip install spacetransformer-core\npip install spacetransformer-torch  # GPU 加速版本"
  },
  {
    "objectID": "index.html#详细文档",
    "href": "index.html#详细文档",
    "title": "FastDiag Toolkit",
    "section": "详细文档",
    "text": "详细文档\n欢迎查看左侧导航栏中的相关技术文档，深入了解各个库的实现细节和使用方法。\n\n如需技术支持或贡献代码，请访问相应的 GitHub 仓库"
  },
  {
    "objectID": "2.0_mask.html",
    "href": "2.0_mask.html",
    "title": "掩膜存储痛点分析",
    "section": "",
    "text": "在前一章节中，我们探讨了 DiCube 如何解决原始 DICOM 图像的存储与管理问题。本章聚焦医学影像分析中的另一个关键环节：分割掩膜（Segmentation Masks）的存储与管理。\n分割掩膜是AI模型分析结果的直接体现，是后续进行量化计算、手术规划和疗效评估的数据基础。然而，当前行业内通用的存储方案（如 .npz 和 .nii.gz）是为通用数据场景设计的，并未针对医学掩膜的特性进行优化，由此引发了四项核心的技术挑战，对研发效率和系统稳健性构成了制约。",
    "crumbs": [
      "MedMask",
      "掩膜存储痛点分析"
    ]
  },
  {
    "objectID": "2.0_mask.html#挑战一空间参考信息的缺失与不一致",
    "href": "2.0_mask.html#挑战一空间参考信息的缺失与不一致",
    "title": "掩膜存储痛点分析",
    "section": "挑战一：空间参考信息的缺失与不一致",
    "text": "挑战一：空间参考信息的缺失与不一致\n精确的空间定位是所有医学图像分析的先决条件。如果分割结果无法与其对应的原始图像在空间上精确对齐，其价值将大打折扣。现有掩膜格式在此方面存在明显不足。\n\nNPZ 格式：缺乏空间参考信息\nNPZ 是 NumPy 数组的压缩存档格式，其设计目标是存储纯粹的数组数据，因此不包含任何空间参考信息，如图像原点（Origin）、像素间距（Spacing）和方向（Direction）。当掩膜被存为 NPZ 文件时，它便成为一个与原始图像物理空间完全分离的独立数组。\n这导致一个实际问题：对于仅包含微小病灶的掩膜，若用 NPZ 存储，既可能需要存一个与原始图像等大的稀疏数组（效率低），也无法凭文件自身信息自动精准叠加回原始 CT 图像，需要额外手工参数对齐。\n\n\nNIfTI 格式：坐标系统不兼容\nNIfTI 格式虽然保留了空间信息，但其生态系统普遍采用的 RAS+ 坐标系与医学影像的 DICOM 标准所规定的 LPS+ 坐标系存在根本性差异（X、Y轴方向相反）。这种不一致性带来了潜在的风险：\n\n增加处理复杂性：与 DICOM 对齐需额外坐标转换，流程更复杂\n潜在对齐错误：复杂流程更易引入左右颠倒等错误\n增加认知负荷：开发需时刻处理坐标差异，维护成本高",
    "crumbs": [
      "MedMask",
      "掩膜存储痛点分析"
    ]
  },
  {
    "objectID": "2.0_mask.html#挑战二语义信息的外部依赖管理",
    "href": "2.0_mask.html#挑战二语义信息的外部依赖管理",
    "title": "掩膜存储痛点分析",
    "section": "挑战二：语义信息的外部依赖管理",
    "text": "挑战二：语义信息的外部依赖管理\n分割掩膜不仅定义了目标的空间位置，还需定义其语义类别（例如，这是哪个器官）。现有格式缺乏内置的、标准化的语义信息管理机制，导致标签的定义必须在文件外部进行管理。\n\n# 传统方法：通过外部代码或配置文件关联像素值与语义\norgan_mapping = {\n    1: \"liver\",\n    2: \"kidney_left\", \n    3: \"kidney_right\",\n    4: \"spleen\",\n    # ...\n}\n\n这种将语义信息与像素数据分离的管理模式，在实际工程中会带来一系列挑战：\n\n数据不自洽：掩膜文件本身不包含自我描述信息，其内容的解释依赖于外部的配置文件、数据库或硬编码。\n同步困难：在多团队协作中（如标注、算法、前后端），对标签值的理解必须通过外部文档进行同步，容易造成不一致。\n版本管理复杂：当标签定义需要更新时（如增减类别），需要协调修改所有相关的外部配置文件和代码库，增加了版本控制的复杂性。",
    "crumbs": [
      "MedMask",
      "掩膜存储痛点分析"
    ]
  },
  {
    "objectID": "2.0_mask.html#挑战三稀疏数据的压缩效率不足",
    "href": "2.0_mask.html#挑战三稀疏数据的压缩效率不足",
    "title": "掩膜存储痛点分析",
    "section": "挑战三：稀疏数据的压缩效率不足",
    "text": "挑战三：稀疏数据的压缩效率不足\n医学分割掩膜是典型的高度稀疏数据，通常超过99%的像素为背景值（0）。通用压缩算法未能有效利用这一特性，导致压缩效率不理想。\n\n通用算法的局限：Gzip 等基于 LZ77 的算法主要通过查找重复序列压缩，能处理连续零，但不如面向稀疏数据的特定算法（如 RLE）\n忽略空间相关性：掩膜目标区域常呈空间团块性，通用算法未充分利用\n\n其结果是，尽管文件经过压缩，但存储体积仍有很大的优化空间，这会增加存储成本和网络传输时间。",
    "crumbs": [
      "MedMask",
      "掩膜存储痛点分析"
    ]
  },
  {
    "objectID": "2.0_mask.html#挑战四无法统一处理重叠与互斥的分割目标",
    "href": "2.0_mask.html#挑战四无法统一处理重叠与互斥的分割目标",
    "title": "掩膜存储痛点分析",
    "section": "挑战四：无法统一处理重叠与互斥的分割目标",
    "text": "挑战四：无法统一处理重叠与互斥的分割目标\n这是医学分割应用中一个普遍且复杂的需求。在临床场景中，往往需要同时表示相互排斥的（mutually exclusive）和可重叠的（overlapping）目标。\n以肺部分割为例：\n\n肺叶：5个标签，彼此互不重叠。\n肺段：18个标签，彼此也互不重叠，但是与肺叶重叠。\n病灶：N个标签，可能与肺叶、肺段及其他病灶重叠。\n整体肺：1个标签，与上述所有结构重叠。\n\n使用标准的数组结构来存储这种混合关系，会面临一个根本性的设计权衡。\n\n方法 1：数值标签掩膜（Value-based Mask）\n每个像素存储一个整数，代表其所属的单一类别。\n优点：存储效率高，一个 uint8 数组即可表示多达255个互斥类别。 缺点：设计上无法表示重叠。一个像素只能属于一个类别。\n\nimport numpy as np\n# 示例：构建互不重叠的肺叶掩膜\nlung_lobe_mask = np.zeros((64, 256, 256), dtype=np.uint8)\nlung_lobe_mask[10:30, 50:150, 60:160] = 1  # 左上叶\nlung_lobe_mask[30:50, 50:150, 60:160] = 2  # 左下叶\n\nprint(f\"存储的标签: {np.unique(lung_lobe_mask)}\")\nprint(f\"数据类型: {lung_lobe_mask.dtype}, 支持 {np.iinfo(lung_lobe_mask.dtype).max} 个互斥类别\")\n\n局限性：无法在同一数组中表示一个跨越区域 1 和 2 的病灶，因为赋值会覆盖已有的肺叶信息。\n\n\n方法 2：位掩膜（Bitmask）\n使用二进制的每一位（bit）代表一个目标。\n优点：通过按位或（OR）运算，允许一个像素同时属于多个类别。 缺点：可表示的目标数量有硬性上限，存储效率较低。\n\n# 示例：使用位掩膜表示重叠\nbit_mask = np.zeros((64, 256, 256), dtype=np.uint8)\n\n# 第0位代表左上叶\nleft_upper_lobe = np.zeros_like(bit_mask); left_upper_lobe[10:30, 50:150, 60:160] = 1\nbit_mask |= (left_upper_lobe &lt;&lt; 0)\n\n# 第2位代表一个重叠的病灶\nlesion = np.zeros_like(bit_mask); lesion[15:35, 60:140, 70:150] = 1\nbit_mask |= (lesion &lt;&lt; 2)\n\nprint(f\"最大可表示的重叠结构数: {bit_mask.dtype.itemsize * 8}\")\n\n局限性：一个 uint8 数组最多支持 8 个可重叠目标，uint64 也仅支持 64 个。这对于需要分割上百个解剖结构（如 TotalSegmentator 数据集）的复杂任务是远远不够的。\n\n\n实际工程中的管理复杂性\n由于上述底层数据结构的限制，目前处理复杂分割任务的普遍做法是：为每个分割目标存储一个独立的掩膜文件。\n\nimport os\nfrom pathlib import Path\n\n# 检查一个全身分割病例的文件存储情况\nmask_dir = 'dicube-testdata/mask/s0000'\nmask_files = list(Path(mask_dir).glob('*.nii.gz'))\n\nprint(f\"单个病例的分割结果包含: {len(mask_files)} 个独立的 .nii.gz 文件\")\nprint(f\"文件总大小: {sum(os.path.getsize(f) for f in mask_files) / 1024 / 1024:.2f} MB\")\n\n这种“一个目标一文件”的模式，导致了数据管理的碎片化，给数据存储、传输和下游处理带来了显著的复杂性。",
    "crumbs": [
      "MedMask",
      "掩膜存储痛点分析"
    ]
  },
  {
    "objectID": "2.0_mask.html#总结",
    "href": "2.0_mask.html#总结",
    "title": "掩膜存储痛点分析",
    "section": "总结",
    "text": "总结\n综上所述，当前通用的分割掩膜存储方法在面对现代医学影像分析的需求时，存在四项相互关联的技术挑战。\n\n\n\n\n\n\n\n\n挑战领域\n技术表现\n对工程实践的影响\n\n\n\n\n空间参考\nNPZ丢失信息，NIfTI坐标系不一致\n增加数据对齐的复杂度和出错风险\n\n\n语义管理\n语义与像素分离，依赖外部管理\n降低数据自洽性，增加多团队协同和版本控制的难度\n\n\n压缩效率\n通用算法未充分利用数据稀疏性\n导致不必要的存储和网络开销，影响I/O性能\n\n\n重叠与互斥\n标准数组结构无法兼顾，导致文件碎片化\n迫使采用复杂的、低效的数据管理和组织方式\n\n\n\n在下一章节中，我们将介绍 MedMask，这是一个专门为医学图像分割掩膜设计的解决方案。我们将详细阐述其如何通过创新的分层式架构和优化的数据结构，来系统性地应对上述挑战。",
    "crumbs": [
      "MedMask",
      "掩膜存储痛点分析"
    ]
  },
  {
    "objectID": "3.1_space_concept_fundamentals.html",
    "href": "3.1_space_concept_fundamentals.html",
    "title": "Space 概念详解",
    "section": "",
    "text": "每一幅医学图像都对应物理世界中的一个规范采样网格。SpaceTransformer 通过 Space 对象的六个要素来完整描述这个网格：形状、原点、间距与三个方向向量。\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom spacetransformer.core import Space\n\n# 创建一个标准的规范采样网格\nstandard_space = Space(\n    shape=(1, 10, 10),               # 三维网格，第一维度为1用于2D可视化\n    origin=(0.0, 0.0, 0.0),          # 物理原点\n    spacing=(1.0, 1.0, 1.0),         # 各向同性1mm采样\n    x_orientation=(1.0, 0.0, 0.0),   # X轴方向\n    y_orientation=(0.0, 1.0, 0.0),   # Y轴方向  \n    z_orientation=(0.0, 0.0, 1.0)    # Z轴方向\n)\n\n# 展示标准规范采样网格\n\n为了直观展示 Space 变换效果，我们实现 2D 网格可视化：\n\ndef visualize_sampling_grid(space, color='blue', show_axes=True, label_suffix=''):\n    \"\"\"\n    可视化采样网格的2D投影（绘制所有采样点）\n    \n    Args:\n        space: Space 对象\n        color: 绘制颜色\n        show_axes: 是否显示坐标轴\n        label_suffix: 标签后缀，用于区分不同的网格\n    \"\"\"\n    # 提取 Y-Z 平面信息（忽略 X 维）\n    shape_yz = space.shape[1:3]  # (height, width)\n    \n    # 创建所有索引点的网格\n    y_indices, z_indices = np.meshgrid(\n        np.arange(shape_yz[0]),\n        np.arange(shape_yz[1]),\n        indexing='ij'\n    )\n    \n    # 构建 3D 索引点（X 维设为 0）\n    index_points = np.stack([\n        np.zeros_like(y_indices.flatten()),  # X=0\n        y_indices.flatten(),                 # Y索引\n        z_indices.flatten()                  # Z索引\n    ], axis=1)\n    \n    # 转换为世界坐标\n    world_points = space.to_world_transform.apply_point(index_points)\n    \n    # 绘制采样点\n    plt.scatter(world_points[:, 2], world_points[:, 1], \n               c=color, alpha=0.4, s=20, label=f'Sampling Grid{label_suffix}')\n    \n    if show_axes:\n        # 显示原点和坐标轴方向\n        origin_world = space.to_world_transform.apply_point([[0, 0, 0]])[0]\n        plt.plot(origin_world[2], origin_world[1], 'o', \n                color=color, markersize=8, alpha=0.8)\n        \n        # 计算坐标轴长度（适当拉长）\n        axis_length = 1\n        \n        # Y 轴方向（图中为垂直）\n        y_axis_end = origin_world[1:3] + np.array(space.y_orientation[1:3]) * axis_length\n        plt.arrow(origin_world[2], origin_world[1], \n                 y_axis_end[1] - origin_world[2], y_axis_end[0] - origin_world[1],\n                 head_width=axis_length*0.1, head_length=axis_length*0.1, \n                 fc=color, ec=color, alpha=0.7)\n        \n        # Y轴文字标注（偏移避免被箭头遮挡）\n        y_text_offset = np.array(space.y_orientation[1:3]) * axis_length * 0.3\n        plt.text(y_axis_end[1] + y_text_offset[1], y_axis_end[0] + y_text_offset[0], 'Y', \n                fontsize=12, color=color, ha='center', va='center', weight='bold')\n        \n        # Z 轴方向（图中为水平）\n        z_axis_end = origin_world[1:3] + np.array(space.z_orientation[1:3]) * axis_length\n        plt.arrow(origin_world[2], origin_world[1],\n                 z_axis_end[1] - origin_world[2], z_axis_end[0] - origin_world[1],\n                 head_width=axis_length*0.1, head_length=axis_length*0.1,\n                 fc=color, ec=color, alpha=0.7)\n        \n        # Z轴文字标注（偏移避免被箭头遮挡）\n        z_text_offset = np.array(space.z_orientation[1:3]) * axis_length * 0.3\n        plt.text(z_axis_end[1] + z_text_offset[1], z_axis_end[0] + z_text_offset[0], 'Z', \n                fontsize=12, color=color, ha='center', va='center', weight='bold')\n\ndef setup_plot(figsize=(10, 8)):\n    \"\"\"设置绘图通用参数\"\"\"\n    plt.figure(figsize=figsize)\n\ndef finalize_plot(title):\n    \"\"\"完成绘图的通用设置\"\"\"\n    plt.xlabel('Z (mm)')\n    plt.ylabel('Y (mm)')\n    plt.title(title)\n    plt.grid(True, alpha=0.3)\n    plt.axis('equal')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n# 可视化标准网格\nsetup_plot()\nvisualize_sampling_grid(standard_space, color='blue')\nfinalize_plot('Standard Sampling Grid (10x10, 1mm resolution)')",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "Space 概念详解"
    ]
  },
  {
    "objectID": "3.1_space_concept_fundamentals.html#space-概念完整的-3d-图像几何描述",
    "href": "3.1_space_concept_fundamentals.html#space-概念完整的-3d-图像几何描述",
    "title": "Space 概念详解",
    "section": "",
    "text": "每一幅医学图像都对应物理世界中的一个规范采样网格。SpaceTransformer 通过 Space 对象的六个要素来完整描述这个网格：形状、原点、间距与三个方向向量。\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom spacetransformer.core import Space\n\n# 创建一个标准的规范采样网格\nstandard_space = Space(\n    shape=(1, 10, 10),               # 三维网格，第一维度为1用于2D可视化\n    origin=(0.0, 0.0, 0.0),          # 物理原点\n    spacing=(1.0, 1.0, 1.0),         # 各向同性1mm采样\n    x_orientation=(1.0, 0.0, 0.0),   # X轴方向\n    y_orientation=(0.0, 1.0, 0.0),   # Y轴方向  \n    z_orientation=(0.0, 0.0, 1.0)    # Z轴方向\n)\n\n# 展示标准规范采样网格\n\n为了直观展示 Space 变换效果，我们实现 2D 网格可视化：\n\ndef visualize_sampling_grid(space, color='blue', show_axes=True, label_suffix=''):\n    \"\"\"\n    可视化采样网格的2D投影（绘制所有采样点）\n    \n    Args:\n        space: Space 对象\n        color: 绘制颜色\n        show_axes: 是否显示坐标轴\n        label_suffix: 标签后缀，用于区分不同的网格\n    \"\"\"\n    # 提取 Y-Z 平面信息（忽略 X 维）\n    shape_yz = space.shape[1:3]  # (height, width)\n    \n    # 创建所有索引点的网格\n    y_indices, z_indices = np.meshgrid(\n        np.arange(shape_yz[0]),\n        np.arange(shape_yz[1]),\n        indexing='ij'\n    )\n    \n    # 构建 3D 索引点（X 维设为 0）\n    index_points = np.stack([\n        np.zeros_like(y_indices.flatten()),  # X=0\n        y_indices.flatten(),                 # Y索引\n        z_indices.flatten()                  # Z索引\n    ], axis=1)\n    \n    # 转换为世界坐标\n    world_points = space.to_world_transform.apply_point(index_points)\n    \n    # 绘制采样点\n    plt.scatter(world_points[:, 2], world_points[:, 1], \n               c=color, alpha=0.4, s=20, label=f'Sampling Grid{label_suffix}')\n    \n    if show_axes:\n        # 显示原点和坐标轴方向\n        origin_world = space.to_world_transform.apply_point([[0, 0, 0]])[0]\n        plt.plot(origin_world[2], origin_world[1], 'o', \n                color=color, markersize=8, alpha=0.8)\n        \n        # 计算坐标轴长度（适当拉长）\n        axis_length = 1\n        \n        # Y 轴方向（图中为垂直）\n        y_axis_end = origin_world[1:3] + np.array(space.y_orientation[1:3]) * axis_length\n        plt.arrow(origin_world[2], origin_world[1], \n                 y_axis_end[1] - origin_world[2], y_axis_end[0] - origin_world[1],\n                 head_width=axis_length*0.1, head_length=axis_length*0.1, \n                 fc=color, ec=color, alpha=0.7)\n        \n        # Y轴文字标注（偏移避免被箭头遮挡）\n        y_text_offset = np.array(space.y_orientation[1:3]) * axis_length * 0.3\n        plt.text(y_axis_end[1] + y_text_offset[1], y_axis_end[0] + y_text_offset[0], 'Y', \n                fontsize=12, color=color, ha='center', va='center', weight='bold')\n        \n        # Z 轴方向（图中为水平）\n        z_axis_end = origin_world[1:3] + np.array(space.z_orientation[1:3]) * axis_length\n        plt.arrow(origin_world[2], origin_world[1],\n                 z_axis_end[1] - origin_world[2], z_axis_end[0] - origin_world[1],\n                 head_width=axis_length*0.1, head_length=axis_length*0.1,\n                 fc=color, ec=color, alpha=0.7)\n        \n        # Z轴文字标注（偏移避免被箭头遮挡）\n        z_text_offset = np.array(space.z_orientation[1:3]) * axis_length * 0.3\n        plt.text(z_axis_end[1] + z_text_offset[1], z_axis_end[0] + z_text_offset[0], 'Z', \n                fontsize=12, color=color, ha='center', va='center', weight='bold')\n\ndef setup_plot(figsize=(10, 8)):\n    \"\"\"设置绘图通用参数\"\"\"\n    plt.figure(figsize=figsize)\n\ndef finalize_plot(title):\n    \"\"\"完成绘图的通用设置\"\"\"\n    plt.xlabel('Z (mm)')\n    plt.ylabel('Y (mm)')\n    plt.title(title)\n    plt.grid(True, alpha=0.3)\n    plt.axis('equal')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n# 可视化标准网格\nsetup_plot()\nvisualize_sampling_grid(standard_space, color='blue')\nfinalize_plot('Standard Sampling Grid (10x10, 1mm resolution)')",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "Space 概念详解"
    ]
  },
  {
    "objectID": "3.1_space_concept_fundamentals.html#空间变换操作演示",
    "href": "3.1_space_concept_fundamentals.html#空间变换操作演示",
    "title": "Space 概念详解",
    "section": "空间变换操作演示",
    "text": "空间变换操作演示\n\n形状变换（Resize）\n\n# 创建不同分辨率的采样网格\nhigh_res_space = standard_space.apply_shape((1, 20, 20))\nlow_res_space = standard_space.apply_shape((1, 5, 5))\n\nsetup_plot()\n# 低分辨率对比\nvisualize_sampling_grid(standard_space, color='blue', label_suffix=' (Original)')\nvisualize_sampling_grid(low_res_space, color='red', label_suffix=' (5x5)')\nfinalize_plot('Low Resolution Transform (10x10 → 5x5)')\n\n\n\n翻转变换\n\n# 创建翻转的采样网格\nflipped_space = standard_space.apply_flip(axis=1)  # 沿Y轴翻转\n\n# 可视化翻转变换的overlay效果\nsetup_plot()\nvisualize_sampling_grid(standard_space, color='blue', label_suffix=' (Original)')\nvisualize_sampling_grid(flipped_space, color='red', label_suffix=' (Flipped Y-axis)')\nfinalize_plot('Flip Transform (Y-axis)')\n\n\n\n轴交换变换\n\n# 创建轴交换的采样网格（使用非正方形网格以增强对比）\nrect_space = Space(\n    shape=(1, 6, 12),  # 矩形网格\n    origin=(0.0, 0.0, 0.0),\n    spacing=(1.0, 1.0, 1.0),\n    x_orientation=(1.0, 0.0, 0.0),\n    y_orientation=(0.0, 1.0, 0.0),\n    z_orientation=(0.0, 0.0, 1.0)\n)\n\nswapped_space = rect_space.apply_swap(1, 2)  # 交换 Y 轴与 Z 轴\n\n# 可视化轴交换变换的overlay效果\nsetup_plot()\nvisualize_sampling_grid(rect_space, color='blue', label_suffix=' (Original 6x12)')\nvisualize_sampling_grid(swapped_space, color='red', label_suffix=' (Swapped Y↔Z 12x6)')\nfinalize_plot('Axis Swap Transform (Y ↔ Z)')\n\n\n\n旋转变换\n\n# 创建旋转的采样网格\nrotated_space = standard_space.apply_rotate(axis=0, angle=30, unit='degree', center='center')\n\n# 可视化旋转变换的overlay效果\nsetup_plot()\nvisualize_sampling_grid(standard_space, color='blue', label_suffix=' (Original)')\nvisualize_sampling_grid(rotated_space, color='red', label_suffix=' (Rotated 30°)')\nfinalize_plot('Rotation Transform (around X-axis 30°)')\n\n\n\n边界框裁剪\n\n# 定义裁剪区域并应用变换\ncrop_bbox = np.array([[0, 1], [2, 8], [2, 8]])  # X, Y, Z范围\ncropped_space = standard_space.apply_bbox(crop_bbox)\n\n# 可视化裁剪变换的overlay效果\nsetup_plot()\nvisualize_sampling_grid(standard_space, color='blue', label_suffix=' (Original)')\nvisualize_sampling_grid(cropped_space, color='red', label_suffix=' (Cropped ROI)')\nfinalize_plot('Bounding Box Crop (6x6 ROI)')\n\n\n\n复杂变换链\n\n# 演示复杂变换链的抽象规划\ncomplex_target_space = (standard_space\n    .apply_bbox(np.array([[0, 1], [2, 8], [2, 8]]))  # 裁剪到中心区域\n    .apply_shape((1, 12, 12))                         # 重采样到12×12\n    .apply_rotate(axis=0, angle=45, unit='degree')    # 旋转45度\n)\n\n# 可视化复杂变换链的 overlay 效果\nsetup_plot()\nvisualize_sampling_grid(standard_space, color='blue', label_suffix=' (Original)')\nvisualize_sampling_grid(complex_target_space, color='red', label_suffix=' (Crop→Resample→Rotate)')\nfinalize_plot('Complex Transform Chain (Crop → Resample → Rotate)')",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "Space 概念详解"
    ]
  },
  {
    "objectID": "3.1_space_concept_fundamentals.html#space-抽象框架的核心优势",
    "href": "3.1_space_concept_fundamentals.html#space-抽象框架的核心优势",
    "title": "Space 概念详解",
    "section": "Space 抽象框架的核心优势",
    "text": "Space 抽象框架的核心优势\n\n设计理念：Space 中心 vs Transform 中心\nSpaceTransformer 采用“Space 中心”的设计理念，区别于 torchvision 等库的“Transform 中心”模式。该选择基于医学图像处理的本质：对象的坐标以世界坐标系为准。\nSpace 中心设计：每个数据对象（图像、点集、掩膜）都绑定唯一空间描述符。当两个对象需要对齐时，通过比较它们的 Space 属性自动生成精确变换关系。\nTransform 中心的局限：变换本质相对，缺乏绝对基准，导致多对象空间关系难维护，容易产生累积误差。\n\n\n技术实现：规划与执行分离\nSpace 类实现了空间变换的“规划阶段”与“执行阶段”完全解耦：\n规划阶段：通过链式调用构建复杂变换序列，所有操作在抽象几何空间进行，无需触碰像素数据。\n执行阶段：warp_image 分析完整变换链，自动选择最优插值路径，以单次采样完成全部变换。\n\n\n实际收益\n几何精度：变换顺序不影响结果。“旋转→缩放”与“缩放→旋转”在 Space 层面等价，避免传统方法受采样边界影响的信息丢失。\n内存效率：消除多步骤变换中的中间缓存；传统每步都需要完整图像拷贝，而 Space 仅在最终执行时分配目标内存一次。\n架构简洁：库中的 warp_xxx 接口处理所有类型变换，无需针对图像/点集/掩膜分别维护复杂逻辑。\n接口易用：相比 SimpleITK 需手工配置采样参数，SpaceTransformer 提供语义化接口，同时保留高级用户的底层控制力。",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "Space 概念详解"
    ]
  },
  {
    "objectID": "1.4_sort_method-en.html",
    "href": "1.4_sort_method-en.html",
    "title": "Slice Sorting Methods",
    "section": "",
    "text": "Pulling a series from PACS or storage usually yields hundreds of loose 2D slices with arbitrary filenames. To stack them into the correct 3D volume, we must decide how to order the slices.\nWhat looks simple hides conflicting requirements from clinical workflow, rendering engines, and AI pipelines. Each sorting rule has valid use cases yet can break under other scenarios.\n\n\n\nClinical reporting: Radiologists reference lesions by InstanceNumber (e.g., “lesion on slice X”). Most PACS viewers default to InstanceNumber, so clinical workflows expect this order.\nAI standardization: Models prefer anatomical order (“head→feet” or the inverse), typically using SliceLocation or ImagePositionPatient. This yields consistent spatial patterns for learning.\nNon‑standard scans: Oblique acquisitions (e.g., cardiac MR) or reconstructions (e.g., coronal reformat) may lack SliceLocation, and picking the proper component from ImagePositionPatient is non‑trivial.\n3D rendering constraints: Engines like VTK assume right‑handed coordinates; incorrect ordering can mirror the volume (“left/right swap”).\n\nGiven these trade‑offs, we recommend right‑handed coordinate sorting as the default.\n\n\n\n\nLeast modification cost: Algorithms and renderers operate on full 3D arrays. Flipping or reordering requires heavy memory operations. Viewers, in contrast, can remap indices without moving pixels. Standardizing slices for compute‑heavy components keeps conversions lightweight downstream.\nAlignment with rendering/ITK/VTK: Right‑handed ordering matches the dominant assumption in visualization toolkits, reducing extra transforms.\nStandard compliance: It respects DICOM’s LPS+ convention.\n\n\n\n\nRead ImageOrientationPatient to obtain in‑plane X/Y direction vectors. Their cross product yields the normal. Project each ImagePositionPatient onto the normal and sort ascending; this guarantees a right‑handed stack.\n\n\n\nA few vendors mis‑calibrate world coordinates and ship left‑handed geometry. Sorting alone cannot detect it and the result still mirrors. Detecting such anomalies requires additional analysis because metadata remains ambiguous.",
    "crumbs": [
      "首页",
      "DiCube",
      "Slice Sorting Methods"
    ]
  },
  {
    "objectID": "1.4_sort_method-en.html#why-sort-dicom-series",
    "href": "1.4_sort_method-en.html#why-sort-dicom-series",
    "title": "Slice Sorting Methods",
    "section": "",
    "text": "Pulling a series from PACS or storage usually yields hundreds of loose 2D slices with arbitrary filenames. To stack them into the correct 3D volume, we must decide how to order the slices.\nWhat looks simple hides conflicting requirements from clinical workflow, rendering engines, and AI pipelines. Each sorting rule has valid use cases yet can break under other scenarios.\n\n\n\nClinical reporting: Radiologists reference lesions by InstanceNumber (e.g., “lesion on slice X”). Most PACS viewers default to InstanceNumber, so clinical workflows expect this order.\nAI standardization: Models prefer anatomical order (“head→feet” or the inverse), typically using SliceLocation or ImagePositionPatient. This yields consistent spatial patterns for learning.\nNon‑standard scans: Oblique acquisitions (e.g., cardiac MR) or reconstructions (e.g., coronal reformat) may lack SliceLocation, and picking the proper component from ImagePositionPatient is non‑trivial.\n3D rendering constraints: Engines like VTK assume right‑handed coordinates; incorrect ordering can mirror the volume (“left/right swap”).\n\nGiven these trade‑offs, we recommend right‑handed coordinate sorting as the default.\n\n\n\n\nLeast modification cost: Algorithms and renderers operate on full 3D arrays. Flipping or reordering requires heavy memory operations. Viewers, in contrast, can remap indices without moving pixels. Standardizing slices for compute‑heavy components keeps conversions lightweight downstream.\nAlignment with rendering/ITK/VTK: Right‑handed ordering matches the dominant assumption in visualization toolkits, reducing extra transforms.\nStandard compliance: It respects DICOM’s LPS+ convention.\n\n\n\n\nRead ImageOrientationPatient to obtain in‑plane X/Y direction vectors. Their cross product yields the normal. Project each ImagePositionPatient onto the normal and sort ascending; this guarantees a right‑handed stack.\n\n\n\nA few vendors mis‑calibrate world coordinates and ship left‑handed geometry. Sorting alone cannot detect it and the result still mirrors. Detecting such anomalies requires additional analysis because metadata remains ambiguous.",
    "crumbs": [
      "首页",
      "DiCube",
      "Slice Sorting Methods"
    ]
  },
  {
    "objectID": "1.4_sort_method-en.html#visual-verification",
    "href": "1.4_sort_method-en.html#visual-verification",
    "title": "Slice Sorting Methods",
    "section": "Visual Verification",
    "text": "Visual Verification\nPlot axial/coronal/sagittal slices to confirm correct spatial arrangement.\n\nimport dicube\nfrom dicube import SortMethod\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndirname = 'dicube-testdata/dicom/sample_200'\nimg_rh = dicube.load_from_dicom_folder(dirname, sort_method=SortMethod.POSITION_RIGHT_HAND)\n\nprint(\"=== Right-Handed Sorting ===\")\nprint(\"Shape:\", img_rh.raw_image.shape)\nprint(\"Sort method: POSITION_RIGHT_HAND\")\n\ndef get_center_slices(image_data):\n    \"\"\"Return center slices along three axes.\"\"\"\n    z = image_data.shape[0] // 2\n    y = image_data.shape[1] // 2\n    x = image_data.shape[2] // 2\n    return {\n        'axial': image_data[z, :, :],\n        'coronal': image_data[:, y, :],\n        'sagittal': image_data[:, :, x]\n    }\n\nslices_rh = get_center_slices(img_rh.get_fdata())\n\nfig1, ax1 = plt.subplots(figsize=(8, 6))\nax1.imshow(slices_rh['axial'], cmap='gray', origin='lower')\nax1.set_title(f'Axial slice {img_rh.raw_image.shape[0]//2} / {img_rh.raw_image.shape[0]}')\nax1.set_xlabel('Axis 2 (X): Right → Left')\nax1.set_ylabel('Axis 1 (Y): Anterior → Posterior')\nplt.tight_layout(); plt.show()\n\nfig2, ax2 = plt.subplots(figsize=(8, 6))\nax2.imshow(slices_rh['coronal'], cmap='gray', origin='lower')\nax2.set_title(f'Coronal slice {img_rh.raw_image.shape[1]//2} / {img_rh.raw_image.shape[1]}')\nax2.set_xlabel('Axis 2 (X): Right → Left')\nax2.set_ylabel('Axis 0 (Z): Inferior → Superior')\nplt.tight_layout(); plt.show()\n\nfig3, ax3 = plt.subplots(figsize=(8, 6))\nax3.imshow(slices_rh['sagittal'], cmap='gray', origin='lower')\nax3.set_title(f'Sagittal slice {img_rh.raw_image.shape[2]//2} / {img_rh.raw_image.shape[2]}')\nax3.set_xlabel('Axis 1 (Y): Anterior → Posterior')\nax3.set_ylabel('Axis 0 (Z): Inferior → Superior')\nplt.tight_layout(); plt.show()",
    "crumbs": [
      "首页",
      "DiCube",
      "Slice Sorting Methods"
    ]
  },
  {
    "objectID": "1.4_sort_method-en.html#best-practices",
    "href": "1.4_sort_method-en.html#best-practices",
    "title": "Slice Sorting Methods",
    "section": "Best Practices",
    "text": "Best Practices\n\nRendering compatibility: VTK/ITK assume right‑handed coordinates. Sorting accordingly avoids extra transforms.\nStandards compliance: Matches DICOM’s LPS+ orientation.\nAI stability: Prevents mirrored inputs across training/inference environments.\nRuntime efficiency: Minimizes on‑the‑fly reordering in performance‑critical modules.",
    "crumbs": [
      "首页",
      "DiCube",
      "Slice Sorting Methods"
    ]
  },
  {
    "objectID": "1.2_meta_storage-en.html",
    "href": "1.2_meta_storage-en.html",
    "title": "Metadata Storage Mechanism",
    "section": "",
    "text": "DICOM’s one‑file‑per‑slice model leads to heavy repetition of series‑level metadata across hundreds of files. Only a few fields vary per slice (e.g., InstanceNumber, ImagePositionPatient). This bloats storage and hurts I/O when scanning entire series for a single field.\n\nimport pydicom, os\nfrom pathlib import Path\n\ndicom_dir = \"dicube-testdata/dicom/sample_200\"\ndicom_files = list(Path(dicom_dir).glob(\"*\"))[:2]\nds1 = pydicom.dcmread(dicom_files[0], stop_before_pixels=True)\nds2 = pydicom.dcmread(dicom_files[1], stop_before_pixels=True)\n\nprint(\"PatientName same:\", ds1.PatientName == ds2.PatientName)\nprint(\"SeriesInstanceUID same:\", ds1.SeriesInstanceUID == ds2.SeriesInstanceUID)\nprint(\"InstanceNumber same:\", ds1.InstanceNumber == ds2.InstanceNumber)",
    "crumbs": [
      "首页",
      "DiCube",
      "Metadata Storage Mechanism"
    ]
  },
  {
    "objectID": "1.2_meta_storage-en.html#legacy-dicom-pattern-redundant-headers",
    "href": "1.2_meta_storage-en.html#legacy-dicom-pattern-redundant-headers",
    "title": "Metadata Storage Mechanism",
    "section": "",
    "text": "DICOM’s one‑file‑per‑slice model leads to heavy repetition of series‑level metadata across hundreds of files. Only a few fields vary per slice (e.g., InstanceNumber, ImagePositionPatient). This bloats storage and hurts I/O when scanning entire series for a single field.\n\nimport pydicom, os\nfrom pathlib import Path\n\ndicom_dir = \"dicube-testdata/dicom/sample_200\"\ndicom_files = list(Path(dicom_dir).glob(\"*\"))[:2]\nds1 = pydicom.dcmread(dicom_files[0], stop_before_pixels=True)\nds2 = pydicom.dcmread(dicom_files[1], stop_before_pixels=True)\n\nprint(\"PatientName same:\", ds1.PatientName == ds2.PatientName)\nprint(\"SeriesInstanceUID same:\", ds1.SeriesInstanceUID == ds2.SeriesInstanceUID)\nprint(\"InstanceNumber same:\", ds1.InstanceNumber == ds2.InstanceNumber)",
    "crumbs": [
      "首页",
      "DiCube",
      "Metadata Storage Mechanism"
    ]
  },
  {
    "objectID": "1.2_meta_storage-en.html#embracing-dicom-json",
    "href": "1.2_meta_storage-en.html#embracing-dicom-json",
    "title": "Metadata Storage Mechanism",
    "section": "2. Embracing DICOM JSON",
    "text": "2. Embracing DICOM JSON\nDICOM PS3.18 defines a JSON model for headers—human‑readable and tool‑friendly. DiCube adopts it internally to maximize interoperability and future‑proofing.\n\nimport json\nds = pydicom.dcmread(dicom_files[0], stop_before_pixels=True)\ndicom_json_str = ds.to_json()\ndata = json.loads(dicom_json_str)\nfor tag in [\"00100010\",\"00080021\",\"00200013\"]:  # PatientName, SeriesDate, InstanceNumber\n    if tag in data:\n        vr = data[tag][\"vr\"]\n        value = data[tag].get(\"Value\", [\"N/A\"])[0]\n        print(f\"Tag {tag} (VR: {vr}): {value}\")",
    "crumbs": [
      "首页",
      "DiCube",
      "Metadata Storage Mechanism"
    ]
  },
  {
    "objectID": "1.2_meta_storage-en.html#dicommeta-split-shared-vs-perslice",
    "href": "1.2_meta_storage-en.html#dicommeta-split-shared-vs-perslice",
    "title": "Metadata Storage Mechanism",
    "section": "3. DicomMeta: Split Shared vs Per‑Slice",
    "text": "3. DicomMeta: Split Shared vs Per‑Slice\nDiCube’s DicomMeta separates shared vs per‑slice fields to remove redundancy and enable O(1) shared lookups and fast vectorized per‑slice queries.\n\nimport dicube\nfrom dicube.dicom import CommonTags\n\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, \"temp_demo.dcbs\")\nmeta = dicube.load_meta(\"temp_demo.dcbs\")\nmeta.display()\n\npatient_name = meta.get_shared_value(CommonTags.PatientName)\nprint(\"PatientName:\", patient_name, \"(shared)\")\n\ninstance_numbers = meta.get_values(CommonTags.InstanceNumber)\nprint(\"InstanceNumber count:\", len(instance_numbers))",
    "crumbs": [
      "首页",
      "DiCube",
      "Metadata Storage Mechanism"
    ]
  },
  {
    "objectID": "1.2_meta_storage-en.html#extreme-compression-json-zstandard",
    "href": "1.2_meta_storage-en.html#extreme-compression-json-zstandard",
    "title": "Metadata Storage Mechanism",
    "section": "4. Extreme Compression: JSON + Zstandard",
    "text": "4. Extreme Compression: JSON + Zstandard\nStructured, repetitive text (JSON) compresses extremely well with Zstandard (zstd).\n\nfrom pathlib import Path\nimport zstandard as zstd\nimport numpy as np\n\nall_files = list(Path(dicom_dir).glob(\"*\"))\ndicom_header_total_size = 0\nfor f in all_files:\n    total_size = os.path.getsize(f)\n    ds = pydicom.dcmread(f)\n    pixel_size = ds.pixel_array.nbytes if hasattr(ds,'pixel_array') else 0\n    dicom_header_total_size += (total_size - pixel_size)\n\nmeta_json_str = meta.to_json()\ncompressed = zstd.ZstdCompressor(level=9).compress(meta_json_str.encode('utf-8'))\nprint(\"DICOM header total (est.):\", dicom_header_total_size/1024, \"KB\")\nprint(\"DiCube meta (zstd):\", len(compressed)/1024, \"KB\")",
    "crumbs": [
      "首页",
      "DiCube",
      "Metadata Storage Mechanism"
    ]
  },
  {
    "objectID": "1.2_meta_storage-en.html#developer-ergonomics-commontags",
    "href": "1.2_meta_storage-en.html#developer-ergonomics-commontags",
    "title": "Metadata Storage Mechanism",
    "section": "5. Developer Ergonomics: CommonTags",
    "text": "5. Developer Ergonomics: CommonTags\nSemantic tag enums replace error‑prone hex codes and improve readability.\n\ninstance_numbers = meta.get_values(CommonTags.InstanceNumber)\npositions = meta.get_values(CommonTags.ImagePositionPatient)\nprint(\"Instance range:\", min(instance_numbers), \"-\", max(instance_numbers))\nprint(\"Z range:\", positions[0][2], \"→\", positions[-1][2])",
    "crumbs": [
      "首页",
      "DiCube",
      "Metadata Storage Mechanism"
    ]
  },
  {
    "objectID": "1.2_meta_storage-en.html#performance-leap",
    "href": "1.2_meta_storage-en.html#performance-leap",
    "title": "Metadata Storage Mechanism",
    "section": "6. Performance Leap",
    "text": "6. Performance Leap\nVectorized metadata access vs file‑by‑file parsing delivers order‑of‑magnitude wins.\n\nimport time\n\nstart = time.time();\ndicom_instance_numbers = []\nfor f in all_files:\n    ds = pydicom.dcmread(f, stop_before_pixels=True)\n    dicom_instance_numbers.append(int(ds.InstanceNumber))\ndicom_ms = (time.time()-start)*1000\n\nstart = time.time();\ndicube_instance_numbers = meta.get_values(CommonTags.InstanceNumber)\ndicube_ms = (time.time()-start)*1000\n\nprint(f\"DICOM: {dicom_ms:.2f} ms, DiCube: {dicube_ms:.2f} ms, Speedup: {dicom_ms/dicube_ms:.1f}×\")\nos.remove(\"temp_demo.dcbs\")",
    "crumbs": [
      "首页",
      "DiCube",
      "Metadata Storage Mechanism"
    ]
  },
  {
    "objectID": "1.2_meta_storage-en.html#summary",
    "href": "1.2_meta_storage-en.html#summary",
    "title": "Metadata Storage Mechanism",
    "section": "7. Summary",
    "text": "7. Summary\n\nRemove redundancy by splitting shared/per‑slice; JSON + zstd yields tiny headers\nMillisecond‑level access for common queries; ideal for listing, previews, and AI\nStandards‑aligned (DICOM JSON), future‑proof and interoperable",
    "crumbs": [
      "首页",
      "DiCube",
      "Metadata Storage Mechanism"
    ]
  },
  {
    "objectID": "1.5_axis_order-en.html",
    "href": "1.5_axis_order-en.html",
    "title": "3D Axis Order Convention",
    "section": "",
    "text": "SimpleITK.Image.GetSize() reports dimensions in (X, Y, Z), while sitk.GetArrayFromImage(image) returns a NumPy array with shape (Z, Y, X). Example:\n\nimport SimpleITK as sitk\ndirname = \"dicube-testdata/dicom/sample_200\"\n\nreader = sitk.ImageSeriesReader()\ndicom_names = reader.GetGDCMSeriesFileNames(dirname)\nreader.SetFileNames(dicom_names)\nsitk_image = reader.Execute()\n\nprint(\"GetSize -&gt;\", sitk_image.GetSize(), \"(X, Y, Z)\")\narray = sitk.GetArrayFromImage(sitk_image)\nprint(\"array.shape -&gt;\", array.shape, \"(Z, Y, X)\")\n\nThe mismatch comes from historical row‑major (C order) vs column‑major (Fortran order) memory layouts across ecosystems.",
    "crumbs": [
      "首页",
      "DiCube",
      "3D Axis Order Convention"
    ]
  },
  {
    "objectID": "1.5_axis_order-en.html#problem-simpleitk-axis-order-mismatch",
    "href": "1.5_axis_order-en.html#problem-simpleitk-axis-order-mismatch",
    "title": "3D Axis Order Convention",
    "section": "",
    "text": "SimpleITK.Image.GetSize() reports dimensions in (X, Y, Z), while sitk.GetArrayFromImage(image) returns a NumPy array with shape (Z, Y, X). Example:\n\nimport SimpleITK as sitk\ndirname = \"dicube-testdata/dicom/sample_200\"\n\nreader = sitk.ImageSeriesReader()\ndicom_names = reader.GetGDCMSeriesFileNames(dirname)\nreader.SetFileNames(dicom_names)\nsitk_image = reader.Execute()\n\nprint(\"GetSize -&gt;\", sitk_image.GetSize(), \"(X, Y, Z)\")\narray = sitk.GetArrayFromImage(sitk_image)\nprint(\"array.shape -&gt;\", array.shape, \"(Z, Y, X)\")\n\nThe mismatch comes from historical row‑major (C order) vs column‑major (Fortran order) memory layouts across ecosystems.",
    "crumbs": [
      "首页",
      "DiCube",
      "3D Axis Order Convention"
    ]
  },
  {
    "objectID": "1.5_axis_order-en.html#background-rowmajor-vs-columnmajor",
    "href": "1.5_axis_order-en.html#background-rowmajor-vs-columnmajor",
    "title": "3D Axis Order Convention",
    "section": "2. Background: Row‑Major vs Column‑Major",
    "text": "2. Background: Row‑Major vs Column‑Major\n\nRow‑major (C order): used by C/C++/Python/NumPy; a 3D image is accessed as (Z, Y, X).\nColumn‑major (Fortran order): used by Fortran/MATLAB/R; follows (X, Y, Z).\n\nITK/VTK/DICOM inherit Fortran conventions, hence SimpleITK exposes (X, Y, Z) metadata while exposing raw memory to NumPy as (Z, Y, X) for zero‑copy.",
    "crumbs": [
      "首页",
      "DiCube",
      "3D Axis Order Convention"
    ]
  },
  {
    "objectID": "1.5_axis_order-en.html#zerocopy-conversion-and-its-side-effects",
    "href": "1.5_axis_order-en.html#zerocopy-conversion-and-its-side-effects",
    "title": "3D Axis Order Convention",
    "section": "3. Zero‑Copy Conversion And Its Side Effects",
    "text": "3. Zero‑Copy Conversion And Its Side Effects\nSimpleITK exposes ITK memory to NumPy without reordering. By adjusting shape/strides, NumPy interprets column‑major data as row‑major without copying.\n\nimport numpy as np\n\noriginal = np.arange(10)\nprint(\"Original linear data:\", original)\n\nc_array = np.reshape(original, (2,5), order='C')\nprint(\"\\nC-order array:\\n\", c_array)\nprint(\"C-order strides:\", c_array.strides)\n\nf_array = np.reshape(original, (5,2), order='F')\nprint(\"\\nF-order array:\\n\", f_array)\nprint(\"F-order strides:\", f_array.strides)\n\nZero‑copy is fast but flips axes (X,Y,Z) → (Z,Y,X), increasing cognitive load and risk.",
    "crumbs": [
      "首页",
      "DiCube",
      "3D Axis Order Convention"
    ]
  },
  {
    "objectID": "1.5_axis_order-en.html#practical-issues",
    "href": "1.5_axis_order-en.html#practical-issues",
    "title": "3D Axis Order Convention",
    "section": "4. Practical Issues",
    "text": "4. Practical Issues\n\n4.1. Cognitive Load\n\nMetadata mismatch: image.GetSpacing() returns (X,Y,Z) but NumPy arrays use (Z,Y,X).\nIndexing mistakes: intuitive array[x, y, z] fails; correct form is array[z, y, x].\nAPI parameters: functions like scipy.ndimage.zoom expect matching axis order; easy to misalign.\n\n\n\n4.2. Performance Cost Of Manual Fixes\nNaively calling .transpose(2,1,0) produces a non‑contiguous view. Many libraries require contiguous arrays, forcing np.ascontiguousarray() (full copy + extra memory).\n\nimport numpy as np, time\n\nlarge = np.random.rand(399,400,401).astype(np.float32)\nprint(\"Original C-contiguous:\", large.flags['C_CONTIGUOUS'])\n\ntransposed = large.transpose(2,1,0)\nprint(\"Transposed C-contiguous:\", transposed.flags['C_CONTIGUOUS'])\n\ndef benchmark(arr, name):\n    start = time.time(); _ = np.sum(arr[60:100] * 2.0 + 1.0); ms = (time.time()-start)*1000\n    print(f\"  {name}: {ms:.2f} ms\"); return ms\n\norig_ms = benchmark(large, \"original contiguous\")\nview_ms = benchmark(transposed, \"transposed view\")\nprint(f\"  Slowdown: {(view_ms/orig_ms-1)*100:.1f}%\")\n\nstart = time.time(); contiguous = np.ascontiguousarray(transposed); copy_ms = (time.time()-start)*1000\nprint(f\"ascontiguousarray copy: {copy_ms:.1f} ms, extra memory: {contiguous.nbytes/1024/1024:.1f} MB\")\n\nDeep learning frameworks, CUDA/OpenCL, ONNX, and many imaging libraries require contiguous buffers—making the copy unavoidable.",
    "crumbs": [
      "首页",
      "DiCube",
      "3D Axis Order Convention"
    ]
  },
  {
    "objectID": "1.5_axis_order-en.html#dicubes-approach-unified-axis-order",
    "href": "1.5_axis_order-en.html#dicubes-approach-unified-axis-order",
    "title": "3D Axis Order Convention",
    "section": "5. DiCube’s Approach: Unified Axis Order",
    "text": "5. DiCube’s Approach: Unified Axis Order\ndicube.load_from_dicom_folder() resolves axis order once during load:\n\nRead data/metadata.\nInterpret memory as (Z, Y, X) in C‑contiguous fashion without copying.\nFlip space metadata so spacing/origin/orientation also follow (Z, Y, X).\n\nResult: arrays and metadata align; downstream code can treat everything as (Z, Y, X).\n\nimport dicube\n\ndcb_image = dicube.load_from_dicom_folder(dirname, sort_method=dicube.SortMethod.POSITION_RIGHT_HAND)\n\nprint(\"--- DiCube (consistent) ---\")\nprint(\"array.shape -&gt;\", dcb_image.get_fdata().shape, \"(Z, Y, X)\")\nprint(\"space.spacing -&gt;\", dcb_image.space.spacing, \"(Z, Y, X)\")\n\nprint(\"\\n--- SimpleITK (mixed) ---\")\nprint(\"array.shape -&gt;\", array.shape, \"(Z, Y, X)\")\nprint(\"image.GetSpacing() -&gt;\", sitk_image.GetSpacing(), \"(X, Y, Z)\")\n\nDiCube avoids extra rearrangements while exposing an intuitive API, eliminating axis confusion and fragile conversions.",
    "crumbs": [
      "首页",
      "DiCube",
      "3D Axis Order Convention"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html",
    "href": "1.6_dicom_compatibility_simple.html",
    "title": "DICOM兼容性保证",
    "section": "",
    "text": "DiCube作为高效的医学影像存储方案，需要与现有DICOM生态系统无缝集成，以确保PACS厂商能够顺利采用这一技术。\n为解决这一需求，DiCube提供了DcbStreamingReader组件，它能够将压缩的DCBS文件实时转换为标准DICOM格式，有效地模拟传统PACS后端的数据分发功能。这种设计使得下游应用可以透明地访问DiCube存储的数据，而无需修改现有的DICOM处理流程。",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM兼容性保证"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html#问题背景pacs-系统集成需求",
    "href": "1.6_dicom_compatibility_simple.html#问题背景pacs-系统集成需求",
    "title": "DICOM兼容性保证",
    "section": "",
    "text": "DiCube作为高效的医学影像存储方案，需要与现有DICOM生态系统无缝集成，以确保PACS厂商能够顺利采用这一技术。\n为解决这一需求，DiCube提供了DcbStreamingReader组件，它能够将压缩的DCBS文件实时转换为标准DICOM格式，有效地模拟传统PACS后端的数据分发功能。这种设计使得下游应用可以透明地访问DiCube存储的数据，而无需修改现有的DICOM处理流程。",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM兼容性保证"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html#流式读取机制技术实现与性能优势",
    "href": "1.6_dicom_compatibility_simple.html#流式读取机制技术实现与性能优势",
    "title": "DICOM兼容性保证",
    "section": "2. 流式读取机制：技术实现与性能优势",
    "text": "2. 流式读取机制：技术实现与性能优势\n\n2.1. 基本使用接口\nDiCube的流式读取器提供了简洁的API接口，支持按帧索引动态生成DICOM数据：\n\nimport dicube\nfrom dicube.dicom import DcbStreamingReader\n\n# 初始化流式读取器\ndicom_dir = 'dicube-testdata/dicom/sample_10'\ndcb_file = 'dicube-testdata/sample_10.dcbs'\n\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, dcb_file)\ndcb_stream = DcbStreamingReader(dcb_file)\n\n# 按需提取指定帧的DICOM数据\nslice_0 = dcb_stream.get_dicom_for_frame(0)\nwith open('dicube-testdata/sample_10_0.dcm', 'wb') as f:\n    f.write(slice_0)\nprint(f\"✅ 成功生成DICOM数据，大小: {len(slice_0)} 字节\")\n\n\n\n2.2. 数据处理与可视化分析\n流式读取器生成的DICOM数据完全符合标准规范，可以直接被PyDICOM等主流库处理：\n\nimport pydicom\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom io import BytesIO\n\ndef analyze_dicom_slice(slice_index):\n    \"\"\"分析并显示指定索引的DICOM切片\"\"\"\n    # 获取DICOM字节流并解析\n    dicom_buffer = BytesIO(dcb_stream.get_dicom_for_frame(slice_index))\n    dataset = pydicom.dcmread(dicom_buffer, force=True)\n\n    # 提取并校正像素数据\n    pixel_array = dataset.pixel_array.astype('float32')\n    if hasattr(dataset, 'RescaleIntercept'):\n        pixel_array += float(dataset.RescaleIntercept)\n\n    # 使用临床标准窗位窗宽显示\n    plt.figure(figsize=(8, 6))\n    plt.imshow(pixel_array, cmap='gray', vmin=-800, vmax=300)  # 肺窗标准参数\n    plt.axis('off')\n    plt.title(f\"DICOM Slice #{slice_index}\")\n    plt.tight_layout()\n    plt.show()\n    \n    return dataset\n\n# 分析多个代表性切片\nfor slice_idx in [0, 4, 8]:\n    dataset = analyze_dicom_slice(slice_idx)\n\n这种流式处理方式的核心优势在于按需转换：系统只在实际访问时才进行DCBS到DICOM的转换，避免了预先转换整个序列所带来的存储开销和延迟。",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM兼容性保证"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html#编码兼容性挑战htj2k-标准的生态现状",
    "href": "1.6_dicom_compatibility_simple.html#编码兼容性挑战htj2k-标准的生态现状",
    "title": "DICOM兼容性保证",
    "section": "3. 编码兼容性挑战：HTJ2K 标准的生态现状",
    "text": "3. 编码兼容性挑战：HTJ2K 标准的生态现状\n\n3.1. 技术标准演进背景\nDiCube 采用的 DCBS 格式基于 HTJ2K（High Throughput JPEG 2000） 编码器，该技术于 2023 年被 DICOM 标准委员会纳入官方规范。HTJ2K 相比传统 JPEG 2000 具有显著优势：\n\n编码速度提升：相比标准 JPEG 2000，编码效率提高约 10–15 倍\n压缩质量保持：在相同压缩比下保持无损或近无损的图像质量\n硬件友好性：更适合 GPU 并行与硬件实现\n\n然而，作为一个相对较新的标准，HTJ2K在现有医学影像生态系统中的支持程度存在显著差异。\n\n\n3.2. 当前兼容性状况分析\n基于测试与调研，我们梳理了主要工具和平台对 HTJ2K 编码 DICOM 文件的支持状况：\n✅ 已支持的工具链\n\nPyDICOM ≥ 3.0.0：需配合 pylibjpeg-openjpeg &gt; 2.0 与 pylibjpeg &gt; 2.0\nPython-GDCM 3.0.26：原生支持 HTJ2K 解码\nITK-SNAP 4.4.0：可视化工具，支持 HTJ2K\n\n❌ 尚未支持的工具\n\nHoros 4.0.1：Mac 平台 DICOM 查看器\nSimpleITK 2.5.2：影响部分 Python 科学计算工作流\n\n\n\n3.3. 最大兼容性解决方案\n针对兼容性挑战，DiCube 提供“强制解压缩”选项，通过 force_uncompressed=True 生成未压缩的 DICOM：\n\n# 生成最大兼容性的未压缩DICOM\nuncompressed_dicom = dcb_stream.get_dicom_for_frame(0, force_uncompressed=True)\n\n这种方案的权衡分析：\n优势： - 广泛兼容：未压缩 DICOM 几乎被所有医学影像工具支持 - 处理简单：无需考虑解码器依赖和版本问题 - 传输可靠：网络传输中不存在解码失败风险\n劣势： - 文件体积：未压缩文件通常比 HTJ2K 压缩版本大 5–10 倍 - 网络负载：增加 PACS 系统的存储与带宽压力 - 传输延迟：大文件传输时间显著增加",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM兼容性保证"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple.html#部署建议渐进式兼容性策略",
    "href": "1.6_dicom_compatibility_simple.html#部署建议渐进式兼容性策略",
    "title": "DICOM兼容性保证",
    "section": "4. 部署建议：渐进式兼容性策略",
    "text": "4. 部署建议：渐进式兼容性策略\n在实际部署中，建议采用渐进式兼容性策略：\n\n环境评估：首先测试目标PACS环境对HTJ2K的支持程度\n混合部署：对支持HTJ2K的新系统使用压缩格式，对旧系统fallback到未压缩格式\n监控升级：跟踪关键依赖库的更新，逐步扩大HTJ2K的使用范围\n\n这种策略平衡了技术先进性与现实兼容性的需求，为DiCube在医疗机构的广泛采用提供了可行路径。",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM兼容性保证"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation-en.html",
    "href": "3.0_spacetransformer_motivation-en.html",
    "title": "SpaceTransformer Motivation",
    "section": "",
    "text": "Standard pipelines—crop ROI → resample → analyze → map results back—are error-prone with mainstream libraries (SimpleITK, scipy.ndimage, PyTorch). We compare them and show how SpaceTransformer provides accurate transforms with concise code.",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "SpaceTransformer Motivation"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation-en.html#introduction-space-transforms-are-harder-than-they-look",
    "href": "3.0_spacetransformer_motivation-en.html#introduction-space-transforms-are-harder-than-they-look",
    "title": "SpaceTransformer Motivation",
    "section": "",
    "text": "Standard pipelines—crop ROI → resample → analyze → map results back—are error-prone with mainstream libraries (SimpleITK, scipy.ndimage, PyTorch). We compare them and show how SpaceTransformer provides accurate transforms with concise code.",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "SpaceTransformer Motivation"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation-en.html#test-setup",
    "href": "3.0_spacetransformer_motivation-en.html#test-setup",
    "title": "SpaceTransformer Motivation",
    "section": "Test Setup",
    "text": "Test Setup\nSynthetic 35×35 image with a 9×9 square and a central keypoint. Crop a 15×15 ROI (slightly offset), resample to 32×32, run segmentation + keypoint detection, map results back to the original grid.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef create_test_image():\n    img = np.zeros((35,35), dtype=np.float32)\n    c = 35 // 2\n    half = 4\n    img[c-half:c+half+1, c-half:c+half+1] = 1.0\n    img[c, c] = 5\n    return img\n\ndef get_segmentation(img, threshold=0.5):\n    return (img &gt;= threshold).astype(np.uint8)\n\ndef get_keypoint(img):\n    candidates = np.array(np.where(img &gt;= 3))\n    if candidates.size &gt; 0:\n        y = candidates[0].mean()\n        x = candidates[1].mean()\n        return np.array([y, x])\n    return np.array([0.0, 0.0])\n\nROI_START_Y = 10; ROI_START_X = 10; ROI_SIZE = 15\nROI_END_Y = ROI_START_Y + ROI_SIZE\nROI_END_X = ROI_START_X + ROI_SIZE\nTARGET_SIZE = 32\n\noriginal_img = create_test_image()\ntrue_keypoint = np.array([17, 17])\nprint(\"Original shape:\", original_img.shape)\n\nHelper for plotting results.\n\ndef plot_result(original_img, segment_result, keypoint_result, method_name, true_keypoint):\n    plt.figure(figsize=(8,6))\n    plt.imshow(original_img, cmap='gray', alpha=0.7)\n    if segment_result is not None:\n        plt.contour(segment_result, levels=[0.5], colors='red', linewidths=2)\n    if keypoint_result is not None and len(keypoint_result)&gt;0:\n        if keypoint_result.ndim == 1:\n            plt.plot(keypoint_result[1], keypoint_result[0], 'ro', markersize=8, label='Detected')\n        else:\n            plt.plot(keypoint_result[0,1], keypoint_result[0,0], 'ro', markersize=8, label='Detected')\n    plt.plot(true_keypoint[1], true_keypoint[0], 'g+', markersize=12, markeredgewidth=3, label='Ground Truth')\n    if keypoint_result is not None and len(keypoint_result)&gt;0:\n        err = np.linalg.norm((keypoint_result if keypoint_result.ndim==1 else keypoint_result[0]) - true_keypoint)\n        plt.text(0.02, 0.98, f'Error: {err:.3f}px', transform=plt.gca().transAxes,\n                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.8), va='top')\n    plt.title(f'{method_name} Result')\n    plt.legend(); plt.grid(True, alpha=0.3)\n    plt.tight_layout(); plt.show()",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "SpaceTransformer Motivation"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation-en.html#pipeline-definition",
    "href": "3.0_spacetransformer_motivation-en.html#pipeline-definition",
    "title": "SpaceTransformer Motivation",
    "section": "Pipeline Definition",
    "text": "Pipeline Definition\n\nCrop: extract 15×15 ROI from 35×35 image\nResample: resize ROI to 32×32\nAnalyze: segmentation + keypoint detection\nMap back: transform results to original space\n\nWe implement with different libraries.",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "SpaceTransformer Motivation"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation-en.html#method-1-simpleitk",
    "href": "3.0_spacetransformer_motivation-en.html#method-1-simpleitk",
    "title": "SpaceTransformer Motivation",
    "section": "Method 1: SimpleITK",
    "text": "Method 1: SimpleITK\n\nimport SimpleITK as sitk\n\ndef process_with_simpleitk(img):\n    sitk_img = sitk.GetImageFromArray(img)\n    sitk_img.SetSpacing([1.0, 1.0]); sitk_img.SetOrigin([0.0, 0.0])\n\n    roi_size = [ROI_SIZE, ROI_SIZE]\n    roi_start = [ROI_START_X, ROI_START_Y]\n    roi_img = sitk.RegionOfInterest(sitk_img, roi_size, roi_start)\n\n    target_size = [TARGET_SIZE, TARGET_SIZE]\n    original_spacing = roi_img.GetSpacing()\n    physical_size = [roi_size[i] * original_spacing[i] for i in range(2)]\n    target_spacing = [physical_size[i] / target_size[i] for i in range(2)]\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetOutputSpacing(target_spacing)\n    resampler.SetSize(target_size)\n    resampler.SetOutputOrigin(roi_img.GetOrigin())\n    resampler.SetOutputDirection(roi_img.GetDirection())\n    resampler.SetInterpolator(sitk.sitkLinear)\n    resampler.SetDefaultPixelValue(0)\n    resampled_img = resampler.Execute(roi_img)\n    resampled_array = sitk.GetArrayFromImage(resampled_img)\n\n    segment = get_segmentation(resampled_array)\n    keypoint = get_keypoint(resampled_array)\n\n    scale_factor = np.array(roi_size) / np.array(target_size)\n    keypoint_roi = keypoint * scale_factor\n    keypoint_original = keypoint_roi + np.array([roi_start[1], roi_start[0]])\n\n    segment_sitk = sitk.GetImageFromArray(segment.astype(np.float32))\n    segment_sitk.SetSpacing(target_spacing)\n    segment_sitk.SetOrigin(resampled_img.GetOrigin())\n\n    back_resampler = sitk.ResampleImageFilter()\n    back_resampler.SetOutputSpacing(original_spacing)\n    back_resampler.SetSize(roi_size)\n    back_resampler.SetOutputOrigin(roi_img.GetOrigin())\n    back_resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n    back_resampler.SetDefaultPixelValue(0)\n    segment_roi = back_resampler.Execute(segment_sitk)\n    segment_roi_array = sitk.GetArrayFromImage(segment_roi)\n\n    segment_original = np.zeros(img.shape, dtype=np.uint8)\n    segment_original[ROI_START_Y:ROI_END_Y, ROI_START_X:ROI_END_X] = segment_roi_array\n    return segment_original, keypoint_original\n\nprint(\"=== SimpleITK ===\")\nsitk_segment, sitk_key = process_with_simpleitk(original_img)\nplot_result(original_img, sitk_segment, sitk_key, \"SimpleITK\", true_keypoint)\n\nIssues: verbose resampling setup, manual coordinate math, easy axis mistakes.",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "SpaceTransformer Motivation"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation-en.html#method-2-scipy.ndimage",
    "href": "3.0_spacetransformer_motivation-en.html#method-2-scipy.ndimage",
    "title": "SpaceTransformer Motivation",
    "section": "Method 2: scipy.ndimage",
    "text": "Method 2: scipy.ndimage\n\nfrom scipy.ndimage import zoom\n\ndef process_with_scipy(img):\n    roi = img[ROI_START_Y:ROI_END_Y, ROI_START_X:ROI_END_X]\n    factor = TARGET_SIZE / ROI_SIZE\n    resampled = zoom(roi, factor, order=1, mode='constant', cval=0)\n    segment = get_segmentation(resampled)\n    keypoint = get_keypoint(resampled)\n\n    keypoint_roi = keypoint / factor\n    keypoint_original = keypoint_roi + [ROI_START_Y, ROI_START_X]\n\n    segment_roi = zoom(segment.astype(np.float32), 1.0/factor, order=0, mode='constant', cval=0)\n    segment_original = np.zeros_like(img, dtype=np.uint8)\n    segment_original[ROI_START_Y:ROI_END_Y, ROI_START_X:ROI_END_X] = segment_roi\n    return segment_original, keypoint_original\n\nprint(\"=== scipy.ndimage ===\")\nscipy_segment, scipy_key = process_with_scipy(original_img)\nplot_result(original_img, scipy_segment, scipy_key, \"scipy.ndimage\", true_keypoint)\n\nIssues: manual scaling, rounding errors when reversing zoom.",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "SpaceTransformer Motivation"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation-en.html#method-3-pytorch-interpolate",
    "href": "3.0_spacetransformer_motivation-en.html#method-3-pytorch-interpolate",
    "title": "SpaceTransformer Motivation",
    "section": "Method 3: PyTorch interpolate",
    "text": "Method 3: PyTorch interpolate\n\nimport torch\nimport torch.nn.functional as F\n\ndef process_with_pytorch(img):\n    tensor = torch.from_numpy(img).unsqueeze(0).unsqueeze(0).float()\n    roi_tensor = tensor[:, :, ROI_START_Y:ROI_END_Y, ROI_START_X:ROI_END_X]\n    resampled = F.interpolate(roi_tensor, size=(TARGET_SIZE, TARGET_SIZE), mode='bilinear', align_corners=False)\n    resampled_arr = resampled.squeeze().numpy()\n\n    segment = get_segmentation(resampled_arr)\n    keypoint = get_keypoint(resampled_arr)\n\n    scale = ROI_SIZE / TARGET_SIZE\n    keypoint_original = keypoint * scale + [ROI_START_Y, ROI_START_X]\n\n    segment_tensor = torch.from_numpy(segment.astype(np.float32)).unsqueeze(0).unsqueeze(0)\n    segment_roi = F.interpolate(segment_tensor, size=(ROI_SIZE, ROI_SIZE), mode='nearest').squeeze().numpy().astype(np.uint8)\n\n    segment_original = np.zeros_like(img, dtype=np.uint8)\n    segment_original[ROI_START_Y:ROI_END_Y, ROI_START_X:ROI_END_X] = segment_roi\n    return segment_original, keypoint_original\n\nprint(\"=== PyTorch ===\")\ntorch_segment, torch_key = process_with_pytorch(original_img)\nplot_result(original_img, torch_segment, torch_key, \"PyTorch interpolate\", true_keypoint)\n\nIssues: align_corners confusion, manual batch/channel management, visible mask offset.",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "SpaceTransformer Motivation"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation-en.html#method-4-spacetransformer",
    "href": "3.0_spacetransformer_motivation-en.html#method-4-spacetransformer",
    "title": "SpaceTransformer Motivation",
    "section": "Method 4: SpaceTransformer",
    "text": "Method 4: SpaceTransformer\n\nfrom spacetransformer.core import Space, warp_point\nfrom spacetransformer.torch import warp_image\n\ndef process_with_spacetransformer(img):\n    original_space = Space(shape=[1]+list(img.shape), spacing=(1.0,1.0,1.0), origin=(0.0,0.0,0.0))\n    target_space = (original_space\n        .apply_bbox([(0,1),(ROI_START_Y,ROI_END_Y),(ROI_START_X,ROI_END_X)])\n        .apply_shape((1, TARGET_SIZE, TARGET_SIZE)))\n\n    resampled = warp_image(img[None], original_space, target_space,\n                            mode='trilinear', pad_value=0, cuda_device='cpu', numpy=True)[0]\n    segment = get_segmentation(resampled)\n    keypoint_2d = get_keypoint(resampled)\n\n    keypoint_3d = np.array([[0, keypoint_2d[0], keypoint_2d[1]]])\n    segment_back = warp_image(segment[None], target_space, original_space,\n                              mode='nearest', pad_value=0, cuda_device='cpu', numpy=True)[0]\n    keypoint_back = warp_point(keypoint_3d, target_space, original_space)[0]\n    return segment_back, keypoint_back[0,1:3]\n\nprint(\"=== SpaceTransformer ===\")\nst_segment, st_key = process_with_spacetransformer(original_img)\nplot_result(original_img, st_segment, st_key, \"SpaceTransformer\", true_keypoint)",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "SpaceTransformer Motivation"
    ]
  },
  {
    "objectID": "3.0_spacetransformer_motivation-en.html#results",
    "href": "3.0_spacetransformer_motivation-en.html#results",
    "title": "SpaceTransformer Motivation",
    "section": "Results",
    "text": "Results\n\nAccuracy: SpaceTransformer yields zero offset. Other methods show varying coordinate drifts; PyTorch visibly shifts the mask.\nDeveloper effort: SpaceTransformer uses a declarative space description; code is concise. Others require manual bookkeeping.\nDesign: It separates transformation planning from execution, hiding fragile math and ensuring consistent behavior.\n\nNext chapter dives into SpaceTransformer’s internals.",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "SpaceTransformer Motivation"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple-en.html",
    "href": "1.6_dicom_compatibility_simple-en.html",
    "title": "DICOM Compatibility",
    "section": "",
    "text": "DiCube must integrate seamlessly with existing DICOM ecosystems so PACS vendors can adopt it. DcbStreamingReader converts .dcbs files to DICOM on demand, emulating a traditional PACS backend. Downstream systems consume DiCube data without workflow changes.",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Compatibility"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple-en.html#background-pacs-integration-needs",
    "href": "1.6_dicom_compatibility_simple-en.html#background-pacs-integration-needs",
    "title": "DICOM Compatibility",
    "section": "",
    "text": "DiCube must integrate seamlessly with existing DICOM ecosystems so PACS vendors can adopt it. DcbStreamingReader converts .dcbs files to DICOM on demand, emulating a traditional PACS backend. Downstream systems consume DiCube data without workflow changes.",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Compatibility"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple-en.html#streaming-reader",
    "href": "1.6_dicom_compatibility_simple-en.html#streaming-reader",
    "title": "DICOM Compatibility",
    "section": "2. Streaming Reader",
    "text": "2. Streaming Reader\n\n2.1. Basic Usage\n\nimport dicube\nfrom dicube.dicom import DcbStreamingReader\n\ndicom_dir = 'dicube-testdata/dicom/sample_10'\ndcb_file = 'dicube-testdata/sample_10.dcbs'\n\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, dcb_file)\ndcb_stream = DcbStreamingReader(dcb_file)\n\nslice_0 = dcb_stream.get_dicom_for_frame(0)\nwith open('dicube-testdata/sample_10_0.dcm', 'wb') as f:\n    f.write(slice_0)\nprint(f\"Generated DICOM bytes: {len(slice_0)}\")\n\n\n\n2.2. Processing + Visualization\n\nimport pydicom\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom io import BytesIO\n\ndef analyze_dicom_slice(slice_index):\n    buffer = BytesIO(dcb_stream.get_dicom_for_frame(slice_index))\n    dataset = pydicom.dcmread(buffer, force=True)\n\n    pixels = dataset.pixel_array.astype('float32')\n    if hasattr(dataset, 'RescaleIntercept'):\n        pixels += float(dataset.RescaleIntercept)\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(pixels, cmap='gray', vmin=-800, vmax=300)\n    plt.axis('off')\n    plt.title(f\"Slice #{slice_index}\")\n    plt.tight_layout()\n    plt.show()\n    return dataset\n\nfor idx in [0, 4, 8]:\n    analyze_dicom_slice(idx)\n\nConversion happens only when requested—no need to pre-expand entire series, saving space and latency.",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Compatibility"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple-en.html#htj2k-compatibility-landscape",
    "href": "1.6_dicom_compatibility_simple-en.html#htj2k-compatibility-landscape",
    "title": "DICOM Compatibility",
    "section": "3. HTJ2K Compatibility Landscape",
    "text": "3. HTJ2K Compatibility Landscape\n\n3.1. Standard Evolution\nDiCube uses HTJ2K (High Throughput JPEG 2000), standardized by DICOM in 2023. Compared to classic JPEG 2000:\n\n10–15× faster encoding/decoding\nSame compression quality at equal ratios\nBetter suited to GPU/hardware acceleration\n\n\n\n3.2. Current Support\n\nSupported\n\nPyDICOM ≥ 3.0.0 (with pylibjpeg-openjpeg &gt; 2.0 + pylibjpeg &gt; 2.0)\nPython-GDCM 3.0.26\nITK-SNAP 4.4.0\n\nNot yet supported\n\nHoros 4.0.1 (macOS viewer)\nSimpleITK 2.5.2\n\n\n\n\n3.3. Maximum Compatibility Option\nFallback to uncompressed DICOM for legacy environments:\n\nuncompressed_dicom = dcb_stream.get_dicom_for_frame(0, force_uncompressed=True)\n\nPros: - Universally compatible - No decoder dependency - Zero risk of decode failure in transit\nCons: - 5–10× larger files - Higher storage/bandwidth usage - Longer transfer times",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Compatibility"
    ]
  },
  {
    "objectID": "1.6_dicom_compatibility_simple-en.html#deployment-strategy",
    "href": "1.6_dicom_compatibility_simple-en.html#deployment-strategy",
    "title": "DICOM Compatibility",
    "section": "4. Deployment Strategy",
    "text": "4. Deployment Strategy\nAdopt a gradual approach:\n\nAssess HTJ2K support in target PACS/clients.\nUse HTJ2K where supported; fallback to uncompressed for legacy systems.\nMonitor upstream library updates and expand HTJ2K coverage over time.\n\nThis balances modern compression gains with real-world compatibility.",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Compatibility"
    ]
  },
  {
    "objectID": "2.3_mask_archive-en.html",
    "href": "2.3_mask_archive-en.html",
    "title": "MaskArchive",
    "section": "",
    "text": "MaskArchive bundles multiple segmentation masks sharing identical space (shape, spacing, origin) into one archive—ideal for large organ sets (lungs: lobes, segments, lesions, whole lung). All contained masks must share the same space.",
    "crumbs": [
      "首页",
      "MedMask",
      "MaskArchive"
    ]
  },
  {
    "objectID": "2.3_mask_archive-en.html#scenario-multi-level-lung-segmentation",
    "href": "2.3_mask_archive-en.html#scenario-multi-level-lung-segmentation",
    "title": "MaskArchive",
    "section": "1. Scenario: Multi-Level Lung Segmentation",
    "text": "1. Scenario: Multi-Level Lung Segmentation\n\n5 lobes (mutually exclusive)\n18 segments (mutually exclusive but overlap lobes)\nN lesions (overlap everything)\nWhole lung (overlaps all)\n\nTraditional approach: store 5+18+N+1 separate files.",
    "crumbs": [
      "首页",
      "MedMask",
      "MaskArchive"
    ]
  },
  {
    "objectID": "2.3_mask_archive-en.html#synthetic-data-setup",
    "href": "2.3_mask_archive-en.html#synthetic-data-setup",
    "title": "MaskArchive",
    "section": "2. Synthetic Data Setup",
    "text": "2. Synthetic Data Setup\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom medmask import SegmentationMask, MaskArchive\nfrom spacetransformer import Space\nfrom pathlib import Path\nimport time\n\nshape = (1,64,64)\nspace = Space(shape=shape, spacing=(1.0,1.0,1.0), origin=(0.0,0.0,0.0))\n\nlobe_mask = np.zeros(shape, dtype=np.uint8)\n# Five lobes\nlobe_mask[0,10:30,10:25] = 1\nlobe_mask[0,35:55,10:25] = 2\nlobe_mask[0,10:25,40:55] = 3\nlobe_mask[0,30:45,40:55] = 4\nlobe_mask[0,50:60,40:55] = 5\nlobe_mapping = {\n    \"left_upper_lobe\":1,\n    \"left_lower_lobe\":2,\n    \"right_upper_lobe\":3,\n    \"right_middle_lobe\":4,\n    \"right_lower_lobe\":5\n}\n\nsegment_mask = np.zeros(shape, dtype=np.uint8)\nsegment_mask[0,10:18,10:18] = 1\nsegment_mask[0,18:25,12:20] = 2\nsegment_mask[0,22:30,17:25] = 3\nsegment_mask[0,35:42,10:18] = 4\nsegment_mask[0,42:50,12:20] = 5\nsegment_mask[0,48:55,17:25] = 6\nsegment_mask[0,10:18,40:48] = 7\nsegment_mask[0,18:25,42:50] = 8\nsegment_mask[0,30:38,40:48] = 9\nsegment_mask[0,38:45,42:50] = 10\nsegment_mapping = {\n    \"LUL_S1\":1,\"LUL_S2\":2,\"LUL_S3\":3,\n    \"LLL_S4\":4,\"LLL_S5\":5,\"LLL_S6\":6,\n    \"RUL_S1\":7,\"RUL_S2\":8,\n    \"RML_S4\":9,\"RML_S5\":10\n}\n\nlesion_mask = np.zeros(shape, dtype=np.uint8)\nlesion_mask[0,15:20,15:20] = 1\nlesion_mask[0,40:45,15:20] = 2\nlesion_mask[0,25:30,45:50] = 3\nlesion_mapping = {\"nodule_1\":1,\"nodule_2\":2,\"mass_1\":3}\n\nwhole_lung_mask = np.zeros(shape, dtype=np.uint8)\nwhole_lung_mask[0,8:62,8:57] = 1\nwhole_lung_mapping = {\"whole_lung\":1}\n\nprint(\"Setup complete\")",
    "crumbs": [
      "首页",
      "MedMask",
      "MaskArchive"
    ]
  },
  {
    "objectID": "2.3_mask_archive-en.html#visualize-masks",
    "href": "2.3_mask_archive-en.html#visualize-masks",
    "title": "MaskArchive",
    "section": "3. Visualize Masks",
    "text": "3. Visualize Masks\n\nfig, axes = plt.subplots(2,2, figsize=(12,10))\nplots = [\n    (lobe_mask[0], \"Lobes\", \"Set3\"),\n    (segment_mask[0], \"Segments\", \"Set3\"),\n    (lesion_mask[0], \"Lesions\", \"Set3\"),\n    (whole_lung_mask[0], \"Whole lung\", \"Set3\")\n]\nfor ax, (mask, title, cmap) in zip(axes.flatten(), plots):\n    ax.imshow(mask, cmap=cmap, alpha=0.8)\n    ax.set_title(title)\n    ax.axis('off')\nplt.tight_layout(); plt.show()",
    "crumbs": [
      "首页",
      "MedMask",
      "MaskArchive"
    ]
  },
  {
    "objectID": "2.3_mask_archive-en.html#traditional-separate-files",
    "href": "2.3_mask_archive-en.html#traditional-separate-files",
    "title": "MaskArchive",
    "section": "4. Traditional: Separate Files",
    "text": "4. Traditional: Separate Files\n\nprint(\"=== Separate files ===\")\nstart = time.time()\n\nlobe_segmask = SegmentationMask(lobe_mask, lobe_mapping, space=space)\nsegment_segmask = SegmentationMask(segment_mask, segment_mapping, space=space)\nlesion_segmask = SegmentationMask(lesion_mask, lesion_mapping, space=space)\nwhole_segmask = SegmentationMask(whole_lung_mask, whole_lung_mapping, space=space)\n\nlobe_segmask.save(\"lung_lobes.msk\")\nsegment_segmask.save(\"lung_segments.msk\")\nlesion_segmask.save(\"lung_lesions.msk\")\nwhole_segmask.save(\"whole_lung.msk\")\n\nseparate_time = time.time() - start\nfiles = [\"lung_lobes.msk\",\"lung_segments.msk\",\"lung_lesions.msk\",\"whole_lung.msk\"]\nsize_total = sum(Path(f).stat().st_size for f in files)\nprint(f\"Time: {separate_time:.3f}s, files: {len(files)}, size: {size_total/1024:.1f} KB\")",
    "crumbs": [
      "首页",
      "MedMask",
      "MaskArchive"
    ]
  },
  {
    "objectID": "2.3_mask_archive-en.html#maskarchive",
    "href": "2.3_mask_archive-en.html#maskarchive",
    "title": "MaskArchive",
    "section": "5. MaskArchive",
    "text": "5. MaskArchive\n\nprint(\"\\n=== MaskArchive ===\")\nstart = time.time()\narchive = MaskArchive(\"lung_analysis.mska\", mode=\"w\", space=space)\narchive.add_segmask(lobe_segmask, \"lobes\")\narchive.add_segmask(segment_segmask, \"segments\")\narchive.add_segmask(lesion_segmask, \"lesions\")\narchive.add_segmask(whole_segmask, \"whole_lung\")\narchive_time = time.time() - start\narchive_size = Path(\"lung_analysis.mska\").stat().st_size\nprint(f\"Time: {archive_time:.3f}s, files: 1, size: {archive_size/1024:.1f} KB\")\nprint(\"Masks in archive:\", archive.all_names())\nprint(\"Compression ratio:\", size_total/archive_size if archive_size else 'N/A')",
    "crumbs": [
      "首页",
      "MedMask",
      "MaskArchive"
    ]
  },
  {
    "objectID": "2.3_mask_archive-en.html#access-integrity",
    "href": "2.3_mask_archive-en.html#access-integrity",
    "title": "MaskArchive",
    "section": "6. Access + Integrity",
    "text": "6. Access + Integrity\n\nreader = MaskArchive(\"lung_analysis.mska\", mode=\"r\")\nprint(\"Names:\", reader.all_names())\n\nloaded_lobes = reader.load_segmask(\"lobes\")\nloaded_lesions = reader.load_segmask(\"lesions\")\nprint(\"Shapes match:\", np.array_equal(lobe_mask, loaded_lobes.data))\n\nleft_upper = loaded_lobes.get_binary_mask_by_names(\"left_upper_lobe\")\nnodule = loaded_lesions.get_binary_mask_by_names(\"nodule_1\")\nprint(\"Left upper lobe voxels:\", left_upper.sum())\nprint(\"Nodule 1 voxels:\", nodule.sum())",
    "crumbs": [
      "首页",
      "MedMask",
      "MaskArchive"
    ]
  },
  {
    "objectID": "2.3_mask_archive-en.html#recommendations",
    "href": "2.3_mask_archive-en.html#recommendations",
    "title": "MaskArchive",
    "section": "Recommendations",
    "text": "Recommendations\nUse MaskArchive when:\n\nMany masks share identical grid (organ atlases, multi-stage annotations)\nNeed a single artifact for storage/transfer/versioning\nWant consistent semantics via embedded mappings\n\nKeep separate files when:\n\nMasks come from differing grids/spaces\nLegacy systems require individual formats\n\nMaskArchive reduces file sprawl while preserving full metadata and semantics.",
    "crumbs": [
      "首页",
      "MedMask",
      "MaskArchive"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping.html",
    "href": "2.2_mask_label_mapping.html",
    "title": "语义映射系统",
    "section": "",
    "text": "在前文中，我们识别了医学分割掩膜存储中的一个核心挑战：语义信息的外部依赖管理。传统方法中，像素值与其语义含义（如“肝脏”“脾脏”）的映射必须通过外部配置或硬编码维护，导致数据不自洽、同步困难、版本管理复杂。\n本文将深入介绍 MedMask 如何通过内置的双向语义映射系统来根本性地解决这一问题。我们将展示 LabelMapping 类的核心设计理念、SegmentationMask 的语义集成机制，以及这种设计如何在实际医学影像工作流中带来显著的效率提升和错误减少。",
    "crumbs": [
      "首页",
      "MedMask",
      "语义映射系统"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping.html#摘要",
    "href": "2.2_mask_label_mapping.html#摘要",
    "title": "语义映射系统",
    "section": "",
    "text": "在前文中，我们识别了医学分割掩膜存储中的一个核心挑战：语义信息的外部依赖管理。传统方法中，像素值与其语义含义（如“肝脏”“脾脏”）的映射必须通过外部配置或硬编码维护，导致数据不自洽、同步困难、版本管理复杂。\n本文将深入介绍 MedMask 如何通过内置的双向语义映射系统来根本性地解决这一问题。我们将展示 LabelMapping 类的核心设计理念、SegmentationMask 的语义集成机制，以及这种设计如何在实际医学影像工作流中带来显著的效率提升和错误减少。",
    "crumbs": [
      "首页",
      "MedMask",
      "语义映射系统"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping.html#传统方法的语义管理困境",
    "href": "2.2_mask_label_mapping.html#传统方法的语义管理困境",
    "title": "语义映射系统",
    "section": "1. 传统方法的语义管理困境",
    "text": "1. 传统方法的语义管理困境\n在传统的医学分割工作流中，掩膜文件本身只包含数值标签（如1、2、3），其语义含义需要通过外部机制来定义和维护。目前主流的语义管理方式有两种：\n\n方式一：外置配置文件描述\n通过独立的配置文件（如JSON、YAML、CSV）来维护标签与语义的对应关系。\n\nimport numpy as np\nimport json\n\n# 掩膜数据\nmask_array = np.array([\n    [0, 0, 1, 1],\n    [0, 2, 2, 1], \n    [3, 3, 0, 0]\n])\n\n# 外置配置文件 label_config.json\nconfig = {\n    \"1\": \"liver\",\n    \"2\": \"spleen\", \n    \"3\": \"kidney\"\n}\n\n# 需要额外维护配置文件\nwith open('label_config.json', 'w') as f:\n    json.dump(config, f)\n\nprint(\"方式一：外置配置文件\")\nprint(f\"掩膜文件: 形状{mask_array.shape}, 标签{np.unique(mask_array)}\")\nprint(f\"配置文件: {config}\")\n\n主要缺陷： - 文件管理复杂化：每个掩膜都需要配套的配置文件，增加了文件管理负担 - 数据完整性风险：配置文件容易被意外删除、修改或损坏，导致数据无法解读 - 版本同步困难：掩膜文件与配置文件需要严格保持版本一致，容易出现不匹配\n\n\n方式二：文件名或内部键值描述\n利用文件命名约定或NPZ格式的内部键值来承载语义信息。\n\n# 文件名描述方式\n# liver_segmentation.nii.gz\n# spleen_segmentation.nii.gz  \n# kidney_segmentation.nii.gz\n\n# NPZ内部键值描述方式（变体）\nnp.savez_compressed('multi_organ.npz', \n    liver=mask_array == 1,\n    spleen=mask_array == 2, \n    kidney=mask_array == 3\n)\n\nloaded = np.load('multi_organ.npz')\nprint(\"方式二：文件名/键值描述\")\nprint(f\"NPZ键值: {list(loaded.keys())}\")\n\n主要缺陷： - 信息承载能力有限：文件名长度受限，无法描述复杂的标签关系和层级结构 - 标签数量瓶颈：当标签数量较多时（如100+器官），文件名或键值管理变得不可行 - 标准化困难：缺乏统一的命名规范，不同团队可能采用不同的约定，影响互操作性",
    "crumbs": [
      "首页",
      "MedMask",
      "语义映射系统"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping.html#medmask-的语义映射解决方案",
    "href": "2.2_mask_label_mapping.html#medmask-的语义映射解决方案",
    "title": "语义映射系统",
    "section": "2. MedMask 的语义映射解决方案",
    "text": "2. MedMask 的语义映射解决方案\n\n核心设计理念：内嵌式双向映射\nMedMask 通过 LabelMapping 类实现了语义信息与像素数据的一体化存储。这种设计确保了掩膜文件在任何环境下都是完全自洽的，无需外部依赖即可完整解读。\n\nfrom medmask.core.mapping import LabelMapping\n\n# MedMask方法：创建内嵌语义映射\nmapping = LabelMapping({\n    \"liver\": 1,\n    \"spleen\": 2, \n    \"kidney\": 3\n})\n\nprint(\"双向映射能力:\")\nprint(f\"正向查询: liver -&gt; {mapping['liver']}\")\nprint(f\"反向查询: {mapping.inverse(1)} &lt;- 1\")\nprint(f\"属性访问: mapping.spleen = {mapping.spleen}\")\nprint(f\"函数调用: mapping('kidney') = {mapping('kidney')}\")\n\n\n\nLabelMapping 类的技术特性\nLabelMapping 类提供了完整的双向映射功能，支持多种访问模式以适应不同的编程习惯：\n\n# 1. 字典式访问\nliver_label = mapping[\"liver\"]\n\n# 2. 属性式访问（便于IDE自动补全）\nspleen_label = mapping.spleen\n\n# 3. 函数调用式访问\nkidney_label = mapping(\"kidney\")\n\n# 4. 反向查询\norgan_name = mapping.inverse(1)\n\n# 5. 存在性检查\nhas_liver = \"liver\" in mapping._name_to_label\nhas_label_4 = mapping.has_label(4)\n\nprint(f\"多种访问方式的一致性验证:\")\nprint(f\"字典访问: {liver_label}, 属性访问: {mapping.liver}, 函数调用: {mapping('liver')}\")\nprint(f\"反向查询验证: 标签1对应{organ_name}\")\nprint(f\"存在性检查: 有liver? {has_liver}, 有标签4? {has_label_4}\")\n\n\n\n持久化与版本控制\n语义映射支持JSON序列化，确保了跨平台的兼容性和版本控制的便利性：\n\n# 序列化为JSON\njson_repr = mapping.to_json()\nprint(f\"JSON序列化结果: {json_repr}\")\n\n# 从JSON反序列化\nrestored_mapping = LabelMapping.from_json(json_repr)\nprint(f\"反序列化验证: {restored_mapping}\")\n\n# 验证完整性\nprint(f\"序列化前后一致性: {mapping._name_to_label == restored_mapping._name_to_label}\")",
    "crumbs": [
      "首页",
      "MedMask",
      "语义映射系统"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping.html#segmentationmask-的语义集成",
    "href": "2.2_mask_label_mapping.html#segmentationmask-的语义集成",
    "title": "语义映射系统",
    "section": "3. SegmentationMask 的语义集成",
    "text": "3. SegmentationMask 的语义集成\n\n统一的语义-空间数据模型\nSegmentationMask 类将语义映射、空间信息和像素数据统一管理，形成了完整的医学掩膜表示：\n\nfrom medmask import SegmentationMask\nfrom spacetransformer import Space\n\n# 创建空间信息\nspace = Space(shape=(1, 3, 4), spacing=(1.0, 1.0, 1.0))\n\n# 创建完整的语义掩膜\nsegmask = SegmentationMask(\n    mask_array=mask_array[np.newaxis, :, :],  # 添加Z维度\n    mapping={\"liver\": 1, \"spleen\": 2, \"kidney\": 3},\n    space=space\n)\n\nprint(f\"集成后的掩膜信息:\")\nprint(f\"形状: {segmask.data.shape}\")\nprint(f\"空间: spacing={segmask.space.spacing}\")\nprint(f\"语义映射: {dict(segmask.mapping.items())}\")\n\n\n\n语义化查询接口与代码可维护性\n通过内嵌的语义映射，用户可以直接使用器官名称来查询和操作掩膜数据，这不仅提高了代码的可读性，更重要的是根本性地改善了代码的可维护性。\n\n# 按名称查询单个器官\nliver_mask = segmask.get_binary_mask_by_names(\"liver\")\nprint(f\"肝脏掩膜: 非零像素数 = {np.sum(liver_mask)}\")\n\n# 按名称查询多个器官\nabdominal_organs = segmask.get_binary_mask_by_names([\"liver\", \"spleen\"])\nprint(f\"腹部器官掩膜: 非零像素数 = {np.sum(abdominal_organs)}\")\n\n# 按标签查询（保持向后兼容）\nliver_by_label = segmask.get_binary_mask_by_labels(1)\nprint(f\"按标签查询验证: {np.array_equal(liver_mask, liver_by_label)}\")\n\n可维护性的关键优势在于代码与数据表示的解耦：\n传统方法的维护困境：\n# 传统代码需要硬编码 label-value 对应关系\nLIVER_LABEL = 1\nSPLEEN_LABEL = 2\nKIDNEY_LABEL = 3\n\n# 当算法版本升级，标签值可能发生变化\n# 每次标签值变化，所有相关方都需要同步更新代码\n# v1.0: liver=1, spleen=2, kidney=3\n# v2.0: liver=5, spleen=8, kidney=12\nMedMask 方法的维护优势：\n# 代码完全不依赖具体的标签值\ndef process_organs(segmask):\n    liver_region = segmask.get_binary_mask_by_names(\"liver\")\n    return liver_region\n\n# 无论算法版本如何变化，只要器官名称不变，代码保持不变\n# v1.0: {\"liver\": 1, \"spleen\": 2}  ← 代码无需修改\n# v2.0: {\"liver\": 5, \"spleen\": 8}  ← 代码无需修改\n# v3.0: {\"liver\": 12, \"spleen\": 15} ← 代码无需修改\n这种设计实现了代码与数据版本的完全解耦：开发者只需要维护目标器官的名称列表，而不需要关心具体的数值编码。当分割算法升级、标签分配策略调整时，业务逻辑代码完全不受影响，大幅降低了系统维护成本和版本迁移风险。\n\n\n增量构建与动态扩展\n对于复杂的分割任务，MedMask支持渐进式构建掩膜，每次添加一个器官标签：\n\n# 懒加载初始化：创建空掩膜\nempty_mask = SegmentationMask.lazy_init(bit_depth=8, space=space)\n\n# 模拟分割结果：逐步添加器官\nliver_region = np.zeros((1, 3, 4), dtype=bool)\nliver_region[0, 0:2, 1:3] = True\n\nspleen_region = np.zeros((1, 3, 4), dtype=bool) \nspleen_region[0, 1:3, 2:4] = True\n\n# 动态添加标签\nempty_mask.add_label(liver_region, label=1, name=\"liver\")\nempty_mask.add_label(spleen_region, label=2, name=\"spleen\")\n\nprint(f\"动态构建结果:\")\nprint(f\"标签数量: {len(empty_mask.mapping)}\")\nprint(f\"器官列表: {list(empty_mask.mapping)}\")\n\n# 验证查询功能\ncombined_organs = empty_mask.get_binary_mask_by_names([\"liver\", \"spleen\"])\nprint(f\"组合查询: 覆盖像素数 = {np.sum(combined_organs)}\")\n\n\n\n错误预防机制\nMedMask的设计会防止反复写入同一个键值：\n\n# MedMask的错误预防能力\nprint(\"\\nMedMask的自动错误预防:\")\ntry:\n    # 尝试添加重复标签（系统自动阻止）\n    test_mask = SegmentationMask.lazy_init(8, space=Space(shape=(2, 2, 2)))\n    test_mask.add_label(np.ones((2, 2, 2), dtype=bool), 1, \"organ_a\")\n    test_mask.add_label(np.ones((2, 2, 2), dtype=bool), 1, \"organ_b\")  # 重复标签\nexcept ValueError as e:\n    print(f\"自动检测并阻止错误: {e}\")",
    "crumbs": [
      "首页",
      "MedMask",
      "语义映射系统"
    ]
  },
  {
    "objectID": "2.2_mask_label_mapping.html#总结",
    "href": "2.2_mask_label_mapping.html#总结",
    "title": "语义映射系统",
    "section": "4. 总结",
    "text": "4. 总结\nMedMask 的语义映射系统通过以下核心创新，彻底解决了传统医学掩膜格式在语义管理方面的根本性缺陷：\n\n技术创新点\n\n内嵌式双向映射：将语义信息直接集成到掩膜文件中，实现数据完全自洽，消除外部依赖。\n多模式访问接口：支持字典、属性、函数调用等多种访问方式，适应不同的编程习惯和IDE环境。\n运行时一致性验证：在数据操作过程中自动检测和阻止语义-标签不一致，从源头预防数据错误。\nJSON标准化序列化：确保跨平台兼容性和版本控制友好性，支持复杂项目的长期维护。\n\n\n\n实际价值体现\n\n\n\n传统方法\nMedMask方法\n改进效果\n\n\n\n\n外部配置文件维护\n内嵌语义映射\n消除同步负担\n\n\n手动数据验证\n自动一致性检查\n减少人为错误\n\n\n硬编码标签查询\n语义化查询接口\n提高代码可读性\n\n\n团队沟通协调\n自描述数据格式\n简化协作流程\n\n\n\n通过这种系统性的设计改进，MedMask不仅解决了语义管理的技术问题，更重要的是为医学影像分析工作流带来了根本性的效率提升和质量保障。开发团队可以将更多精力集中在核心的医学算法开发上，而不是琐碎的数据管理细节。",
    "crumbs": [
      "首页",
      "MedMask",
      "语义映射系统"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html",
    "href": "2.3_mask_archive.html",
    "title": "多掩膜归档管理",
    "section": "",
    "text": "MaskArchive 是 MedMask 提供的多掩膜归档功能，核心作用是将多个分割掩膜绑定到同一个归档文件中。当需要管理大量相关掩膜时（如全身器官分割、多层级解剖结构），这一功能可以将原本分散的多个文件合并为单一归档，简化文件管理。\n关键限制：归档中的所有掩膜必须共享相同的空间参考信息（shape、spacing、origin），确保空间一致性。",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html#摘要",
    "href": "2.3_mask_archive.html#摘要",
    "title": "多掩膜归档管理",
    "section": "",
    "text": "MaskArchive 是 MedMask 提供的多掩膜归档功能，核心作用是将多个分割掩膜绑定到同一个归档文件中。当需要管理大量相关掩膜时（如全身器官分割、多层级解剖结构），这一功能可以将原本分散的多个文件合并为单一归档，简化文件管理。\n关键限制：归档中的所有掩膜必须共享相同的空间参考信息（shape、spacing、origin），确保空间一致性。",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html#问题场景肺部多层级分割",
    "href": "2.3_mask_archive.html#问题场景肺部多层级分割",
    "title": "多掩膜归档管理",
    "section": "1. 问题场景：肺部多层级分割",
    "text": "1. 问题场景：肺部多层级分割\n在肺部分析中，常需要同时处理不同粒度的结构：\n\n5个肺叶：左上叶、左下叶、右上叶、右中叶、右下叶（互不重叠）\n18个肺段：每个肺叶下的亚结构（互不重叠，但与肺叶重叠）\n\nN个病灶：肺结节、肿块等（可与肺叶、肺段重叠）\n1个全肺：整体肺区域（与所有结构重叠）\n\n传统方法需要管理 5+18+N+1 个独立文件，而 MaskArchive 可以将它们合并到一个归档中。",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html#模拟数据构建",
    "href": "2.3_mask_archive.html#模拟数据构建",
    "title": "多掩膜归档管理",
    "section": "2. 模拟数据构建",
    "text": "2. 模拟数据构建\n我们用2D掩膜来模拟这一场景：\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom medmask import SegmentationMask, MaskArchive\nfrom spacetransformer import Space\nfrom pathlib import Path\nimport time\n\n# 创建模拟的2D肺部图像 (1, 64, 64) - 单层CT切片\nshape = (1, 64, 64)\nspace = Space(shape=shape, spacing=(1.0, 1.0, 1.0), origin=(0.0, 0.0, 0.0))\n\n# 构建肺叶掩膜 (5个肺叶，互不重叠)\nlobe_mask = np.zeros(shape, dtype=np.uint8)\nlobe_mask[0, 10:30, 10:25] = 1  # 左上叶\nlobe_mask[0, 35:55, 10:25] = 2  # 左下叶  \nlobe_mask[0, 10:25, 40:55] = 3  # 右上叶\nlobe_mask[0, 30:45, 40:55] = 4  # 右中叶\nlobe_mask[0, 50:60, 40:55] = 5  # 右下叶\n\nlobe_mapping = {\n    \"left_upper_lobe\": 1,\n    \"left_lower_lobe\": 2,\n    \"right_upper_lobe\": 3,\n    \"right_middle_lobe\": 4,\n    \"right_lower_lobe\": 5\n}\n\n# 构建肺段掩膜 (10个肺段，与肺叶重叠)\nsegment_mask = np.zeros(shape, dtype=np.uint8)\n# 左上叶的段\nsegment_mask[0, 10:18, 10:18] = 1   \nsegment_mask[0, 18:25, 12:20] = 2   \nsegment_mask[0, 22:30, 17:25] = 3   \n# 左下叶的段\nsegment_mask[0, 35:42, 10:18] = 4   \nsegment_mask[0, 42:50, 12:20] = 5   \nsegment_mask[0, 48:55, 17:25] = 6   \n# 右上叶的段\nsegment_mask[0, 10:18, 40:48] = 7   \nsegment_mask[0, 18:25, 42:50] = 8   \n# 右中叶的段\nsegment_mask[0, 30:38, 40:48] = 9   \nsegment_mask[0, 38:45, 42:50] = 10  \n\nsegment_mapping = {\n    \"LUL_S1\": 1, \"LUL_S2\": 2, \"LUL_S3\": 3,\n    \"LLL_S4\": 4, \"LLL_S5\": 5, \"LLL_S6\": 6,\n    \"RUL_S1\": 7, \"RUL_S2\": 8,\n    \"RML_S4\": 9, \"RML_S5\": 10\n}\n\n# 构建病灶掩膜 (3个病灶，可与肺叶重叠)\nlesion_mask = np.zeros(shape, dtype=np.uint8)\nlesion_mask[0, 15:20, 15:20] = 1    # 病灶1：位于左上叶\nlesion_mask[0, 40:45, 15:20] = 2    # 病灶2：位于左下叶\nlesion_mask[0, 25:30, 45:50] = 3    # 病灶3：位于右中叶\n\nlesion_mapping = {\n    \"nodule_1\": 1,\n    \"nodule_2\": 2,\n    \"mass_1\": 3\n}\n\n# 构建全肺掩膜 (包含所有肺叶区域)\nwhole_lung_mask = np.zeros(shape, dtype=np.uint8)\nwhole_lung_mask[0, 8:62, 8:57] = 1  # 整个肺部区域，稍微扩大范围\n\nwhole_lung_mapping = {\"whole_lung\": 1}\n\nprint(\"模拟数据构建完成:\")\nprint(f\"空间信息: {shape}\")\nprint(f\"肺叶标签数: {len(lobe_mapping)}\")\nprint(f\"肺段标签数: {len(segment_mapping)}\")\nprint(f\"病灶标签数: {len(lesion_mapping)}\")\nprint(f\"全肺标签数: {len(whole_lung_mapping)}\")",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html#可视化掩膜结构",
    "href": "2.3_mask_archive.html#可视化掩膜结构",
    "title": "多掩膜归档管理",
    "section": "3. 可视化掩膜结构",
    "text": "3. 可视化掩膜结构\n\n# 可视化四种掩膜的空间分布\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\nmasks = [\n    (lobe_mask[0], \"Lung Lobes (5 lobes)\", \"Set3\"),\n    (segment_mask[0], \"Lung Segments (10 segments)\", \"Set3\"), \n    (lesion_mask[0], \"Lung Lesions (3 lesions)\", \"Set3\"),\n    (whole_lung_mask[0], \"Whole Lung (1 region)\", \"Set3\")\n]\n\nfor i, (mask, title, cmap) in enumerate(masks):\n    axes[i].imshow(mask, cmap=cmap, alpha=0.8)\n    axes[i].set_title(title, fontsize=12)\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Mask overlap relationships:\")\nprint(\"- Segments overlap with lobes (segments are sub-structures of lobes)\")  \nprint(\"- Lesions overlap with lobes and segments (lesions are located within lobes)\")\nprint(\"- Whole lung overlaps with all structures (whole lung contains all regions)\")",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html#传统方法独立文件存储",
    "href": "2.3_mask_archive.html#传统方法独立文件存储",
    "title": "多掩膜归档管理",
    "section": "4. 传统方法：独立文件存储",
    "text": "4. 传统方法：独立文件存储\n\n# 方法1: 传统的独立文件存储\nprint(\"=== 传统方法：独立文件存储 ===\")\nstart_time = time.time()\n\n# 创建四个独立的SegmentationMask文件\nlobe_segmask = SegmentationMask(lobe_mask, lobe_mapping, space=space)\nsegment_segmask = SegmentationMask(segment_mask, segment_mapping, space=space)\nlesion_segmask = SegmentationMask(lesion_mask, lesion_mapping, space=space)\nwhole_lung_segmask = SegmentationMask(whole_lung_mask, whole_lung_mapping, space=space)\n\n# 保存为独立文件\nlobe_segmask.save(\"lung_lobes.msk\")\nsegment_segmask.save(\"lung_segments.msk\") \nlesion_segmask.save(\"lung_lesions.msk\")\nwhole_lung_segmask.save(\"whole_lung.msk\")\n\ntraditional_time = time.time() - start_time\n\n# 计算独立文件的总大小\nindependent_files = [\"lung_lobes.msk\", \"lung_segments.msk\", \"lung_lesions.msk\", \"whole_lung.msk\"]\ntotal_size = sum(Path(f).stat().st_size for f in independent_files)\n\nprint(f\"创建时间: {traditional_time:.3f}s\")\nprint(f\"文件数量: {len(independent_files)} 个\")\nprint(f\"总大小: {total_size / 1024:.1f} KB\")\nfor f in independent_files:\n    size = Path(f).stat().st_size\n    print(f\"  - {f}: {size / 1024:.1f} KB\")",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html#maskarchive-方法归档存储",
    "href": "2.3_mask_archive.html#maskarchive-方法归档存储",
    "title": "多掩膜归档管理",
    "section": "5. MaskArchive 方法：归档存储",
    "text": "5. MaskArchive 方法：归档存储\n\n# 方法2: MaskArchive归档存储\nprint(\"\\n=== MaskArchive方法：归档存储 ===\")\nstart_time = time.time()\n\n# 创建归档并添加所有掩膜\narchive = MaskArchive(\"lung_analysis.mska\", mode=\"w\", space=space)\n\n# 添加各层级掩膜到归档\narchive.add_segmask(lobe_segmask, \"lobes\")\narchive.add_segmask(segment_segmask, \"segments\")\narchive.add_segmask(lesion_segmask, \"lesions\") \narchive.add_segmask(whole_lung_segmask, \"whole_lung\")\n\narchive_time = time.time() - start_time\narchive_size = Path(\"lung_analysis.mska\").stat().st_size\n\nprint(f\"创建时间: {archive_time:.3f}s\")\nprint(f\"文件数量: 1 个归档文件\")\nprint(f\"总大小: {archive_size / 1024:.1f} KB\")\nprint(f\"包含掩膜: {len(archive.all_names())} 个\")\nprint(f\"掩膜列表: {archive.all_names()}\")\n\n# 效率对比\nprint(f\"\\n=== 效率对比 ===\")\nprint(f\"文件管理: {len(independent_files)} 个独立文件 → 1 个归档文件\")\nprint(f\"存储大小: {total_size / 1024:.1f} KB → {archive_size / 1024:.1f} KB\")\nif total_size &gt; archive_size:\n    compression = total_size / archive_size\n    print(f\"存储优化: 压缩比 {compression:.1f}:1\")",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html#归档访问与查询",
    "href": "2.3_mask_archive.html#归档访问与查询",
    "title": "多掩膜归档管理",
    "section": "6. 归档访问与查询",
    "text": "6. 归档访问与查询\n\n# 演示归档的访问功能\nprint(\"=== 归档访问演示 ===\")\n\n# 重新打开归档进行读取\nreader = MaskArchive(\"lung_analysis.mska\", mode=\"r\")\n\n# 查询可用掩膜\nprint(f\"归档中的掩膜: {reader.all_names()}\")\n\n# 单独加载特定掩膜\nprint(\"\\n单独访问掩膜:\")\nloaded_lobes = reader.load_segmask(\"lobes\")\nprint(f\"肺叶掩膜: {list(loaded_lobes.mapping.items())}\")\n\nloaded_lesions = reader.load_segmask(\"lesions\")  \nprint(f\"病灶掩膜: {list(loaded_lesions.mapping.items())}\")\n\n# 验证数据完整性\nprint(f\"\\n数据完整性验证:\")\nprint(f\"原始肺叶形状: {lobe_mask.shape}\")\nprint(f\"加载肺叶形状: {loaded_lobes.data.shape}\")\nprint(f\"数据一致性: {np.array_equal(lobe_mask, loaded_lobes.data)}\")\n\n# 演示语义查询 (基于加载的掩膜)\nleft_upper_lobe_mask = loaded_lobes.get_binary_mask_by_names(\"left_upper_lobe\")\nnodule_1_mask = loaded_lesions.get_binary_mask_by_names(\"nodule_1\")\nprint(f\"左上叶掩膜像素数: {np.sum(left_upper_lobe_mask)}\")\nprint(f\"病灶1掩膜像素数: {np.sum(nodule_1_mask)}\")",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html#使用建议",
    "href": "2.3_mask_archive.html#使用建议",
    "title": "多掩膜归档管理",
    "section": "7. 使用建议",
    "text": "7. 使用建议\n\n适用场景\n推荐使用 MaskArchive 的情况： - 需要管理大量相关掩膜（&gt;10个文件） - 所有掩膜共享相同的空间参考 - 需要简化文件传输和备份 - 追求存储空间优化\n继续使用独立文件的情况： - 掩膜数量较少（&lt;5个文件） - 不同掩膜有不同的空间参数 - 需要频繁单独修改特定掩膜 - 与现有工具链的兼容性考虑\n\n\n技术限制\n\n空间一致性要求：所有掩膜必须具有相同的 shape、spacing、origin\n名称唯一性：归档中每个掩膜必须有唯一的名称标识\n增量添加：支持动态添加新掩膜，但不支持删除现有掩膜",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "2.3_mask_archive.html#总结",
    "href": "2.3_mask_archive.html#总结",
    "title": "多掩膜归档管理",
    "section": "总结",
    "text": "总结\nMaskArchive 提供了一种简单有效的多掩膜管理方案。通过将相关的掩膜合并到单一归档文件中，它能够简化文件管理、优化存储空间，并为复杂的多层级掩膜组织提供技术支持。\n虽然不是革命性的功能，但在处理大量掩膜文件时，MaskArchive 确实能够带来实用的管理便利。选择使用归档还是独立文件，主要取决于具体的应用场景和文件管理需求。\n\n# 清理测试文件\nimport os\ncleanup_files = [\"lung_lobes.msk\", \"lung_segments.msk\", \"lung_lesions.msk\", \n                 \"whole_lung.msk\", \"lung_analysis.mska\"]\nfor f in cleanup_files:\n    if os.path.exists(f):\n        os.remove(f)\nprint(\"测试文件已清理\")",
    "crumbs": [
      "首页",
      "MedMask",
      "多掩膜归档管理"
    ]
  },
  {
    "objectID": "1.5_axis_order.html",
    "href": "1.5_axis_order.html",
    "title": "三维轴序约定",
    "section": "",
    "text": "在使用SimpleITK处理医学影像时，一个常见的问题是SimpleITK.Image对象和它转换成的NumPy数组在轴的顺序上不一致。具体来说，image.GetSize()返回的维度顺序是 (X, Y, Z)，而sitk.GetArrayFromImage(image)返回的NumPy数组的 shape 属性却是 (Z, Y, X)。\n下面的代码演示了这个问题：\n\nimport SimpleITK as sitk\ndirname = \"dicube-testdata/dicom/sample_200\"\n\nreader = sitk.ImageSeriesReader()\ndicom_names = reader.GetGDCMSeriesFileNames(dirname)\nreader.SetFileNames(dicom_names)\nsitk_image = reader.Execute()\n\n# SimpleITK Image对象的尺寸，顺序为 (X, Y, Z)\nprint(\"image.GetSize() -&gt;\", sitk_image.GetSize(), \"(X, Y, Z)\")\n\n# 转换成NumPy数组后，shape的顺序为 (Z, Y, X)\narray = sitk.GetArrayFromImage(sitk_image)\nprint(\"array.shape -&gt;\", array.shape, \"(Z, Y, X)\")\n\n这种不一致并非程序错误，而是一个为了性能而做的设计选择。它源于不同编程生态系统对多维数组存储方式的历史差异。",
    "crumbs": [
      "首页",
      "DiCube",
      "三维轴序约定"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#问题描述simpleitk-的轴序不一致",
    "href": "1.5_axis_order.html#问题描述simpleitk-的轴序不一致",
    "title": "三维轴序约定",
    "section": "",
    "text": "在使用SimpleITK处理医学影像时，一个常见的问题是SimpleITK.Image对象和它转换成的NumPy数组在轴的顺序上不一致。具体来说，image.GetSize()返回的维度顺序是 (X, Y, Z)，而sitk.GetArrayFromImage(image)返回的NumPy数组的 shape 属性却是 (Z, Y, X)。\n下面的代码演示了这个问题：\n\nimport SimpleITK as sitk\ndirname = \"dicube-testdata/dicom/sample_200\"\n\nreader = sitk.ImageSeriesReader()\ndicom_names = reader.GetGDCMSeriesFileNames(dirname)\nreader.SetFileNames(dicom_names)\nsitk_image = reader.Execute()\n\n# SimpleITK Image对象的尺寸，顺序为 (X, Y, Z)\nprint(\"image.GetSize() -&gt;\", sitk_image.GetSize(), \"(X, Y, Z)\")\n\n# 转换成NumPy数组后，shape的顺序为 (Z, Y, X)\narray = sitk.GetArrayFromImage(sitk_image)\nprint(\"array.shape -&gt;\", array.shape, \"(Z, Y, X)\")\n\n这种不一致并非程序错误，而是一个为了性能而做的设计选择。它源于不同编程生态系统对多维数组存储方式的历史差异。",
    "crumbs": [
      "首页",
      "DiCube",
      "三维轴序约定"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#历史背景行优先-c-order-与列优先-f-order",
    "href": "1.5_axis_order.html#历史背景行优先-c-order-与列优先-f-order",
    "title": "三维轴序约定",
    "section": "2. 历史背景：行优先 (C-Order) 与列优先 (F-Order)",
    "text": "2. 历史背景：行优先 (C-Order) 与列优先 (F-Order)\n计算机内存本质上是一维线性的。多维数组在内存中的存储方式主要有两种标准：\n\n行优先 (Row-Major Order / C-Order)：这是C/C++、Python (NumPy) 等语言的默认方式。数据按行连续存储。对于一个三维图像，其访问顺序通常被理解为 (深度, 高度, 宽度)，即 (Z, Y, X)。\n列优先 (Column-Major Order / F-Order)：这是Fortran、MATLAB、R等语言的默认方式。数据按列连续存储。这种方式更贴近传统的笛卡尔坐标系，访问顺序通常被理解为 (X, Y, Z)。\n\n医学影像领域的许多基础库，如ITK、VTK，以及DICOM标准的设计，都深受Fortran科学计算传统的影响，因此其内部数据表示和元数据都遵循 (X, Y, Z) 的列优先约定。SimpleITK作为ITK的接口，自然也继承了这一约定。",
    "crumbs": [
      "首页",
      "DiCube",
      "三维轴序约定"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#技术原理零拷贝转换及其后果",
    "href": "1.5_axis_order.html#技术原理零拷贝转换及其后果",
    "title": "三维轴序约定",
    "section": "3. 技术原理：零拷贝转换及其后果",
    "text": "3. 技术原理：零拷贝转换及其后果\n当调用 sitk.GetArrayFromImage() 时，SimpleITK 为了最大化效率，采用了零拷贝（Zero-Copy）机制。它不会在内存中重新排列数据来适应 NumPy 的行优先标准，而是直接将 ITK 管理的内存块暴露给 NumPy，同时提供一套新的“解读规则”（即 shape 和 strides 元数据），让 NumPy 能以行优先的方式去理解这段原本按列优先存储的数据。\n我们可以用NumPy模拟这个过程。对于同一段线性数据，可以通过不同的strides（步长）信息，将其解释为不同的多维结构。\n\nimport numpy as np\nimport time\n\n# 假设一段线性内存数据\noriginal_data = np.arange(10)\nprint(f\"原始线性数据: {original_data}\")\n\n# 按C-order (行优先) 解释\nc_order_array = np.reshape(original_data, (2, 5), order='C')\nprint(f\"\\nC-order 数组:\\n{c_order_array}\")\n# 要移动到下一行(从0到5)，内存指针需要跳过5个元素\nprint(f\"C-order Strides: {c_order_array.strides}\") \n\n# 按F-order (列优先) 解释\nf_order_array = np.reshape(original_data, (5, 2), order='F')\nprint(f\"\\nF-order 数组:\\n{f_order_array}\")\n# 要移动到下一行(从0到1)，内存指针只需要跳过1个元素\nprint(f\"F-order Strides: {f_order_array.strides}\")\n\nSimpleITK的零拷贝操作虽然速度极快，但其直接后果就是轴序的翻转 (X, Y, Z) -&gt; (Z, Y, X)。这个结果给开发者带来了实际的编程负担和潜在风险。",
    "crumbs": [
      "首页",
      "DiCube",
      "三维轴序约定"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#给开发者带来的实际问题",
    "href": "1.5_axis_order.html#给开发者带来的实际问题",
    "title": "三维轴序约定",
    "section": "4. 给开发者带来的实际问题",
    "text": "4. 给开发者带来的实际问题\n轴序不一致会引发两类主要问题：认知负担和性能开销。\n\n4.1. 认知负担与常见错误\n开发者必须在编码时持续关注轴序的转换，这很容易导致错误：\n\n元数据不匹配：image.GetSpacing()返回的体素间距是 (X, Y, Z) 顺序，必须手动将其与 (Z, Y, X) 顺序的数组对应起来，例如 spacing_z = spacing_xyz[2]。\n索引错误：对数组进行切片或索引时，很容易下意识地使用 (x, y, z) 顺序，而正确的应该是 array[z, y, x]。\n函数参数错误：在使用如scipy.ndimage.zoom等需要数组和参数轴序对应的函数时，极易传错参数顺序，导致非预期的空间变换结果。\n\n\n\n4.2. 手动修正的性能代价\n一个直接的想法是获取数组后立即使用 .transpose(2, 1, 0) 将其手动转换为 (X, Y, Z) 顺序，然后所有的 python 代码也在 (X, Y, Z) 上进行，这样全部与simpleitk 的生态保持一致。然而，这个操作并非没有代价。\n1. 创建非连续数组 首先，我们创建一个模拟真实图像的连续数组。\n\n# 创建一个200x300x400的连续数组 (ZYX)\nlarge_array_zyx = np.random.rand(399, 400, 401).astype(np.float32)\nprint(f\"原始数组 C-contiguous: {large_array_zyx.flags['C_CONTIGUOUS']}\")\n\n.transpose() 操作本身很快，因为它不移动数据，只改变strides信息。但它会产生一个**非连续（Non-Contiguous）**的数组视图。\n\n# 转置操作 (ZYX -&gt; XYZ)\ntransposed_view_xyz = large_array_zyx.transpose(2, 1, 0)\nprint(f\"转置后视图 C-contiguous: {transposed_view_xyz.flags['C_CONTIGUOUS']}\")\n\n2. 非连续数组的计算性能 在非连续数组上进行运算时，由于数据在内存中是跳跃访问的，会降低CPU缓存命中率，导致计算性能下降。\n\ndef benchmark_operation(arr, name):\n    start = time.time()\n    _ = np.sum(arr[60:100] * 2.0 + 1.0)\n    end = time.time()\n    exec_time = (end - start) * 1000\n    print(f\"  {name}: {exec_time:.2f} ms\")\n    return exec_time\n\noriginal_time = benchmark_operation(large_array_zyx, \"在原始连续数组上计算\")\nview_time = benchmark_operation(transposed_view_xyz, \"在转置视图(非连续)上计算\")\nprint(f\"  性能差异: 转置视图计算慢约 {(view_time/original_time-1)*100:.1f}%\")\n\n3. 外部库的连续性要求 问题进一步复杂化的是，许多外部库和工具明确要求输入数组必须是C连续的（C-contiguous）：\n\n深度学习框架：PyTorch的 torch.from_numpy() 和TensorFlow的张量转换都要求输入数组是C-contiguous的\nGPU计算：CUDA kernels和OpenCL通常需要连续的内存布局来实现高效的GPU内存传输\nONNX推理：多数ONNX Runtime后端要求模型输入为连续数组\n图像处理库：OpenCV的某些函数和skimage的部分算法对内存布局有严格要求\n\n这意味着在将转置后的非连续数组传递给这些库之前，必须先进行连续化处理。\n4. 恢复连续性的开销 要解决性能问题和兼容性问题，需要调用np.ascontiguousarray()，但这会触发一次完整的内存拷贝，消耗额外的时间和一倍的内存。\n\nstart_time = time.time()\ncontiguous_copy_xyz = np.ascontiguousarray(transposed_view_xyz)\ncontiguous_time = (time.time() - start_time) * 1000\n\nprint(f\"强制连续化(内存拷贝)耗时: {contiguous_time:.1f} ms\")\nprint(f\"新数组 C-contiguous: {contiguous_copy_xyz.flags['C_CONTIGUOUS']}\")\nprint(f\"额外内存占用: {contiguous_copy_xyz.nbytes / 1024 / 1024:.1f} MB\")\n\n结论是，手动修正轴序问题，要么牺牲计算性能和访问效率，要么付出高昂的时间和内存成本。这个代价在深度学习和GPU计算场景中尤其显著，因为每次模型推理都需要进行连续化处理。",
    "crumbs": [
      "首页",
      "DiCube",
      "三维轴序约定"
    ]
  },
  {
    "objectID": "1.5_axis_order.html#dicube的解决方案设计上的一致性",
    "href": "1.5_axis_order.html#dicube的解决方案设计上的一致性",
    "title": "三维轴序约定",
    "section": "5. DiCube的解决方案：设计上的一致性",
    "text": "5. DiCube的解决方案：设计上的一致性\nDiCube的设计哲学是将复杂性封装在库内部，为用户提供一个简单、一致的编程接口。它选择在数据加载阶段一次性解决轴序问题。\n当使用dicube.load_from_dicom_folder()时，DiCube执行了以下操作：\n\n读取原始数据和元数据。\n使用(Z, Y, X) + C-continuous的方式重新解释内存布局，无需内存重排。\n同时，将空间元数据的xyz轴进行翻转，使spacing等元数据也符合 (Z, Y, X) 顺序。\n\n这样，用户从DiCube获取的数据和元数据在轴序上是完全统一的，可以直接用于Python生态中的其他库。\n下面的代码对比了DiCube和SimpleITK的输出：\n\nimport dicube\n# 使用DiCube加载同一份数据\ndcb_image = dicube.load_from_dicom_folder(dirname, sort_method=dicube.SortMethod.POSITION_RIGHT_HAND)\n\nprint(\"--- DiCube: 轴序一致 ---\")\n# 数组shape是 (Z, Y, X)\nprint('dicube array.shape -&gt;', dcb_image.get_fdata().shape, '(Z, Y, X)')\n# space.spacing也是 (Z, Y, X)\nprint('dicube space.spacing -&gt;', dcb_image.space.spacing, '(Z, Y, X)')\n# 索引直接对应\nprint(f\"  数组轴0(Z)的spacing为: {dcb_image.space.spacing[0]}\")\n\nprint(\"\\n--- SimpleITK: 轴序不一致 ---\")\n# 数组shape是 (Z, Y, X)\nprint(\"simpleitk array.shape -&gt;\", array.shape, \"(Z, Y, X)\")\n# GetSpacing()是 (X, Y, Z)\nprint(\"simpleitk image.GetSpacing() -&gt;\", sitk_image.GetSpacing(), \"(X, Y, Z)\")\n# 索引需要转换\nprint(f\"  数组轴0(Z)的spacing为: {sitk_image.GetSpacing()[2]}\")\n\n由于DiCube只是重新解释内存布局和翻转space轴序，没有实际的内存重排开销。它通过提供一个统一且符合Python开发者直觉的接口，从根本上消除了后续处理流程中所有因轴序不一致而引发的认知负担和潜在错误。",
    "crumbs": [
      "首页",
      "DiCube",
      "三维轴序约定"
    ]
  },
  {
    "objectID": "1.1_vs_nifti-en.html",
    "href": "1.1_vs_nifti-en.html",
    "title": "Compared With NIfTI",
    "section": "",
    "text": "NIfTI is the de facto format in neuroimaging research, enabling sharing and algorithm development. However, when used in rigorous clinical workflows, three issues become prominent: inconsistent spatial conventions, heavy metadata loss, and limited compression efficiency.\nThese issues compound across the lifecycle from acquisition (DICOM) → research (NIfTI) → back to clinical systems (e.g., navigation/archiving), creating obstacles for consistency and traceability.\n\n\nReading the same NIfTI file using different libraries can yield inconsistent origin and orientation (RAS+ vs LPS+ practices), leading to downstream registration and analysis risks.\n\nimport nibabel as nib\nimport SimpleITK as sitk\nimport numpy as np\n\nnifti_file = \"dicube-testdata/nifti/CT_Philips.nii.gz\"\nnib_image = nib.load(nifti_file)\nsitk_image = sitk.ReadImage(nifti_file)\n\nprint(f\"Nibabel Origin: {nib_image.affine[:3, 3]} (RAS+ oriented)\")\nprint(f\"SimpleITK Origin: {sitk_image.GetOrigin()} (LPS+ oriented)\")\n\nx_nib = nib_image.affine[:3, 0]; x_nib /= np.linalg.norm(x_nib)\nprint(f\"Nibabel X Orientation: {x_nib}\")\nprint(f\"SimpleITK X Orientation: {np.array(sitk_image.GetDirection())[:3]}\")\n\ny_nib = nib_image.affine[:3, 1]; y_nib /= np.linalg.norm(y_nib)\nprint(f\"Nibabel Y Orientation: {y_nib}\")\nprint(f\"SimpleITK Y Orientation: {np.array(sitk_image.GetDirection())[3:6]}\")\n\nz_nib = nib_image.affine[:3, 2]; z_nib /= np.linalg.norm(z_nib)\nprint(f\"Nibabel Z Orientation: {z_nib}\")\nprint(f\"SimpleITK Z Orientation: {np.array(sitk_image.GetDirection())[6:9]}\")\n\n\n\n\n\nLPS+ (DICOM/clinical): X→Left, Y→Posterior, Z→Superior\nRAS+ (neuro/research): X→Right, Y→Anterior, Z→Superior\n\nThey differ on X and Y directions, explaining the common sign flips across libraries.\n\n\n\nNIfTI stores two affine transforms: qform (scanner space) and sform (aligned/standard space). Libraries may prefer one over the other, producing varying origins/orientations for the same file.\n\nqform = nib_image.get_qform()\nsform = nib_image.get_sform()\nprint(\"qform (scanner space):\\n\", np.round(qform, 3))\nprint(\"\\nsform (standard space):\\n\", np.round(sform, 3))\n\n\n\n\nConverting from DICOM to NIfTI typically drops most clinical metadata (patient, study, device, acquisition parameters). The file becomes detached from its clinical context and is hard to round‑trip safely.\n\n\n\n.nii.gz uses gzip (DEFLATE), a general‑purpose codec not optimized for medical images. Compression ratios are typically 2–4×, leaving room for improvement.",
    "crumbs": [
      "首页",
      "DiCube",
      "Compared With NIfTI"
    ]
  },
  {
    "objectID": "1.1_vs_nifti-en.html#problem-niftis-core-challenges-in-clinical-workflows",
    "href": "1.1_vs_nifti-en.html#problem-niftis-core-challenges-in-clinical-workflows",
    "title": "Compared With NIfTI",
    "section": "",
    "text": "NIfTI is the de facto format in neuroimaging research, enabling sharing and algorithm development. However, when used in rigorous clinical workflows, three issues become prominent: inconsistent spatial conventions, heavy metadata loss, and limited compression efficiency.\nThese issues compound across the lifecycle from acquisition (DICOM) → research (NIfTI) → back to clinical systems (e.g., navigation/archiving), creating obstacles for consistency and traceability.\n\n\nReading the same NIfTI file using different libraries can yield inconsistent origin and orientation (RAS+ vs LPS+ practices), leading to downstream registration and analysis risks.\n\nimport nibabel as nib\nimport SimpleITK as sitk\nimport numpy as np\n\nnifti_file = \"dicube-testdata/nifti/CT_Philips.nii.gz\"\nnib_image = nib.load(nifti_file)\nsitk_image = sitk.ReadImage(nifti_file)\n\nprint(f\"Nibabel Origin: {nib_image.affine[:3, 3]} (RAS+ oriented)\")\nprint(f\"SimpleITK Origin: {sitk_image.GetOrigin()} (LPS+ oriented)\")\n\nx_nib = nib_image.affine[:3, 0]; x_nib /= np.linalg.norm(x_nib)\nprint(f\"Nibabel X Orientation: {x_nib}\")\nprint(f\"SimpleITK X Orientation: {np.array(sitk_image.GetDirection())[:3]}\")\n\ny_nib = nib_image.affine[:3, 1]; y_nib /= np.linalg.norm(y_nib)\nprint(f\"Nibabel Y Orientation: {y_nib}\")\nprint(f\"SimpleITK Y Orientation: {np.array(sitk_image.GetDirection())[3:6]}\")\n\nz_nib = nib_image.affine[:3, 2]; z_nib /= np.linalg.norm(z_nib)\nprint(f\"Nibabel Z Orientation: {z_nib}\")\nprint(f\"SimpleITK Z Orientation: {np.array(sitk_image.GetDirection())[6:9]}\")\n\n\n\n\n\nLPS+ (DICOM/clinical): X→Left, Y→Posterior, Z→Superior\nRAS+ (neuro/research): X→Right, Y→Anterior, Z→Superior\n\nThey differ on X and Y directions, explaining the common sign flips across libraries.\n\n\n\nNIfTI stores two affine transforms: qform (scanner space) and sform (aligned/standard space). Libraries may prefer one over the other, producing varying origins/orientations for the same file.\n\nqform = nib_image.get_qform()\nsform = nib_image.get_sform()\nprint(\"qform (scanner space):\\n\", np.round(qform, 3))\nprint(\"\\nsform (standard space):\\n\", np.round(sform, 3))\n\n\n\n\nConverting from DICOM to NIfTI typically drops most clinical metadata (patient, study, device, acquisition parameters). The file becomes detached from its clinical context and is hard to round‑trip safely.\n\n\n\n.nii.gz uses gzip (DEFLATE), a general‑purpose codec not optimized for medical images. Compression ratios are typically 2–4×, leaving room for improvement.",
    "crumbs": [
      "首页",
      "DiCube",
      "Compared With NIfTI"
    ]
  },
  {
    "objectID": "1.1_vs_nifti-en.html#dicube-designed-for-clinical-research-together",
    "href": "1.1_vs_nifti-en.html#dicube-designed-for-clinical-research-together",
    "title": "Compared With NIfTI",
    "section": "2. DiCube: Designed For Clinical + Research Together",
    "text": "2. DiCube: Designed For Clinical + Research Together\n\n2.1. Unified Coordinate System (LPS+)\nDiCube adopts DICOM’s LPS+ consistently. Reading the same DICOM series, DiCube matches SimpleITK’s interpretation.\n\nimport dicube, numpy as np\n\ndcb_image = dicube.load_from_dicom_folder(dicom_dir, sort_method=dicube.SortMethod.POSITION_RIGHT_HAND)\nprint(\"SimpleITK (from DICOM):\", np.round(sitk_image_from_dicom.GetOrigin(), 3))\nprint(\"DiCube      (from DICOM):\", np.round(dcb_image.space.origin, 3))\n\n\n\n2.2. Full Metadata Preservation and Round‑Trip\nDiCube embeds all DICOM metadata (including private tags) and supports lossless DICOM round‑trip.\n\ndicube.save(dcb_image, 'dicube-testdata/test.dcbs')\ndicube.save_to_dicom_folder(dcb_image, 'dicube-testdata/roundtrip_test')\n\nroundtrip_slice_path = 'dicube-testdata/roundtrip_test/slice_0000.dcm'\nroundtrip_dcm = pydicom.dcmread(roundtrip_slice_path)\n\nprint(\"Round‑trip fields match:\")\nfor field in ['PatientID','StudyDate','Manufacturer','WindowWidth','WindowCenter']:\n    print(field, original_dcm.get(field) == roundtrip_dcm.get(field))\n\n\n\n2.3. Efficient Medical Compression (HTJ2K)\nHTJ2K (a DICOM standard codec) provides significantly higher compression ratios and fast throughput compared to gzip for imaging data.\n\n\n2.4. Optimized I/O\nSingle‑file structure + efficient codec lead to faster loads than .nii.gz in many scenarios.\n\nimport time\n\nstart = time.time(); _ = sitk.ReadImage(nifti_file2); nifti_ms = (time.time()-start)*1000\nstart = time.time(); _ = dicube.load('dicube-testdata/test.dcbs'); dcb_ms = (time.time()-start)*1000\nprint(f\"NIfTI load: {nifti_ms:.0f} ms, DiCube load: {dcb_ms:.0f} ms\")",
    "crumbs": [
      "首页",
      "DiCube",
      "Compared With NIfTI"
    ]
  },
  {
    "objectID": "1.1_vs_nifti-en.html#summary",
    "href": "1.1_vs_nifti-en.html#summary",
    "title": "Compared With NIfTI",
    "section": "3. Summary",
    "text": "3. Summary\n\n\n\n\n\n\n\n\nFeature\nNIfTI Issue\nDiCube Solution\n\n\n\n\nCoordinates\nMixed LPS+/RAS+, qform/sform ambiguity\nUnified LPS+ (DICOM‑consistent)\n\n\nMetadata\n&gt;95% clinical metadata lost\n100% lossless round‑trip with full tags\n\n\nCompression\nGzip (2–4×)\nHTJ2K (often 5–15× or better)\n\n\nDICOM Workflow\nOne‑way lossy conversion\nTwo‑way lossless; safe clinical container\n\n\nI/O + API\nGzip‑bound I/O, library variance\nSingle‑file + clear, consistent APIs\n\n\n\nConclusion: NIfTI works well for pure research exchange. For applications that require integrity, traceability, and clinical interoperability, DiCube offers a safer, faster, and more reliable modern alternative.",
    "crumbs": [
      "首页",
      "DiCube",
      "Compared With NIfTI"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html",
    "href": "1.1_vs_nifti.html",
    "title": "与NIfTI格式对比",
    "section": "",
    "text": "结论：NIfTI 在临床工作流中的三大痛点是坐标系统不一致、元数据丢失与压缩效率不足；DiCube 提供统一坐标（LPS+）、无损往返与 HTJ2K 压缩的系统性应对。\nNIfTI 格式作为神经影像研究领域的通用标准，极大地促进了学术交流与算法开发。然而，当试图将其应用于严谨的临床工作流时，其固有的设计缺陷便暴露无遗。本文聚焦 NIfTI 在实际临床应用中面临的三个核心挑战：坐标系统混乱、元数据大量丢失、压缩效率不足。\n这些问题并非孤立存在，而是在数据从临床影像设备（DICOM 格式）转换到研究环境（NIfTI 格式），再尝试回归临床系统（例如用于手术导航或存档）的完整生命周期中相互交织，形成数据一致性与可追溯性的障碍。\n让我们首先通过代码演示，直观地揭示这些问题的具体表现。\n\n\nNIfTI 格式最令人困惑的问题之一，是其空间坐标定义的不统一。使用不同的标准库读取同一个 NIfTI 文件，竟然会得到截然不同的空间定位结果。这种不一致性为后续的图像配准、融合以及定量分析埋下了巨大的隐患。\n\nimport nibabel as nib\nimport SimpleITK as sitk\nimport numpy as np\n\n# 测试数据\nnifti_file = \"dicube-testdata/nifti/CT_Philips.nii.gz\"\n\n# 使用两种广泛应用的库读取同一个NIfTI文件\nnib_image = nib.load(nifti_file)\nsitk_image = sitk.ReadImage(nifti_file)\n\nprint(f\"Nibabel Origin: {nib_image.affine[:3, 3]} (通常为 RAS+)\")\nprint(f\"SimpleITK Origin: {sitk_image.GetOrigin()} (严格为 LPS+)\")\nprint()\n\n# 提取并标准化X轴方向向量\nx_nib = nib_image.affine[:3, 0]\nx_nib /= np.linalg.norm(x_nib)\nprint(f\"Nibabel X Orientation: {x_nib}\")\nprint(f\"SimpleITK X Orientation: {np.array(sitk_image.GetDirection())[:3]}\")\nprint()\n\n# 提取并标准化Y轴方向向量\ny_nib = nib_image.affine[:3, 1]\ny_nib /= np.linalg.norm(y_nib)\nprint(f\"Nibabel Y Orientation: {y_nib}\")\nprint(f\"SimpleITK Y Orientation: {np.array(sitk_image.GetDirection())[3:6]}\")\nprint()\n\n# 提取并标准化Z轴方向向量\nz_nib = nib_image.affine[:3, 2]\nz_nib /= np.linalg.norm(z_nib)\nprint(f\"Nibabel Z Orientation: {z_nib}\")\nprint(f\"SimpleITK Z Orientation: {np.array(sitk_image.GetDirection())[6:9]}\")\n\n从输出结果可以清晰地看到，对于图像原点（Origin）和方向（Orientation），nibabel 和 SimpleITK 的解析大相径庭。方向向量在 X 和 Y 轴上互为相反数，而原点的差异则毫无规律可循。这种混乱的根源在于 NIfTI 对坐标系统的双重定义以及不同社区的解读习惯。\n\n\n\n要理解上述差异，首先需要了解医学影像中两个主流的笛卡尔坐标系：LPS+ 和 RAS+。\n\nLPS+ (Left, Posterior, Superior)：这是 DICOM 标准以及放射科医生习惯使用的坐标系。\n\nX轴正方向：指向患者的左侧 (Left)。\nY轴正方向：指向患者的背侧 (Posterior)。\nZ轴正方向：指向患者的头顶 (Superior)。\n\nRAS+ (Right, Anterior, Superior)：这是神经影像分析领域（尤其是一些流行的软件包如 FSL, FreeSurfer）常用的坐标系。\n\nX轴正方向：指向患者的右侧 (Right)。\nY轴正方向：指向患者的腹侧 (Anterior)。\nZ轴正方向：同样指向患者的头顶 (Superior)。\n\n\n两者在Z轴上定义一致，但在X轴和Y轴上方向完全相反。这就是为什么我们在上面的代码输出中看到 X 和 Y 方向向量互为相反数。SimpleITK 严格遵循 DICOM 的 LPS+ 约定，而 nibabel 则更倾向于神经影像研究的 RAS+ 约定。\n\n\n\n仅仅是 LPS+ 和 RAS+ 的区别还不足以解释原点（Origin）的巨大差异。NIfTI 格式内部设计了两个独立的仿射变换矩阵来描述图像空间与世界空间的关系，这进一步加剧了混乱：\n\nqform (quaternion form)：主要用于记录图像相对于扫描仪设备坐标系的空间信息。它通常直接从原始 DICOM 头的 Image Position (Patient) 和 Image Orientation (Patient) 标签计算得来，反映的是图像采集时的物理位置和方向。\nsform (standard form)：主要用于记录图像对齐到某个标准空间模板（如 MNI 或 Talairach 脑模板）后的空间信息。这个矩阵通常是图像配准（registration）过程的产物。\n\n一个 NIfTI 文件可以同时包含 qform 和 sform，当两者不一致时，不同的读取库会根据自身的应用背景做出不同的选择：\n\n# 探查NIfTI文件内部的双重变换矩阵\nqform = nib_image.get_qform()\nsform = nib_image.get_sform()\n\nprint(f\"qform (源自扫描仪坐标):\")\nprint(np.round(qform, 3))\nprint(f\"\\nsform (对齐至标准空间):\")\nprint(np.round(sform, 3))\n\n\nSimpleITK 的选择：遵循放射科和临床设备的惯例，优先使用 qform，因为它最忠实地反映了原始扫描信息。\nNibabel 的选择：遵循神经科学研究的惯例，优先使用 sform，因为它代表了数据在标准脑模板下的分析坐标。\n\n在我们的示例中，qform 和 sform 的平移分量（最后一列）相差甚远，这直接导致了 SimpleITK 和 nibabel 解读出的图像原点位置完全不同。这种依赖于“潜规则”的设计，使得 NIfTI 文件在跨平台、跨工具链使用时，极易发生空间定位错误。\n\n\n\n从 DICOM 转换为 NIfTI 的过程是“有损”的，但损失的并非像素数据，而是宝贵的元数据（Metadata）。DICOM 文件内嵌了数百个描述患者、检查、设备、序列参数等信息的标签，这些信息对于临床诊断、质量控制和法律追溯至关重要。\nNIfTI 格式的设计初衷是服务于匿名的图像算法研究，因此它几乎丢弃了所有与空间定位无关的元数据。\n\nimport pydicom\nimport os\n\n# 检查原始DICOM元数据\ndicom_dir = 'dicube-testdata/dicom/sample_200'\nfirst_slice_path = os.path.join(dicom_dir, sorted(os.listdir(dicom_dir))[0])\noriginal_dcm = pydicom.dcmread(first_slice_path)\n\nprint(f\"原始DICOM元数据字段数: {len(original_dcm)}\")\nprint(f\"患者ID (PatientID): {original_dcm.get('PatientID', 'N/A')}\")\nprint(f\"检查日期 (StudyDate): {original_dcm.get('StudyDate', 'N/A')}\")\nprint(f\"设备制造商 (Manufacturer): {original_dcm.get('Manufacturer', 'N/A')}\")\nprint(f\"窗宽/窗位 (Window Width/Center): {original_dcm.get('WindowWidth', 'N/A')} / {original_dcm.get('WindowCenter', 'N/A')}\")\n\n# NIfTI文件几乎不包含这些信息\n# NIfTI header can be accessed via nib_image.header, but it lacks most clinical metadata.\nprint(f\"\\nNIfTI格式仅保留了图像尺寸、像素间距、原点和方向等基本空间信息。\")\n\n这种元数据的“蒸发”意味着，一旦数据被转换为 NIfTI，它就与原始的临床情境脱钩。我们无法知道这个图像属于哪位患者、何时检查、由哪台设备扫描、扫描参数是什么。这使得 NIfTI 文件无法被直接用于临床生产环境或作为合规的医疗数据存档。\n\n\n\n为了节省存储空间，NIfTI 文件通常使用 .nii.gz 的扩展名，即采用 gzip 进行压缩。Gzip 是一种通用的、无损的压缩算法，但它并非为医学影像这类具有高度空间相关性的数据而优化。因此，其压缩比通常相当有限。\n\nimport os\n\n# 对比原始DICOM和NIfTI格式的存储大小\ndicom_size = sum(os.path.getsize(os.path.join(dicom_dir, f)) \n                 for f in os.listdir(dicom_dir))\nnifti_file2 = 'dicube-testdata/sample_200.nii.gz'\n\n# SimpleITK读取DICOM序列\nseries_reader = sitk.ImageSeriesReader()\ndicom_names = series_reader.GetGDCMSeriesFileNames(dicom_dir)\nseries_reader.SetFileNames(dicom_names)\nsitk_image_from_dicom = series_reader.Execute()\nsitk.WriteImage(sitk_image_from_dicom, nifti_file2)\nnifti_size = os.path.getsize(nifti_file2)\n\nprint(f\"原始DICOM文件夹总大小: {dicom_size / 1024 / 1024:.2f} MB\")\nprint(f\"NIfTI (gzip压缩后)大小: {nifti_size / 1024 / 1024:.2f} MB\")\nprint(f\"压缩比: {dicom_size / nifti_size:.2f}x\")\n\n通常，gzip 只能提供约 2 倍的压缩率，这对于动辄数百兆甚至上G的影像数据而言，存储和传输效率仍然不高。",
    "crumbs": [
      "首页",
      "DiCube",
      "与NIfTI格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#问题描述nifti-在临床应用中的核心挑战",
    "href": "1.1_vs_nifti.html#问题描述nifti-在临床应用中的核心挑战",
    "title": "与NIfTI格式对比",
    "section": "",
    "text": "结论：NIfTI 在临床工作流中的三大痛点是坐标系统不一致、元数据丢失与压缩效率不足；DiCube 提供统一坐标（LPS+）、无损往返与 HTJ2K 压缩的系统性应对。\nNIfTI 格式作为神经影像研究领域的通用标准，极大地促进了学术交流与算法开发。然而，当试图将其应用于严谨的临床工作流时，其固有的设计缺陷便暴露无遗。本文聚焦 NIfTI 在实际临床应用中面临的三个核心挑战：坐标系统混乱、元数据大量丢失、压缩效率不足。\n这些问题并非孤立存在，而是在数据从临床影像设备（DICOM 格式）转换到研究环境（NIfTI 格式），再尝试回归临床系统（例如用于手术导航或存档）的完整生命周期中相互交织，形成数据一致性与可追溯性的障碍。\n让我们首先通过代码演示，直观地揭示这些问题的具体表现。\n\n\nNIfTI 格式最令人困惑的问题之一，是其空间坐标定义的不统一。使用不同的标准库读取同一个 NIfTI 文件，竟然会得到截然不同的空间定位结果。这种不一致性为后续的图像配准、融合以及定量分析埋下了巨大的隐患。\n\nimport nibabel as nib\nimport SimpleITK as sitk\nimport numpy as np\n\n# 测试数据\nnifti_file = \"dicube-testdata/nifti/CT_Philips.nii.gz\"\n\n# 使用两种广泛应用的库读取同一个NIfTI文件\nnib_image = nib.load(nifti_file)\nsitk_image = sitk.ReadImage(nifti_file)\n\nprint(f\"Nibabel Origin: {nib_image.affine[:3, 3]} (通常为 RAS+)\")\nprint(f\"SimpleITK Origin: {sitk_image.GetOrigin()} (严格为 LPS+)\")\nprint()\n\n# 提取并标准化X轴方向向量\nx_nib = nib_image.affine[:3, 0]\nx_nib /= np.linalg.norm(x_nib)\nprint(f\"Nibabel X Orientation: {x_nib}\")\nprint(f\"SimpleITK X Orientation: {np.array(sitk_image.GetDirection())[:3]}\")\nprint()\n\n# 提取并标准化Y轴方向向量\ny_nib = nib_image.affine[:3, 1]\ny_nib /= np.linalg.norm(y_nib)\nprint(f\"Nibabel Y Orientation: {y_nib}\")\nprint(f\"SimpleITK Y Orientation: {np.array(sitk_image.GetDirection())[3:6]}\")\nprint()\n\n# 提取并标准化Z轴方向向量\nz_nib = nib_image.affine[:3, 2]\nz_nib /= np.linalg.norm(z_nib)\nprint(f\"Nibabel Z Orientation: {z_nib}\")\nprint(f\"SimpleITK Z Orientation: {np.array(sitk_image.GetDirection())[6:9]}\")\n\n从输出结果可以清晰地看到，对于图像原点（Origin）和方向（Orientation），nibabel 和 SimpleITK 的解析大相径庭。方向向量在 X 和 Y 轴上互为相反数，而原点的差异则毫无规律可循。这种混乱的根源在于 NIfTI 对坐标系统的双重定义以及不同社区的解读习惯。\n\n\n\n要理解上述差异，首先需要了解医学影像中两个主流的笛卡尔坐标系：LPS+ 和 RAS+。\n\nLPS+ (Left, Posterior, Superior)：这是 DICOM 标准以及放射科医生习惯使用的坐标系。\n\nX轴正方向：指向患者的左侧 (Left)。\nY轴正方向：指向患者的背侧 (Posterior)。\nZ轴正方向：指向患者的头顶 (Superior)。\n\nRAS+ (Right, Anterior, Superior)：这是神经影像分析领域（尤其是一些流行的软件包如 FSL, FreeSurfer）常用的坐标系。\n\nX轴正方向：指向患者的右侧 (Right)。\nY轴正方向：指向患者的腹侧 (Anterior)。\nZ轴正方向：同样指向患者的头顶 (Superior)。\n\n\n两者在Z轴上定义一致，但在X轴和Y轴上方向完全相反。这就是为什么我们在上面的代码输出中看到 X 和 Y 方向向量互为相反数。SimpleITK 严格遵循 DICOM 的 LPS+ 约定，而 nibabel 则更倾向于神经影像研究的 RAS+ 约定。\n\n\n\n仅仅是 LPS+ 和 RAS+ 的区别还不足以解释原点（Origin）的巨大差异。NIfTI 格式内部设计了两个独立的仿射变换矩阵来描述图像空间与世界空间的关系，这进一步加剧了混乱：\n\nqform (quaternion form)：主要用于记录图像相对于扫描仪设备坐标系的空间信息。它通常直接从原始 DICOM 头的 Image Position (Patient) 和 Image Orientation (Patient) 标签计算得来，反映的是图像采集时的物理位置和方向。\nsform (standard form)：主要用于记录图像对齐到某个标准空间模板（如 MNI 或 Talairach 脑模板）后的空间信息。这个矩阵通常是图像配准（registration）过程的产物。\n\n一个 NIfTI 文件可以同时包含 qform 和 sform，当两者不一致时，不同的读取库会根据自身的应用背景做出不同的选择：\n\n# 探查NIfTI文件内部的双重变换矩阵\nqform = nib_image.get_qform()\nsform = nib_image.get_sform()\n\nprint(f\"qform (源自扫描仪坐标):\")\nprint(np.round(qform, 3))\nprint(f\"\\nsform (对齐至标准空间):\")\nprint(np.round(sform, 3))\n\n\nSimpleITK 的选择：遵循放射科和临床设备的惯例，优先使用 qform，因为它最忠实地反映了原始扫描信息。\nNibabel 的选择：遵循神经科学研究的惯例，优先使用 sform，因为它代表了数据在标准脑模板下的分析坐标。\n\n在我们的示例中，qform 和 sform 的平移分量（最后一列）相差甚远，这直接导致了 SimpleITK 和 nibabel 解读出的图像原点位置完全不同。这种依赖于“潜规则”的设计，使得 NIfTI 文件在跨平台、跨工具链使用时，极易发生空间定位错误。\n\n\n\n从 DICOM 转换为 NIfTI 的过程是“有损”的，但损失的并非像素数据，而是宝贵的元数据（Metadata）。DICOM 文件内嵌了数百个描述患者、检查、设备、序列参数等信息的标签，这些信息对于临床诊断、质量控制和法律追溯至关重要。\nNIfTI 格式的设计初衷是服务于匿名的图像算法研究，因此它几乎丢弃了所有与空间定位无关的元数据。\n\nimport pydicom\nimport os\n\n# 检查原始DICOM元数据\ndicom_dir = 'dicube-testdata/dicom/sample_200'\nfirst_slice_path = os.path.join(dicom_dir, sorted(os.listdir(dicom_dir))[0])\noriginal_dcm = pydicom.dcmread(first_slice_path)\n\nprint(f\"原始DICOM元数据字段数: {len(original_dcm)}\")\nprint(f\"患者ID (PatientID): {original_dcm.get('PatientID', 'N/A')}\")\nprint(f\"检查日期 (StudyDate): {original_dcm.get('StudyDate', 'N/A')}\")\nprint(f\"设备制造商 (Manufacturer): {original_dcm.get('Manufacturer', 'N/A')}\")\nprint(f\"窗宽/窗位 (Window Width/Center): {original_dcm.get('WindowWidth', 'N/A')} / {original_dcm.get('WindowCenter', 'N/A')}\")\n\n# NIfTI文件几乎不包含这些信息\n# NIfTI header can be accessed via nib_image.header, but it lacks most clinical metadata.\nprint(f\"\\nNIfTI格式仅保留了图像尺寸、像素间距、原点和方向等基本空间信息。\")\n\n这种元数据的“蒸发”意味着，一旦数据被转换为 NIfTI，它就与原始的临床情境脱钩。我们无法知道这个图像属于哪位患者、何时检查、由哪台设备扫描、扫描参数是什么。这使得 NIfTI 文件无法被直接用于临床生产环境或作为合规的医疗数据存档。\n\n\n\n为了节省存储空间，NIfTI 文件通常使用 .nii.gz 的扩展名，即采用 gzip 进行压缩。Gzip 是一种通用的、无损的压缩算法，但它并非为医学影像这类具有高度空间相关性的数据而优化。因此，其压缩比通常相当有限。\n\nimport os\n\n# 对比原始DICOM和NIfTI格式的存储大小\ndicom_size = sum(os.path.getsize(os.path.join(dicom_dir, f)) \n                 for f in os.listdir(dicom_dir))\nnifti_file2 = 'dicube-testdata/sample_200.nii.gz'\n\n# SimpleITK读取DICOM序列\nseries_reader = sitk.ImageSeriesReader()\ndicom_names = series_reader.GetGDCMSeriesFileNames(dicom_dir)\nseries_reader.SetFileNames(dicom_names)\nsitk_image_from_dicom = series_reader.Execute()\nsitk.WriteImage(sitk_image_from_dicom, nifti_file2)\nnifti_size = os.path.getsize(nifti_file2)\n\nprint(f\"原始DICOM文件夹总大小: {dicom_size / 1024 / 1024:.2f} MB\")\nprint(f\"NIfTI (gzip压缩后)大小: {nifti_size / 1024 / 1024:.2f} MB\")\nprint(f\"压缩比: {dicom_size / nifti_size:.2f}x\")\n\n通常，gzip 只能提供约 2 倍的压缩率，这对于动辄数百兆甚至上G的影像数据而言，存储和传输效率仍然不高。",
    "crumbs": [
      "首页",
      "DiCube",
      "与NIfTI格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#dicube的解决方案专为临床与研究一体化设计",
    "href": "1.1_vs_nifti.html#dicube的解决方案专为临床与研究一体化设计",
    "title": "与NIfTI格式对比",
    "section": "2. DiCube的解决方案：专为临床与研究一体化设计",
    "text": "2. DiCube的解决方案：专为临床与研究一体化设计\nDiCube 格式的设计目标非常明确：在保留 NIfTI 单文件、易于处理的优点的同时，从根本上解决其在临床应用中的三大核心缺陷。\n\n2.1. 统一且明确的坐标系统：坚守LPS+标准\nDiCube 彻底摒弃了 NIfTI 模棱两可的双重坐标定义，统一采用 DICOM 标准的 LPS+ 坐标系。这确保了从 DICOM 到 DiCube 的转换过程中，空间信息得到精确、无歧义的保留，保证了与 PACS 系统和各类医学影像软件的无缝对接。\n让我们将 DiCube、SimpleITK（读取 DICOM）和 nibabel（读取 NIfTI）的处理结果进行对比：\n\nimport dicube\n\n\n# DiCube读取DICOM序列\ndcb_image = dicube.load_from_dicom_folder(dicom_dir, sort_method=dicube.SortMethod.POSITION_RIGHT_HAND)\n\n# Nibabel读取NIfTI\nnib_nifti = nib.load(nifti_file2)\n\nprint(\"--- 坐标系统原点对比 ---\")\nprint(f\"SimpleITK (从DICOM): {np.round(sitk_image_from_dicom.GetOrigin(), 3)} (LPS+)\")\nprint(f\"DiCube      (从DICOM): {np.round(dcb_image.space.origin, 3)} (LPS+)\")\nprint(f\"Nibabel     (从NIfTI): {np.round(nib_nifti.affine[:3, 3], 3)} (RAS+)\")\nprint(f\"\\n结论：DiCube与SimpleITK对原始DICOM的解读完全一致: {np.allclose(dcb_image.space.origin, sitk_image_from_dicom.GetOrigin())}\")\n\n结果一目了然：DiCube 的解析结果与同样遵循 DICOM 标准的 SimpleITK 完全一致，从源头上消除了坐标系统的混乱。\n\n\n2.2. 完整的元数据保留与往返能力\nDiCube 的核心特性之一是实现了 DICOM 元数据的无损往返（Lossless Round-trip）。它将原始 DICOM 文件中的所有元数据（包括私有标签）完整地封装在 DiCube 文件内部。这意味着，你可以随时从 DiCube 文件中恢复出与原始文件一模一样的 DICOM 序列。\n\n# 将DiCube对象保存为.dcbs文件，然后再转换回DICOM文件夹\ndicube.save(dcb_image, 'dicube-testdata/test.dcbs')\ndicube.save_to_dicom_folder(dcb_image, 'dicube-testdata/roundtrip_test')\n\n# 验证往返转换后元数据的完整性\nroundtrip_slice_path = os.path.join('dicube-testdata/roundtrip_test', 'slice_0000.dcm')\nroundtrip_dcm = pydicom.dcmread(roundtrip_slice_path)\n\nprint(f\"原始DICOM字段数: {len(original_dcm)}\")\nprint(f\"往返恢复后字段数: {len(roundtrip_dcm)}\")\nprint(f\"元数据保留率: {len(roundtrip_dcm) / len(original_dcm) * 100:.1f}%\")\nprint(\"\\n--- 关键临床字段一致性校验 ---\")\n\n# 验证关键字段是否完全一致\nkey_fields = ['PatientID', 'StudyDate', 'Manufacturer', 'WindowWidth', 'WindowCenter']\nfor field in key_fields:\n    original_value = original_dcm.get(field)\n    roundtrip_value = roundtrip_dcm.get(field)\n    match = \"✓\" if original_value == roundtrip_value else \"✗\"\n    print(f\"字段'{field}': {match} (原始: {original_value}, 恢复后: {roundtrip_value})\")\n\n近乎 100% 的元数据保留率表明 DiCube 具备在临床环境中安全流转的能力，数据保持完整性与可追溯性。\n\n\n2.3. 高效的现代医学影像压缩：HTJ2K\nDiCube 采用 High-Throughput JPEG 2000 (HTJ2K) 作为其核心压缩算法。HTJ2K 是 DICOM 标准的官方组成部分（见 DICOM Standard Part 5），专为高性能医学影像应用设计，其优势远超传统的 gzip：\n\n更高的压缩比：针对医学影像的特征进行优化，通常可提供 5-15 倍甚至更高的无损压缩率。\n性能卓越：利用现代多核 CPU 架构，编解码速度极快。\n标准兼容：作为 DICOM 标准的一部分，确保了长期的兼容性和互操作性。\n\n\n\n# 压缩效果对比\ndcb_size = os.path.getsize('dicube-testdata/test.dcbs')\n\nprint(\"--- 压缩效率对比 ---\")\nprint(f\"原始DICOM:      {dicom_size / 1024 / 1024:.2f} MB\")\nprint(f\"NIfTI (gzip):   {nifti_size / 1024 / 1024:.2f} MB (压缩比: {dicom_size / nifti_size:.2f}x)\")\nprint(f\"DiCube (HTJ2K): {dcb_size / 1024 / 1024:.2f} MB (压缩比: {dicom_size / dcb_size:.2f}x)\")\nprint(f\"\\nDiCube相比NIfTI，文件体积减小了: {(1 - dcb_size / nifti_size) * 100:.1f}%\")\n\n显著的压缩效率提升意味着更低的存储成本和更快的网络传输速度。\n\n\n2.4. 优化的 I/O 性能\n除了压缩率，DiCube 的文件结构和 HTJ2K 解码器也为快速读取进行了优化。在大部分场景下，加载 DiCube 文件比加载 gzip 压缩的 NIfTI 文件更快。\n\nimport time\n\n# 性能对比测试\nstart_time = time.time()\nnifti_loaded = sitk.ReadImage(nifti_file2)\nnifti_time = time.time() - start_time\n\nstart_time = time.time()\ndcb_loaded = dicube.load('dicube-testdata/test.dcbs')\ndcb_time = time.time() - start_time\n\nprint(f\"NIfTI (.nii.gz) 加载耗时: {nifti_time * 1000:.0f} ms\")\nprint(f\"DiCube (.dcbs) 加载耗时: {dcb_time * 1000:.0f} ms\")\n\nif dcb_time &lt; nifti_time:\n    print(f\"DiCube 加载性能提升: {(nifti_time / dcb_time - 1) * 100:.0f}%\")\nelse:\n    print(\"NIfTI 在此测试中加载更快。\")\n\n更快的加载速度对于交互式应用和大规模数据处理流水线都至关重要。\n\n# 清理测试生成的文件和文件夹\nimport shutil\n\ncleanup_files = ['dicube-testdata/test.dcbs','dicube-testdata/sample_200.nii.gz']\ncleanup_dirs = ['dicube-testdata/roundtrip_test']\n\nfor f in cleanup_files:\n    if os.path.exists(f):\n        os.remove(f)\nfor d in cleanup_dirs:\n    if os.path.exists(d):\n        shutil.rmtree(d)",
    "crumbs": [
      "首页",
      "DiCube",
      "与NIfTI格式对比"
    ]
  },
  {
    "objectID": "1.1_vs_nifti.html#总结对比",
    "href": "1.1_vs_nifti.html#总结对比",
    "title": "与NIfTI格式对比",
    "section": "3. 总结对比",
    "text": "3. 总结对比\nDiCube 通过系统性的设计，精准地解决了 NIfTI 在临床转化应用中的核心痛点。\n\n\n\n\n\n\n\n\n特性\nNIfTI 的问题\nDiCube 的解决方案\n\n\n\n\n坐标系统\nLPS+/RAS+ 混用，qform/sform 导致歧义\n统一并强制使用 DICOM 标准的 LPS+ 坐标系\n\n\n元数据保留\n转换时丢失几乎所有临床元数据（&gt;95%）\n100% 无损保留，支持完整的 DICOM 往返转换\n\n\n压缩效率\n通用 gzip 算法，压缩比有限 (约 2-4x)\n专用的 HTJ2K 算法，压缩比更高 (通常 5-15x)\n\n\nDICOM 兼容性\n单向、有损转换，无法恢复原始 DICOM\n双向、无损转换，是临床数据的安全容器\n\n\n生态与性能\n依赖外部库的解释，I/O 性能受 gzip 限制\n内置高性能解码器，提供明确一致的编程接口\n\n\n\n结论： NIfTI 仍然是纯粹算法研究和学术数据共享的有效格式。然而，对于任何需要确保数据完整性、可追溯性并计划与临床工作流对接的应用场景，DiCube 提供了一个更安全、高效和可靠的现代化解决方案。它真正弥合了研究的灵活性与临床的严谨性之间的鸿沟。",
    "crumbs": [
      "首页",
      "DiCube",
      "与NIfTI格式对比"
    ]
  },
  {
    "objectID": "1.3_dicom_status-en.html",
    "href": "1.3_dicom_status-en.html",
    "title": "DICOM Series Status",
    "section": "",
    "text": "For static 3D images, DiCube assumes a regular sampling grid. A series is CONSISTENT if it satisfies:\n\nUniform pixel spacing: PixelSpacing shared\nUniform image shape: Rows and Columns shared\nRegular slice spacing: Z positions are evenly spaced\nUniform orientation: ImageOrientationPatient shared\nContiguous instance numbers: InstanceNumber starts at 1 and increments by 1\nComplete metadata: all required DICOM tags exist and are valid\n\n\nimport dicube\nfrom dicube import get_dicom_status, DicomStatus\nfrom dicube.dicom import CommonTags\n\ndirname = 'dicube-testdata/dicom/sample_200'\nimg = dicube.load_from_dicom_folder(dirname)\nmeta = img.dicom_meta\nstatus = get_dicom_status(meta)\nprint(\"Status:\", status.value)\n\nspacing_consistent = meta.is_shared(CommonTags.PixelSpacing)\nprint(\"Spacing shared:\", spacing_consistent)\nif spacing_consistent:\n    print(\"  spacing:\", meta.get_shared_value(CommonTags.PixelSpacing), \"mm\")\n\nshape_consistent = (meta.is_shared(CommonTags.Rows) and meta.is_shared(CommonTags.Columns))\nprint(\"Shape shared:\", shape_consistent)\nif shape_consistent:\n    rows = meta.get_shared_value(CommonTags.Rows)\n    cols = meta.get_shared_value(CommonTags.Columns)\n    print(f\"  shape: {cols}×{rows}\")\n\norientation_consistent = meta.is_shared(CommonTags.ImageOrientationPatient)\nprint(\"Orientation shared:\", orientation_consistent)",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Series Status"
    ]
  },
  {
    "objectID": "1.3_dicom_status-en.html#what-is-consistent-a-regular-3d-sampling-grid",
    "href": "1.3_dicom_status-en.html#what-is-consistent-a-regular-3d-sampling-grid",
    "title": "DICOM Series Status",
    "section": "",
    "text": "For static 3D images, DiCube assumes a regular sampling grid. A series is CONSISTENT if it satisfies:\n\nUniform pixel spacing: PixelSpacing shared\nUniform image shape: Rows and Columns shared\nRegular slice spacing: Z positions are evenly spaced\nUniform orientation: ImageOrientationPatient shared\nContiguous instance numbers: InstanceNumber starts at 1 and increments by 1\nComplete metadata: all required DICOM tags exist and are valid\n\n\nimport dicube\nfrom dicube import get_dicom_status, DicomStatus\nfrom dicube.dicom import CommonTags\n\ndirname = 'dicube-testdata/dicom/sample_200'\nimg = dicube.load_from_dicom_folder(dirname)\nmeta = img.dicom_meta\nstatus = get_dicom_status(meta)\nprint(\"Status:\", status.value)\n\nspacing_consistent = meta.is_shared(CommonTags.PixelSpacing)\nprint(\"Spacing shared:\", spacing_consistent)\nif spacing_consistent:\n    print(\"  spacing:\", meta.get_shared_value(CommonTags.PixelSpacing), \"mm\")\n\nshape_consistent = (meta.is_shared(CommonTags.Rows) and meta.is_shared(CommonTags.Columns))\nprint(\"Shape shared:\", shape_consistent)\nif shape_consistent:\n    rows = meta.get_shared_value(CommonTags.Rows)\n    cols = meta.get_shared_value(CommonTags.Columns)\n    print(f\"  shape: {cols}×{rows}\")\n\norientation_consistent = meta.is_shared(CommonTags.ImageOrientationPatient)\nprint(\"Orientation shared:\", orientation_consistent)",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Series Status"
    ]
  },
  {
    "objectID": "1.3_dicom_status-en.html#nonlocation-issues",
    "href": "1.3_dicom_status-en.html#nonlocation-issues",
    "title": "DICOM Series Status",
    "section": "Non‑Location Issues",
    "text": "Non‑Location Issues\nFour categories: missing, non_uniform, gap, duplicate.\n\n1. Missing: Key Field Absent\n\nimport copy\nfrom dicube.dicom.dicom_tags import get_tag_key\n\ndef demo_missing():\n    print(\"=== Missing Demo ===\")\n    t1 = copy.deepcopy(meta)\n    t1._merged_data.pop(get_tag_key(CommonTags.PixelSpacing), None)\n    print(\"Drop PixelSpacing -&gt;\", get_dicom_status(t1).value)\n\n    t2 = copy.deepcopy(meta)\n    t2._merged_data.pop(get_tag_key(CommonTags.Columns), None)\n    print(\"Drop Columns -&gt;\", get_dicom_status(t2).value)\n\n    t3 = copy.deepcopy(meta)\n    t3._merged_data.pop(get_tag_key(CommonTags.BitsStored), None)\n    print(\"Drop BitsStored -&gt;\", get_dicom_status(t3).value)\n\ndemo_missing()\n\n\n\n2. Non_uniform: Values Inconsistent\n\ndef demo_non_uniform():\n    print(\"=== Non_uniform Demo ===\")\n    t1 = copy.deepcopy(meta)\n    n = t1.slice_count\n    spacing_values = [[0.5,0.5] if i &lt; n//2 else [1.0,1.0] for i in range(n)]\n    t1.set_nonshared_item(CommonTags.PixelSpacing, spacing_values)\n    print(\"Inconsistent PixelSpacing -&gt;\", get_dicom_status(t1).value)\n\n    t2 = copy.deepcopy(meta)\n    cols_values = [512 if i &lt; n//2 else 256 for i in range(n)]\n    t2.set_nonshared_item(CommonTags.Columns, cols_values)\n    print(\"Inconsistent Columns -&gt;\", get_dicom_status(t2).value)\n\ndemo_non_uniform()\n\n\n\n3. Duplicate: Repeated Values\n\ndef demo_duplicate():\n    print(\"=== Duplicate Demo ===\")\n    t = copy.deepcopy(meta)\n    n = t.slice_count\n    t.set_nonshared_item(CommonTags.InstanceNumber, [1]*n)\n    print(\"Duplicate InstanceNumber -&gt;\", get_dicom_status(t).value)\n\n    nums = t.get_values(CommonTags.InstanceNumber)\n    print(\"unique:\", len(set(nums)), \"total:\", len(nums))\n\ndemo_duplicate()\n\n\n\n4. Gap: Jumps\n\ndef demo_gap():\n    print(\"=== Gap Demo ===\")\n    t = copy.deepcopy(meta)\n    n = t.slice_count\n    gap_numbers = list(range(1, n+1))\n    for i in range(3, len(gap_numbers)):\n        gap_numbers[i] += 1\n    t.set_nonshared_item(CommonTags.InstanceNumber, gap_numbers)\n    print(\"Gap InstanceNumber -&gt;\", get_dicom_status(t).value)\n\n    nums = sorted([int(x) for x in t.get_values(CommonTags.InstanceNumber)])\n    diffs = [nums[i+1]-nums[i] for i in range(len(nums)-1)]\n    print(\"diffs:\", diffs[:7], \"...\")\n\ndemo_gap()",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Series Status"
    ]
  },
  {
    "objectID": "1.3_dicom_status-en.html#locationrelated-issues",
    "href": "1.3_dicom_status-en.html#locationrelated-issues",
    "title": "DICOM Series Status",
    "section": "Location‑Related Issues",
    "text": "Location‑Related Issues\n\nMissing location (both ImagePositionPatient and SliceLocation absent)\nDwelling location (repeated positions)\nReversed location (mixed forward/backward)\nGap location (irregular large gaps vs average spacing)",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Series Status"
    ]
  },
  {
    "objectID": "1.3_dicom_status-en.html#compatibility-strategy",
    "href": "1.3_dicom_status-en.html#compatibility-strategy",
    "title": "DICOM Series Status",
    "section": "Compatibility Strategy",
    "text": "Compatibility Strategy\nDiCube keeps working under imperfect data with clear limitations:\n\nPixels: load/process normally, apply rescale if needed\nMetadata: retain all tags for round‑trip integrity\nSpace: set to None and warn if spatial consistency fails\nLimitations: spatial ops (transform, resample, registration) disabled without valid space",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Series Status"
    ]
  },
  {
    "objectID": "1.3_dicom_status-en.html#priority-report-only-the-most-severe-issue",
    "href": "1.3_dicom_status-en.html#priority-report-only-the-most-severe-issue",
    "title": "DICOM Series Status",
    "section": "Priority: Report Only the Most Severe Issue",
    "text": "Priority: Report Only the Most Severe Issue\nChecks follow severity order (Series UID, Instance Number, dtype, spacing/shape/orientation, location, others). Only the first failing category is reported to avoid overload.",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Series Status"
    ]
  },
  {
    "objectID": "1.3_dicom_status-en.html#summary",
    "href": "1.3_dicom_status-en.html#summary",
    "title": "DICOM Series Status",
    "section": "Summary",
    "text": "Summary\n\nCONSISTENT = regular 3D grid\nNon‑location issues: missing / non_uniform / gap / duplicate\nLocation issues: dwelling / reversed / gap\nFail‑soft design: keep working where possible, restrict spatial ops when invalid\nSeverity‑ordered reporting to focus on root cause first",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM Series Status"
    ]
  },
  {
    "objectID": "index-en.html",
    "href": "index-en.html",
    "title": "FastDiag Toolkit",
    "section": "",
    "text": "Medical imaging AI requires reliable data pipelines and consistent spatial semantics. Established Python libraries such as pydicom, SimpleITK, and nibabel remain focused on traditional imaging workstations, and their designs predate today’s requirements for concurrent loading, compute orchestration, and large-scale data management. When building a new generation of imaging platforms, issues such as fragmented datasets, missing metadata, and ambiguous coordinate systems repeatedly slow down development.\nFastDiag Toolkit was created to close these gaps. It provides modern building blocks for AI workflows so that training, inference, and clinical systems can exchange data without losing fidelity or performance."
  },
  {
    "objectID": "index-en.html#motivation",
    "href": "index-en.html#motivation",
    "title": "FastDiag Toolkit",
    "section": "",
    "text": "Medical imaging AI requires reliable data pipelines and consistent spatial semantics. Established Python libraries such as pydicom, SimpleITK, and nibabel remain focused on traditional imaging workstations, and their designs predate today’s requirements for concurrent loading, compute orchestration, and large-scale data management. When building a new generation of imaging platforms, issues such as fragmented datasets, missing metadata, and ambiguous coordinate systems repeatedly slow down development.\nFastDiag Toolkit was created to close these gaps. It provides modern building blocks for AI workflows so that training, inference, and clinical systems can exchange data without losing fidelity or performance."
  },
  {
    "objectID": "index-en.html#core-components",
    "href": "index-en.html#core-components",
    "title": "FastDiag Toolkit",
    "section": "Core Components",
    "text": "Core Components\n\nDiCube: Medical Image Sequence Storage\nDiCube stores an entire DICOM series in a .dcbs single-file container, optimized for high-concurrency I/O and cold-data archiving.\n\nSequential reads minimize random seeks on mechanical drives\nHTJ2K lossless compression typically yields a 3× size reduction and a 5× read speedup\nShared and slice-level metadata are separated and indexed\nFull round-trip conversion to standard DICOM remains available\n\nGitHub Repository\n\n\nMedMask: High-Efficiency Segmentation Masks\nMedMask introduces the .msk format for segmentation masks, addressing the limitations of nii.gz in compression, semantic richness, and loading throughput.\n\nZstandard compression commonly exceeds a 50× reduction\nSingle-pass reading improves performance by roughly 16×\nBuilt-in semantic mapping supports multi-organ groupings\nOverlapping masks and multi-view alignment are first-class concepts\n\nGitHub Repository\n\n\nSpaceTransformer: Spatial Geometry Abstraction\nSpaceTransformer models shape, spacing, origin, and orientation as a unified Space abstraction. It separates transformation planning from execution to guarantee accurate 3D geometric operations.\n\nSpace-level planning enables chained transformations with just-in-time sampling during execution\nImages, masks, and landmarks remain aligned, avoiding align_corners ambiguities\nPyTorch backends offer GPU acceleration and integrate with common deep learning stacks\n\nCore Library\nPyTorch Extension"
  },
  {
    "objectID": "index-en.html#installation",
    "href": "index-en.html#installation",
    "title": "FastDiag Toolkit",
    "section": "Installation",
    "text": "Installation\n# Install the core libraries\npip install dicube\npip install medmask\npip install spacetransformer-core\npip install spacetransformer-torch  # Optional: GPU acceleration"
  },
  {
    "objectID": "index-en.html#getting-started",
    "href": "index-en.html#getting-started",
    "title": "FastDiag Toolkit",
    "section": "Getting Started",
    "text": "Getting Started\nUse the navigation on the left to explore design rationales, implementation details, and worked examples for each component. Reading the sections sequentially provides the quickest path to understanding how FastDiag Toolkit streamlines storage, compression, and spatial transformation in medical imaging workflows.\n\nReach out via the respective GitHub repositories for support or to contribute."
  },
  {
    "objectID": "3.1_space_concept_fundamentals-en.html",
    "href": "3.1_space_concept_fundamentals-en.html",
    "title": "Space Fundamentals",
    "section": "",
    "text": "Space objects describe the sampling grid via shape, origin, spacing, and three orientation vectors.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom spacetransformer.core import Space\n\nstandard_space = Space(\n    shape=(1,10,10),\n    origin=(0.0,0.0,0.0),\n    spacing=(1.0,1.0,1.0),\n    x_orientation=(1.0,0.0,0.0),\n    y_orientation=(0.0,1.0,0.0),\n    z_orientation=(0.0,0.0,1.0)\n)\n\nHelper to visualize Y–Z slices of the sampling grid.\n\ndef visualize_sampling_grid(space, color='blue', show_axes=True, label_suffix=''):\n    shape_yz = space.shape[1:3]\n    y_idx, z_idx = np.meshgrid(np.arange(shape_yz[0]), np.arange(shape_yz[1]), indexing='ij')\n    index_points = np.stack([\n        np.zeros_like(y_idx.flatten()),\n        y_idx.flatten(),\n        z_idx.flatten()\n    ], axis=1)\n    world = space.to_world_transform.apply_point(index_points)\n    plt.scatter(world[:,2], world[:,1], c=color, alpha=0.4, s=20, label=f'Sampling Grid{label_suffix}')\n    if show_axes:\n        origin_world = space.to_world_transform.apply_point([[0,0,0]])[0]\n        plt.plot(origin_world[2], origin_world[1], 'o', color=color, markersize=8, alpha=0.8)\n        axis_len = 1\n        y_end = origin_world[1:3] + np.array(space.y_orientation[1:3]) * axis_len\n        plt.arrow(origin_world[2], origin_world[1], y_end[1]-origin_world[2], y_end[0]-origin_world[1],\n                  head_width=axis_len*0.1, head_length=axis_len*0.1, fc=color, ec=color, alpha=0.7)\n        z_end = origin_world[1:3] + np.array(space.z_orientation[1:3]) * axis_len\n        plt.arrow(origin_world[2], origin_world[1], z_end[1]-origin_world[2], z_end[0]-origin_world[1],\n                  head_width=axis_len*0.1, head_length=axis_len*0.1, fc=color, ec=color, alpha=0.7)\n\ndef setup_plot(figsize=(10,8)):\n    plt.figure(figsize=figsize)\n\ndef finalize_plot(title):\n    plt.xlabel('Z (mm)'); plt.ylabel('Y (mm)'); plt.title(title)\n    plt.grid(True, alpha=0.3); plt.axis('equal'); plt.legend(); plt.tight_layout(); plt.show()\n\nsetup_plot()\nvisualize_sampling_grid(standard_space)\nfinalize_plot('Standard Sampling Grid (10×10, 1 mm)')",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "Space Fundamentals"
    ]
  },
  {
    "objectID": "3.1_space_concept_fundamentals-en.html#space-complete-3d-geometry",
    "href": "3.1_space_concept_fundamentals-en.html#space-complete-3d-geometry",
    "title": "Space Fundamentals",
    "section": "",
    "text": "Space objects describe the sampling grid via shape, origin, spacing, and three orientation vectors.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom spacetransformer.core import Space\n\nstandard_space = Space(\n    shape=(1,10,10),\n    origin=(0.0,0.0,0.0),\n    spacing=(1.0,1.0,1.0),\n    x_orientation=(1.0,0.0,0.0),\n    y_orientation=(0.0,1.0,0.0),\n    z_orientation=(0.0,0.0,1.0)\n)\n\nHelper to visualize Y–Z slices of the sampling grid.\n\ndef visualize_sampling_grid(space, color='blue', show_axes=True, label_suffix=''):\n    shape_yz = space.shape[1:3]\n    y_idx, z_idx = np.meshgrid(np.arange(shape_yz[0]), np.arange(shape_yz[1]), indexing='ij')\n    index_points = np.stack([\n        np.zeros_like(y_idx.flatten()),\n        y_idx.flatten(),\n        z_idx.flatten()\n    ], axis=1)\n    world = space.to_world_transform.apply_point(index_points)\n    plt.scatter(world[:,2], world[:,1], c=color, alpha=0.4, s=20, label=f'Sampling Grid{label_suffix}')\n    if show_axes:\n        origin_world = space.to_world_transform.apply_point([[0,0,0]])[0]\n        plt.plot(origin_world[2], origin_world[1], 'o', color=color, markersize=8, alpha=0.8)\n        axis_len = 1\n        y_end = origin_world[1:3] + np.array(space.y_orientation[1:3]) * axis_len\n        plt.arrow(origin_world[2], origin_world[1], y_end[1]-origin_world[2], y_end[0]-origin_world[1],\n                  head_width=axis_len*0.1, head_length=axis_len*0.1, fc=color, ec=color, alpha=0.7)\n        z_end = origin_world[1:3] + np.array(space.z_orientation[1:3]) * axis_len\n        plt.arrow(origin_world[2], origin_world[1], z_end[1]-origin_world[2], z_end[0]-origin_world[1],\n                  head_width=axis_len*0.1, head_length=axis_len*0.1, fc=color, ec=color, alpha=0.7)\n\ndef setup_plot(figsize=(10,8)):\n    plt.figure(figsize=figsize)\n\ndef finalize_plot(title):\n    plt.xlabel('Z (mm)'); plt.ylabel('Y (mm)'); plt.title(title)\n    plt.grid(True, alpha=0.3); plt.axis('equal'); plt.legend(); plt.tight_layout(); plt.show()\n\nsetup_plot()\nvisualize_sampling_grid(standard_space)\nfinalize_plot('Standard Sampling Grid (10×10, 1 mm)')",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "Space Fundamentals"
    ]
  },
  {
    "objectID": "3.1_space_concept_fundamentals-en.html#transform-examples",
    "href": "3.1_space_concept_fundamentals-en.html#transform-examples",
    "title": "Space Fundamentals",
    "section": "Transform Examples",
    "text": "Transform Examples\n\nShape (Resize)\n\nhigh_res = standard_space.apply_shape((1,20,20))\nlow_res = standard_space.apply_shape((1,5,5))\nsetup_plot(); visualize_sampling_grid(standard_space, 'blue', label_suffix=' (10×10)')\nvisualize_sampling_grid(low_res, 'red', label_suffix=' (5×5)')\nfinalize_plot('Resize')\n\n\n\nFlip\n\nflipped = standard_space.apply_flip(axis=1)\nsetup_plot(); visualize_sampling_grid(standard_space, 'blue', label_suffix=' (orig)')\nvisualize_sampling_grid(flipped, 'red', label_suffix=' (flip Y)')\nfinalize_plot('Flip (Y axis)')\n\n\n\nAxis Swap\n\nrect_space = Space(shape=(1,6,12), origin=(0,0,0), spacing=(1,1,1),\n                   x_orientation=(1,0,0), y_orientation=(0,1,0), z_orientation=(0,0,1))\nswapped = rect_space.apply_swap(1, 2)\nsetup_plot(); visualize_sampling_grid(rect_space, 'blue', label_suffix=' (6×12)')\nvisualize_sampling_grid(swapped, 'red', label_suffix=' (swap Y↔Z)')\nfinalize_plot('Axis Swap')\n\n\n\nRotation\n\nrotated = standard_space.apply_rotate(axis=0, angle=30, unit='degree', center='center')\nsetup_plot(); visualize_sampling_grid(standard_space, 'blue', label_suffix=' (orig)')\nvisualize_sampling_grid(rotated, 'red', label_suffix=' (rotate 30°)')\nfinalize_plot('Rotation (around X)')\n\n\n\nBounding Box Crop\n\ncrop_bbox = np.array([[0,1],[2,8],[2,8]])\ncropped = standard_space.apply_bbox(crop_bbox)\nsetup_plot(); visualize_sampling_grid(standard_space, 'blue', label_suffix=' (orig)')\nvisualize_sampling_grid(cropped, 'red', label_suffix=' (crop 6×6)')\nfinalize_plot('Bounding Box Crop')\n\n\n\nComplex Transform Chain\n\ncomplex_target = (standard_space\n    .apply_bbox(np.array([[0,1],[2,8],[2,8]]))\n    .apply_shape((1,12,12))\n    .apply_rotate(axis=0, angle=45, unit='degree'))\nsetup_plot(); visualize_sampling_grid(standard_space, 'blue', label_suffix=' (orig)')\nvisualize_sampling_grid(complex_target, 'red', label_suffix=' (Crop→Resample→Rotate)')\nfinalize_plot('Complex Chain')\n\n\n\nFloat Bounding Box Sampling\n\nfloat_bbox_space = standard_space.apply_float_bbox(np.array([[0,1],[2.5,5.5],[2.5,5.5]]), (12,12,12))\nsetup_plot(); visualize_sampling_grid(standard_space, 'blue', label_suffix=' (orig)')\nvisualize_sampling_grid(float_bbox_space, 'red', label_suffix=' (float bbox)')\nfinalize_plot('Float Bounding Box')",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "Space Fundamentals"
    ]
  },
  {
    "objectID": "3.1_space_concept_fundamentals-en.html#why-space-centric-design",
    "href": "3.1_space_concept_fundamentals-en.html#why-space-centric-design",
    "title": "Space Fundamentals",
    "section": "Why Space-Centric Design?",
    "text": "Why Space-Centric Design?\nTraditional “transform-centric” APIs (e.g., torchvision) provide relative transforms. SpaceTransformer is “space-centric”: every object (image, mask, points) carries an absolute Space descriptor. Aligning two objects means comparing spaces and deriving the needed transform automatically.\n\nPlanning vs Execution\n\nPlanning: chain methods on Space (apply_shape, apply_bbox, apply_rotate, …) to describe the desired geometry without touching data.\nExecution: warp_image, warp_point, etc., analyze the chain and perform one optimized resample.\n\n\n\nBenefits\n\nGeometric accuracy: transform order (resize→rotate vs rotate→resize) yields the same result; avoids sampling artifacts.\nMemory efficiency: no intermediate arrays; only final output is allocated.\nSimpler architecture: one warp_* family handles images, masks, points without bespoke logic per type.\nEase of use: declarative API, yet advanced users can still access low-level controls.",
    "crumbs": [
      "首页",
      "SpaceTransformer",
      "Space Fundamentals"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html",
    "href": "1.3_dicom_status.html",
    "title": "DICOM序列状态",
    "section": "",
    "text": "DiCube主要为静态三维医学图像服务，其核心假设是整个3D图像在空间中对应着一个规范的采样网格（regular meshgrid）。当DICOM序列处于CONSISTENT状态时，它满足以下条件：\n\n统一的像素间距：所有切片的 PixelSpacing 相同\n一致的图像尺寸：所有切片的 Rows 与 Columns 相同\n\n规律的切片间距：Z 轴方向上切片位置等间距\n统一的图像方向：所有切片的 ImageOrientationPatient 相同\n连续的实例编号：InstanceNumber 从 1 开始连续递增\n完整的元数据：所有必需的 DICOM 标签存在且有效\n\n\nimport dicube\nfrom dicube import get_dicom_status, DicomStatus\nfrom dicube.dicom import CommonTags\n\n# 读取示例数据\ndirname = 'dicube-testdata/dicom/sample_200'\nimg = dicube.load_from_dicom_folder(dirname)\nmeta = img.dicom_meta\nstatus = get_dicom_status(meta)\n\nprint(f\"当前数据状态: {status.value}\")\n\n\n# 1. 像素间距检查\nspacing_consistent = meta.is_shared(CommonTags.PixelSpacing)\nprint(f\"像素间距统一: {spacing_consistent}\")\nif spacing_consistent:\n    spacing = meta.get_shared_value(CommonTags.PixelSpacing)\n    print(f\"  统一间距: {spacing}mm\")\n\n# 2. 图像尺寸检查\nshape_consistent = (meta.is_shared(CommonTags.Rows) and \n                   meta.is_shared(CommonTags.Columns))\nprint(f\"图像尺寸统一: {shape_consistent}\")\nif shape_consistent:\n    rows = meta.get_shared_value(CommonTags.Rows)\n    cols = meta.get_shared_value(CommonTags.Columns)\n    print(f\"  统一尺寸: {cols}×{rows}\")\n\n# 3. 图像方向检查\norientation_consistent = meta.is_shared(CommonTags.ImageOrientationPatient)\nprint(f\"图像方向统一: {orientation_consistent}\")\n\n只有当序列满足所有这些条件时，DiCube才能为其计算准确的空间信息（Space），构建完整的三维采样网格。",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM序列状态"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#什么是-consistent-状态规范的三维采样网格",
    "href": "1.3_dicom_status.html#什么是-consistent-状态规范的三维采样网格",
    "title": "DICOM序列状态",
    "section": "",
    "text": "DiCube主要为静态三维医学图像服务，其核心假设是整个3D图像在空间中对应着一个规范的采样网格（regular meshgrid）。当DICOM序列处于CONSISTENT状态时，它满足以下条件：\n\n统一的像素间距：所有切片的 PixelSpacing 相同\n一致的图像尺寸：所有切片的 Rows 与 Columns 相同\n\n规律的切片间距：Z 轴方向上切片位置等间距\n统一的图像方向：所有切片的 ImageOrientationPatient 相同\n连续的实例编号：InstanceNumber 从 1 开始连续递增\n完整的元数据：所有必需的 DICOM 标签存在且有效\n\n\nimport dicube\nfrom dicube import get_dicom_status, DicomStatus\nfrom dicube.dicom import CommonTags\n\n# 读取示例数据\ndirname = 'dicube-testdata/dicom/sample_200'\nimg = dicube.load_from_dicom_folder(dirname)\nmeta = img.dicom_meta\nstatus = get_dicom_status(meta)\n\nprint(f\"当前数据状态: {status.value}\")\n\n\n# 1. 像素间距检查\nspacing_consistent = meta.is_shared(CommonTags.PixelSpacing)\nprint(f\"像素间距统一: {spacing_consistent}\")\nif spacing_consistent:\n    spacing = meta.get_shared_value(CommonTags.PixelSpacing)\n    print(f\"  统一间距: {spacing}mm\")\n\n# 2. 图像尺寸检查\nshape_consistent = (meta.is_shared(CommonTags.Rows) and \n                   meta.is_shared(CommonTags.Columns))\nprint(f\"图像尺寸统一: {shape_consistent}\")\nif shape_consistent:\n    rows = meta.get_shared_value(CommonTags.Rows)\n    cols = meta.get_shared_value(CommonTags.Columns)\n    print(f\"  统一尺寸: {cols}×{rows}\")\n\n# 3. 图像方向检查\norientation_consistent = meta.is_shared(CommonTags.ImageOrientationPatient)\nprint(f\"图像方向统一: {orientation_consistent}\")\n\n只有当序列满足所有这些条件时，DiCube才能为其计算准确的空间信息（Space），构建完整的三维采样网格。",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM序列状态"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#非-location-相关的状态问题",
    "href": "1.3_dicom_status.html#非-location-相关的状态问题",
    "title": "DICOM序列状态",
    "section": "非 Location 相关的状态问题",
    "text": "非 Location 相关的状态问题\nDiCube使用四种模式来分类非Location相关的字段问题：missing、non_uniform、gap、duplicate。\n\n1. Missing：关键字段缺失\n\n# 演示missing问题的检测\nimport copy\nfrom dicube.dicom.dicom_tags import get_tag_key\n\ndef demo_missing_problems():\n    print(\"=== Missing 问题演示 ===\")\n    \n    # 缺失像素间距\n    test_meta1 = copy.deepcopy(meta)\n    test_meta1._merged_data.pop(get_tag_key(CommonTags.PixelSpacing), None)\n    status1 = get_dicom_status(test_meta1)\n    print(f\"删除PixelSpacing后: {status1.value}\")\n    \n    # 缺失图像尺寸\n    test_meta2 = copy.deepcopy(meta)\n    test_meta2._merged_data.pop(get_tag_key(CommonTags.Columns), None)\n    status2 = get_dicom_status(test_meta2)\n    print(f\"删除Columns后: {status2.value}\")\n    \n    # 缺失数据类型信息\n    test_meta3 = copy.deepcopy(meta)\n    test_meta3._merged_data.pop(get_tag_key(CommonTags.BitsStored), None)\n    status3 = get_dicom_status(test_meta3)\n    print(f\"删除BitsStored后: {status3.value}\")\n\ndemo_missing_problems()\n\n\n\n2. Non_uniform：字段值不一致\n\ndef demo_non_uniform_problems():\n    print(\"\\n=== Non_uniform 问题演示 ===\")\n    \n    # 像素间距不一致\n    test_meta1 = copy.deepcopy(meta)\n    num_slices = test_meta1.slice_count\n    spacing_values = []\n    for i in range(num_slices):\n        if i &lt; num_slices // 2:\n            spacing_values.append([0.5, 0.5])  # 前半段用0.5mm\n        else:\n            spacing_values.append([1.0, 1.0])  # 后半段用1.0mm\n    test_meta1.set_nonshared_item(CommonTags.PixelSpacing, spacing_values)\n    status1 = get_dicom_status(test_meta1)\n    print(f\"设置不一致PixelSpacing后: {status1.value}\")\n    \n    # 图像尺寸不一致\n    test_meta2 = copy.deepcopy(meta)\n    cols_values = []\n    for i in range(num_slices):\n        if i &lt; num_slices // 2:\n            cols_values.append(512)  # 前半段512列\n        else:\n            cols_values.append(256)  # 后半段256列\n    test_meta2.set_nonshared_item(CommonTags.Columns, cols_values)\n    status2 = get_dicom_status(test_meta2)\n    print(f\"设置不一致Columns后: {status2.value}\")\n\ndemo_non_uniform_problems()\n\n\n\n3. Duplicate：重复值\n\ndef demo_duplicate_problems():\n    print(\"\\n=== Duplicate 问题演示 ===\")\n    \n    # 实例编号重复\n    test_meta = copy.deepcopy(meta)\n    num_slices = test_meta.slice_count\n    # 所有切片都使用相同的实例编号\n    duplicate_numbers = [1] * num_slices\n    test_meta.set_nonshared_item(CommonTags.InstanceNumber, duplicate_numbers)\n    status = get_dicom_status(test_meta)\n    print(f\"设置重复InstanceNumber后: {status.value}\")\n    \n    # 展示重复检测逻辑\n    instance_numbers = test_meta.get_values(CommonTags.InstanceNumber)\n    unique_count = len(set(instance_numbers))\n    total_count = len(instance_numbers)\n    print(f\"  实例编号: {instance_numbers[:5]}... (总共{total_count}个)\")\n    print(f\"  唯一值数量: {unique_count}\")\n    print(f\"  检测逻辑: unique_count({unique_count}) &lt; total_count({total_count}) = {unique_count &lt; total_count}\")\n\ndemo_duplicate_problems()\n\n\n\n4. Gap：数值跳跃\n\ndef demo_gap_problems():\n    print(\"\\n=== Gap 问题演示 ===\")\n    \n    # 实例编号跳跃\n    test_meta = copy.deepcopy(meta)\n    num_slices = test_meta.slice_count\n    \n    # 创建有跳跃的实例编号序列：1,2,3,5,6,7,8...\n    gap_numbers = list(range(1, num_slices + 1))\n    for i in range(3, len(gap_numbers)):  # 从第4个开始，所有编号+1\n        gap_numbers[i] += 1\n    \n    test_meta.set_nonshared_item(CommonTags.InstanceNumber, gap_numbers)\n    status = get_dicom_status(test_meta)\n    print(f\"设置跳跃InstanceNumber后: {status.value}\")\n    \n    # 展示跳跃检测逻辑\n    instance_numbers = test_meta.get_values(CommonTags.InstanceNumber)\n    sorted_numbers = sorted([int(x) for x in instance_numbers])\n    print(f\"  排序后的实例编号: {sorted_numbers[:8]}...\")\n    \n    # 检查连续性\n    diffs = [sorted_numbers[i+1] - sorted_numbers[i] for i in range(len(sorted_numbers)-1)]\n    print(f\"  相邻差值: {diffs[:7]}...\")\n    gap_detected = not all(d == 1 for d in diffs)\n    print(f\"  检测逻辑: 存在非1的差值 = {gap_detected}\")\n\ndemo_gap_problems()",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM序列状态"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#location-相关的状态问题",
    "href": "1.3_dicom_status.html#location-相关的状态问题",
    "title": "DICOM序列状态",
    "section": "Location 相关的状态问题",
    "text": "Location 相关的状态问题\nLocation相关的问题主要涉及切片在三维空间中的位置排列，这些问题会破坏规范采样网格的连续性。\n\n1. Missing Location：位置信息缺失\n当DICOM序列中既缺少ImagePositionPatient又缺少SliceLocation字段时，DiCube无法确定切片的空间位置。\n检测逻辑：需要ImagePositionPatient OR SliceLocation，当两者都缺失时 → MISSING_LOCATION\n\n\n2. Dwelling Location：位置停滞\n这是位置序列中出现重复值的情况，表示多个切片具有相同的空间位置。\n数值示例：\n\n正常序列：[1.0, 2.0, 3.0, 4.0, 5.0] (间距为1.0)\n停滞序列：[1.0, 2.0, 2.0, 3.0, 4.0] (第2和第3个位置相同)\n位置差值：[1.0, 0.0, 1.0, 1.0]\n\n检测逻辑：当位置差值中存在零值时 → DWELLING_LOCATION\n\n\n3. Reversed Location：位置方向混乱\nZ轴位置序列中同时存在正向和反向移动，表示扫描方向不一致或序列被打乱。\n数值示例：\n\n正常序列：[1.0, 2.0, 3.0, 4.0, 5.0] (单调递增)\n混乱序列：[1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 6.0] (第5个位置倒退)\n位置差值：[1.0, 1.0, 1.0, -2.0, 3.0, 1.0]\n\n检测逻辑：当位置差值中同时存在正值和负值时 → REVERSED_LOCATION\n\n\n4. Gap Location：位置跳跃\nZ轴位置序列中出现不规律的大间隙，破坏了等间距采样的假设。\n数值示例：\n\n正常序列：[10.0, 15.0, 20.0, 25.0, 30.0] (间距为5.0)\n跳跃序列：[10.0, 15.0, 20.0, 35.0, 40.0] (第4个位置跳跃)\n位置差值：[5.0, 5.0, 15.0, 5.0]\n平均间距：5.0\n相对偏差：[0%, 0%, 200%, 0%]\n\n检测逻辑：当某个间距偏离平均值超过50%时 → GAP_LOCATION",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM序列状态"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#dicube的兼容性处理策略",
    "href": "1.3_dicom_status.html#dicube的兼容性处理策略",
    "title": "DICOM序列状态",
    "section": "DiCube的兼容性处理策略",
    "text": "DiCube的兼容性处理策略\nDiCube尽力在各种异常情况下保持兼容性，采用”尽力而为”的原则来处理有问题的DICOM数据。当检测到数据质量问题时，DiCube仍然能够加载和处理数据，但会相应地限制某些功能。\n\n处理策略细节\n无法计算Space信息的状态：\n\nMISSING_SPACING、NON_UNIFORM_SPACING：像素间距问题\nMISSING_ORIENTATION、NON_UNIFORM_ORIENTATION：图像方向问题\n\nMISSING_LOCATION、REVERSED_LOCATION、DWELLING_LOCATION、GAP_LOCATION：位置信息问题\n\n处理方式：\n\n像素数据：正常加载和处理，应用必要的rescale变换\n元数据：完整保留所有DICOM标签信息，确保往返转换的完整性\n空间信息：当检测到空间相关问题时，将Space设置为None并警告用户\n功能限制：无法进行需要精确空间信息的操作，如空间变换、重采样、配准等\n\n这种设计确保了DiCube在面对现实世界中不完美的DICOM数据时，仍能提供基本的图像处理功能，同时明确告知用户哪些高级功能不可用。",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM序列状态"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#错误优先级只报告最严重的问题",
    "href": "1.3_dicom_status.html#错误优先级只报告最严重的问题",
    "title": "DICOM序列状态",
    "section": "错误优先级：只报告最严重的问题",
    "text": "错误优先级：只报告最严重的问题\nDiCube的状态检查遵循严格的优先级原则：按照严重程度从高到低依次检查，只报告发现的第一个（最严重的）问题。这种设计避免了信息过载，有助于用户专注于解决最关键的问题。\n\n检查优先级顺序\n\nSeries UID问题（最高优先级）\n\nMISSING_SERIES_UID：缺失序列标识符\nNON_UNIFORM_SERIES_UID：序列标识符不统一\n\nInstance Number问题\n\nMISSING_INSTANCE_NUMBER：缺失实例编号\nDUPLICATE_INSTANCE_NUMBERS：实例编号重复\nGAP_INSTANCE_NUMBER：实例编号跳跃\n\n数据类型问题\n\nMISSING_DTYPE：缺失数据类型信息\nNON_UNIFORM_DTYPE：数据类型不一致\n\n空间参数问题\n\nMISSING_SPACING：缺失像素间距\nNON_UNIFORM_SPACING：像素间距不一致\nMISSING_SHAPE：缺失图像尺寸\nNON_UNIFORM_SHAPE：图像尺寸不一致\nMISSING_ORIENTATION：缺失图像方向\nNON_UNIFORM_ORIENTATION：图像方向不一致\n\n位置问题\n\nMISSING_LOCATION：缺失位置信息\nREVERSED_LOCATION：位置方向混乱\nDWELLING_LOCATION：位置停滞\nGAP_LOCATION：位置跳跃\n\n其他问题\n\nNON_UNIFORM_RESCALE_FACTOR：校正参数不一致\n\n理想状态\n\nCONSISTENT：所有检查通过",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM序列状态"
    ]
  },
  {
    "objectID": "1.3_dicom_status.html#总结",
    "href": "1.3_dicom_status.html#总结",
    "title": "DICOM序列状态",
    "section": "总结",
    "text": "总结\nDicomStatus系统通过系统化的状态检查，确保DiCube能够：\n\n识别理想状态：CONSISTENT状态代表规范的三维采样网格\n分类问题类型：用missing、non_uniform、gap、duplicate四种模式描述非Location问题\n检测空间异常：专门处理dwelling、reversed、gap等Location相关问题\n\n智能兼容处理：在数据有问题时仍能部分工作，但合理限制功能\n优先级管理：按严重程度报告问题，指导用户逐步修复\n\n这个系统为DiCube的可靠性和鲁棒性提供了重要保障，确保在各种真实世界的数据质量情况下都能给出合理的处理方案。",
    "crumbs": [
      "首页",
      "DiCube",
      "DICOM序列状态"
    ]
  },
  {
    "objectID": "1.4_sort_method.html",
    "href": "1.4_sort_method.html",
    "title": "切片排序方法",
    "section": "",
    "text": "当我们从医院PACS系统或者存储设备中获取一个DICOM检查序列时，面对的往往是数百个”散装”的2D切片文件。这些文件通常是无序存储的，文件名也可能毫无规律。要将这些2D图像正确地堆叠成完整的3D体积数据，我们遇到的第一个关键技术问题就是：按什么顺序来排列这些切片？\n这个看似简单的问题，背后实际上隐藏着临床工作流程、三维渲染引擎、AI算法处理等多个层面的需求冲突。每种排序方法都有其合理的技术依据和应用场景，但在特定的使用环境下可能会产生意想不到的问题。\n\n\n在实际项目开发中，我们经常会遇到这样的矛盾场景：\n\n临床报告的需求：医生在写诊断报告时，习惯按照 InstanceNumber 来定位病灶（“病灶位于第 X 层切片”）。多数 PACS 系统默认按 InstanceNumber 展示，这已成为临床流程的事实标准。\nAI 算法的标准化需求：为保证输入一致，很多模型要求按照解剖学方向排序（如“从头到脚/从脚到头”），一般基于 SliceLocation 或 ImagePositionPatient。这样有利于学习稳定的解剖分布。多数 CT/MR 为横断位扫描，这两种方向是自然选择。\n非标准扫描的挑战：倾斜扫描（如心脏 MR 四腔心切面）或后处理重建（如冠状位重建）场景中，SliceLocation 可能不存在，ImagePositionPatient 用哪个分量排序也不直观。\n三维渲染的约束：如使用 VTK 等渲染引擎，需考虑其默认右手坐标系；排序不当可能出现“镜像人”。\n\n基于这些复杂的需求冲突，我们推荐使用右手坐标系排序作为默认方案。\n为什么推荐右手系排序？ - 修改成本最小化: 实际上，任何一种排序方式都有其技术合理性，只要我们能够忠实地记录并传递元数据信息，各个模块都可以根据自身需求进行方向转换。但是，不同模块的转换成本存在显著差异。对于算法处理和三维渲染模块而言，它们直接操作的是完整的3D数组结构，如果需要进行图像翻转或重新排列，就必须对大块的连续内存进行读写操作，这种操作的计算开销相当可观。相比之下，PACS查看器的处理方式更为灵活——它本质上将图像序列视为一个2D图像的列表集合，因此只需要调整索引映射关系就能实现不同的显示顺序，而无需移动实际的图像数据。从系统整体的性能优化角度考虑，让计算密集型的算法和渲染模块使用标准化的右手系排序，而让显示模块承担轻量级的索引转换工作，这种设计思路能够最大化地降低系统的整体修改成本。\n右手系排序的技术实现\n右手系排序的算法原理其实很直观：我们读取DICOM文件中的Image Patient Orientation字段，这个字段会告诉我们图像平面的X方向（前三个数字）和Y方向（后三个数字）。通过对这两个方向向量进行叉乘运算，我们可以得到垂直于图像平面的法向量。然后，将每张图像的Image Patient Position投影到这个法向量上，按照投影值从小到大排列，这样得到的切片序列就保证是右手坐标系的。\n现实问题\n理论上来说，只要我们保证坐标系是右手的，那么无论患者在扫描时是怎么躺的，或者扫描序列是怎么”歪着扫”的（比如心脏MR的四腔心切面），导致三个坐标轴并不完全对应标准的LPS方向，渲染时使用者都可以通过三维旋转操作，将图像调整到标准的LPS显示方向。\n但是有极少的医疗设备厂商并不严格遵守DICOM的LPS坐标系准则，在进行世界坐标系标定时，采用的本身就是左手坐标系。这种情况下，即使我们按照推荐的右手系排序方法进行DICOM堆叠，仍然会出现”镜像人”的问题。好在这种情况相对比较少见，但一旦遇到，就只能通过更复杂的图像分析算法来检测和纠正异常，因为从DICOM的元数据信息中是无法判断出这种标定错误的。",
    "crumbs": [
      "首页",
      "DiCube",
      "切片排序方法"
    ]
  },
  {
    "objectID": "1.4_sort_method.html#为什么-dicom-序列需要排序",
    "href": "1.4_sort_method.html#为什么-dicom-序列需要排序",
    "title": "切片排序方法",
    "section": "",
    "text": "当我们从医院PACS系统或者存储设备中获取一个DICOM检查序列时，面对的往往是数百个”散装”的2D切片文件。这些文件通常是无序存储的，文件名也可能毫无规律。要将这些2D图像正确地堆叠成完整的3D体积数据，我们遇到的第一个关键技术问题就是：按什么顺序来排列这些切片？\n这个看似简单的问题，背后实际上隐藏着临床工作流程、三维渲染引擎、AI算法处理等多个层面的需求冲突。每种排序方法都有其合理的技术依据和应用场景，但在特定的使用环境下可能会产生意想不到的问题。\n\n\n在实际项目开发中，我们经常会遇到这样的矛盾场景：\n\n临床报告的需求：医生在写诊断报告时，习惯按照 InstanceNumber 来定位病灶（“病灶位于第 X 层切片”）。多数 PACS 系统默认按 InstanceNumber 展示，这已成为临床流程的事实标准。\nAI 算法的标准化需求：为保证输入一致，很多模型要求按照解剖学方向排序（如“从头到脚/从脚到头”），一般基于 SliceLocation 或 ImagePositionPatient。这样有利于学习稳定的解剖分布。多数 CT/MR 为横断位扫描，这两种方向是自然选择。\n非标准扫描的挑战：倾斜扫描（如心脏 MR 四腔心切面）或后处理重建（如冠状位重建）场景中，SliceLocation 可能不存在，ImagePositionPatient 用哪个分量排序也不直观。\n三维渲染的约束：如使用 VTK 等渲染引擎，需考虑其默认右手坐标系；排序不当可能出现“镜像人”。\n\n基于这些复杂的需求冲突，我们推荐使用右手坐标系排序作为默认方案。\n为什么推荐右手系排序？ - 修改成本最小化: 实际上，任何一种排序方式都有其技术合理性，只要我们能够忠实地记录并传递元数据信息，各个模块都可以根据自身需求进行方向转换。但是，不同模块的转换成本存在显著差异。对于算法处理和三维渲染模块而言，它们直接操作的是完整的3D数组结构，如果需要进行图像翻转或重新排列，就必须对大块的连续内存进行读写操作，这种操作的计算开销相当可观。相比之下，PACS查看器的处理方式更为灵活——它本质上将图像序列视为一个2D图像的列表集合，因此只需要调整索引映射关系就能实现不同的显示顺序，而无需移动实际的图像数据。从系统整体的性能优化角度考虑，让计算密集型的算法和渲染模块使用标准化的右手系排序，而让显示模块承担轻量级的索引转换工作，这种设计思路能够最大化地降低系统的整体修改成本。\n右手系排序的技术实现\n右手系排序的算法原理其实很直观：我们读取DICOM文件中的Image Patient Orientation字段，这个字段会告诉我们图像平面的X方向（前三个数字）和Y方向（后三个数字）。通过对这两个方向向量进行叉乘运算，我们可以得到垂直于图像平面的法向量。然后，将每张图像的Image Patient Position投影到这个法向量上，按照投影值从小到大排列，这样得到的切片序列就保证是右手坐标系的。\n现实问题\n理论上来说，只要我们保证坐标系是右手的，那么无论患者在扫描时是怎么躺的，或者扫描序列是怎么”歪着扫”的（比如心脏MR的四腔心切面），导致三个坐标轴并不完全对应标准的LPS方向，渲染时使用者都可以通过三维旋转操作，将图像调整到标准的LPS显示方向。\n但是有极少的医疗设备厂商并不严格遵守DICOM的LPS坐标系准则，在进行世界坐标系标定时，采用的本身就是左手坐标系。这种情况下，即使我们按照推荐的右手系排序方法进行DICOM堆叠，仍然会出现”镜像人”的问题。好在这种情况相对比较少见，但一旦遇到，就只能通过更复杂的图像分析算法来检测和纠正异常，因为从DICOM的元数据信息中是无法判断出这种标定错误的。",
    "crumbs": [
      "首页",
      "DiCube",
      "切片排序方法"
    ]
  },
  {
    "objectID": "1.4_sort_method.html#排序方法的可视化验证",
    "href": "1.4_sort_method.html#排序方法的可视化验证",
    "title": "切片排序方法",
    "section": "排序方法的可视化验证",
    "text": "排序方法的可视化验证\n让我们通过三视图的方式来直观地观察和验证右手坐标系排序的效果。通过查看横断面、冠状面和矢状面的图像，我们可以清楚地了解图像的空间排列是否正确：\n\nimport dicube\nfrom dicube import SortMethod\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 加载示例DICOM数据\ndirname = 'dicube-testdata/dicom/sample_200'\n\n# 使用右手坐标系排序方法加载图像数据\nimg_rh = dicube.load_from_dicom_folder(dirname, sort_method=SortMethod.POSITION_RIGHT_HAND)\n\nprint(\"=== 右手坐标系排序的图像数据信息 ===\")\nprint(f\"图像数据形状: {img_rh.raw_image.shape}\")\nprint(f\"排序方法: POSITION_RIGHT_HAND\")\n\n# 获取中心切片\ndef get_center_slices(image_data):\n    \"\"\"获取三个方向的中心切片\"\"\"\n    z_center = image_data.shape[0] // 2\n    y_center = image_data.shape[1] // 2  \n    x_center = image_data.shape[2] // 2\n    \n    return {\n        'axial': image_data[z_center, :, :],      # 横断面\n        'coronal': image_data[:, y_center, :],    # 冠状面  \n        'sagittal': image_data[:, :, x_center]    # 矢状面\n    }\n\nslices_rh = get_center_slices(img_rh.get_fdata())\n\n# 创建三个独立的图\n# 1. Axial View (横断面)\nfig1, ax1 = plt.subplots(1, 1, figsize=(8, 6))\nim1 = ax1.imshow(slices_rh['axial'], cmap='gray', origin='lower')\nax1.set_title(f'Axial View - Slice along Z-axis (slice {img_rh.raw_image.shape[0]//2} of {img_rh.raw_image.shape[0]})', fontsize=14)\nax1.set_xlabel('Axis 2 (X): Right → Left', fontsize=12)\nax1.set_ylabel('Axis 1 (Y): Anterior → Posterior', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n# 2. Coronal View (冠状面)\nfig2, ax2 = plt.subplots(1, 1, figsize=(8, 6))\nim2 = ax2.imshow(slices_rh['coronal'], cmap='gray', origin='lower')\nax2.set_title(f'Coronal View - Slice along Y-axis (slice {img_rh.raw_image.shape[1]//2} of {img_rh.raw_image.shape[1]})', fontsize=14)\nax2.set_xlabel('Axis 2 (X): Right → Left', fontsize=12)\nax2.set_ylabel('Axis 0 (Z): Inferior → Superior', fontsize=12)\nplt.tight_layout()\nplt.show()\n\n# 3. Sagittal View (矢状面)\nfig3, ax3 = plt.subplots(1, 1, figsize=(8, 6))\nim3 = ax3.imshow(slices_rh['sagittal'], cmap='gray', origin='lower')\nax3.set_title(f'Sagittal View - Slice along X-axis (slice {img_rh.raw_image.shape[2]//2} of {img_rh.raw_image.shape[2]})', fontsize=14)\nax3.set_xlabel('Axis 1 (Y): Anterior →  Posterior', fontsize=12)\nax3.set_ylabel('Axis 0 (Z): Inferior → Superior', fontsize=12)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "首页",
      "DiCube",
      "切片排序方法"
    ]
  },
  {
    "objectID": "1.4_sort_method.html#排序方法的最佳实践建议",
    "href": "1.4_sort_method.html#排序方法的最佳实践建议",
    "title": "切片排序方法",
    "section": "排序方法的最佳实践建议",
    "text": "排序方法的最佳实践建议\n基于我们在实际项目中的经验积累和技术考量，我们强烈推荐使用右手坐标系排序作为默认的DICOM切片排序方案。这个建议背后有以下几个重要的技术和实用性考虑：\n\n技术兼容性优势\n\n渲染引擎兼容性：VTK、ITK等主流医学影像处理和渲染引擎都默认采用右手坐标系，直接使用右手系排序可以避免额外的坐标系转换\n标准合规性：完全符合DICOM LPS+坐标系标准，确保与国际医学影像标准的兼容性\nAI算法稳定性：在深度学习模型训练和推理过程中，避免因坐标系不一致导致的”镜像人”问题，提高算法的鲁棒性\n计算效率：减少运行时的坐标系转换计算，降低处理开销",
    "crumbs": [
      "首页",
      "DiCube",
      "切片排序方法"
    ]
  },
  {
    "objectID": "1.0_motivation.html",
    "href": "1.0_motivation.html",
    "title": "设计理念与动机",
    "section": "",
    "text": "DICOM（医学数字成像与通信标准）是医学影像领域的通用语言，统一了图像格式，支撑了跨厂商的互操作。然而，这一诞生于 20 世纪 80 年代的标准，其核心设计未预见到由 AI、大数据与高并发计算驱动的现代工作流。\n在构建集成 AI 算法、三维可视化与海量数据管理的新一代影像工作站时，我们发现 DICOM 的若干设计已成为系统性能的结构性瓶颈。本文聚焦这些挑战，并介绍 DiCube——在保持对现有生态 100% 往返兼容的前提下，提供系统性重构的一种方案。",
    "crumbs": [
      "首页",
      "DiCube",
      "设计理念与动机"
    ]
  },
  {
    "objectID": "1.0_motivation.html#引言经典标准面临的现代挑战",
    "href": "1.0_motivation.html#引言经典标准面临的现代挑战",
    "title": "设计理念与动机",
    "section": "",
    "text": "DICOM（医学数字成像与通信标准）是医学影像领域的通用语言，统一了图像格式，支撑了跨厂商的互操作。然而，这一诞生于 20 世纪 80 年代的标准，其核心设计未预见到由 AI、大数据与高并发计算驱动的现代工作流。\n在构建集成 AI 算法、三维可视化与海量数据管理的新一代影像工作站时，我们发现 DICOM 的若干设计已成为系统性能的结构性瓶颈。本文聚焦这些挑战，并介绍 DiCube——在保持对现有生态 100% 往返兼容的前提下，提供系统性重构的一种方案。",
    "crumbs": [
      "首页",
      "DiCube",
      "设计理念与动机"
    ]
  },
  {
    "objectID": "1.0_motivation.html#dicom在现代工作流中的四大核心挑战",
    "href": "1.0_motivation.html#dicom在现代工作流中的四大核心挑战",
    "title": "设计理念与动机",
    "section": "DICOM在现代工作流中的四大核心挑战",
    "text": "DICOM在现代工作流中的四大核心挑战\n\n1. 文件碎片化：并发 I/O 的瓶颈\n一个 CT 或 MR 序列通常由数百至数千个独立的 .dcm 文件构成，这是 DICOM 的核心性能制约。在现代工作站中，通信、三维渲染、数据库归档、AI 分析等模块需要并发访问同一序列。大量小文件在并发场景下触发频繁随机 I/O，形成显著瓶颈。尽管 SSD 能缓解，但对每天 TB 级增量的数据中心而言，成本更低的机械硬盘仍是长期存储主力；一旦数据转冷，访问延迟会快速升高。\n\n\n2. 元数据冗余：存储与带宽的无效消耗\n序列内绝大多数元数据（患者信息、检查参数、设备型号等）在切片间不变，但 DICOM 要求在每个 .dcm 文件重复保存。一个含 500 张切片的序列，等于把同一份信息复制 500 次，既占用磁盘，也浪费传输带宽。更糟的是，共享字段一旦在不同文件间不一致，会给后续处理引入数据质量风险。\n\n\n3. 内置约束缺失：数据质量不确定\n在实际应用中，DICOM 数据常见质量问题：序列内文件缺失、关键标签为空或错误、InstanceNumber 不连续或重复、像素间距不一致等。厂商往往需要自建复杂质控模块识别与兜底。由于不同 AI 算法对数据质量容忍度各异，想设计普适规则很难，进而增加集成难度与脆弱性。\n\n\n4. 顺序解析：低效的元数据访问\nDICOM 二进制缺乏全局索引，解析器需自文件头顺序扫描才能定位目标标签。即便只为获取 ImagePositionPatient、InstanceNumber 等少量字段，也要遍历解析所有文件的完整元数据块。主流库（如 PyDICOM）常默认完整加载元数据，这在批处理（如 AI 训练）或快速预览场景下效率低下。",
    "crumbs": [
      "首页",
      "DiCube",
      "设计理念与动机"
    ]
  },
  {
    "objectID": "1.0_motivation.html#dicube-的系统性方案重塑影像数据结构",
    "href": "1.0_motivation.html#dicube-的系统性方案重塑影像数据结构",
    "title": "设计理念与动机",
    "section": "DiCube 的系统性方案：重塑影像数据结构",
    "text": "DiCube 的系统性方案：重塑影像数据结构\nDiCube 不是对 DICOM 的微调，而是面向现代工作流的存储与访问重构。核心设计：\n\n统一文件容器：将序列整合为单一文件，根除碎片化。\n智能元数据：分离共享/非共享元数据，建立高效索引。\n现代编解码：采用 HTJ2K 等技术，优化压缩率与编解码速度。\n100% 往返兼容：与标准 DICOM 生态无缝衔接。\n\n\n从碎片到整体：单文件存储\nDiCube 将整个 DICOM 序列合并为一个 .dcbs（DiCube Binary Sequence）文件，将对文件系统的随机读写转为高效顺序读写，从根本上缓解 I/O 瓶颈。\n\nimport dicube\nimport time\nimport os\n\n# 示例DICOM目录和DiCube文件路径\ndicom_dir = 'dicube-testdata/dicom/sample_200'\ndcbs_file = 'dicube-testdata/test_sequence.dcbs'\n\n# 转换DICOM序列为DiCube格式\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, dcbs_file)\n\n\n\n从冗余到索引：智能元数据管理\nDiCube 将元数据分为两类：\n\n共享元数据：如患者 ID、研究日期等，仅存一份；\n非共享元数据：如 ImagePositionPatient 等逐切片变化的字段，以紧凑数组存储并建立索引。\n\n该设计显著压缩元数据体积，并支持特定字段的毫秒级随机访问。\n\nfrom dicube.dicom import CommonTags\n\n# 仅加载元数据，速度极快\nmeta = dicube.load_meta(dcbs_file)\n\n# O(1) 复杂度访问共享字段\npatient_name = meta.get_shared_value(CommonTags.PatientName)\nprint(f\"患者姓名: {patient_name}\")\n\n# 高效批量获取非共享字段\ninstance_numbers = meta.get_values(CommonTags.InstanceNumber)\nprint(f\"一次性获取{len(instance_numbers)}个InstanceNumber, 前5个: {instance_numbers[:5]}\")",
    "crumbs": [
      "首页",
      "DiCube",
      "设计理念与动机"
    ]
  },
  {
    "objectID": "1.0_motivation.html#高并发性能压测贴近真实负载",
    "href": "1.0_motivation.html#高并发性能压测贴近真实负载",
    "title": "设计理念与动机",
    "section": "高并发性能压测：贴近真实负载",
    "text": "高并发性能压测：贴近真实负载\n为精确衡量DiCube在真实并发环境下的性能优势，我们设计了以下测试方案：\n\n并发规模：10个进程并发执行。\n工作负载：每个进程随机处理5个不同的影像序列。\n测试数据：从一个包含1000个真实CT序列的大数据集中随机抽取50个序列，避免文件系统缓存干扰。\n测试场景：\n\n仅元数据读取：模拟PACS浏览器构建序列列表的场景。\n元数据+像素读取：模拟三维重建或AI算法进行完整数据加载的场景。\n\n\n测试环境配置（请按需修改路径）\n\nimport multiprocessing as mp\nimport random\nimport time\nimport os\nimport pydicom\nimport dicube\nimport numpy as np\n\n# --- 配置您的数据路径 ---\ndicom_base_dir = '/data/manifest-NLST_allCT/sample_1000'\ndicube_base_dir = '/data/manifest-NLST_allCT/sample_1000_dcbs'\n# -------------------------\n\n# --- 准备测试数据 ---\nnum_processes = 10\nseries_per_process = 5\ntotal_series_needed = num_processes * series_per_process\n\nall_dicom_dirs = [d for d in os.listdir(dicom_base_dir) if os.path.isdir(os.path.join(dicom_base_dir, d))]\nrandom.seed(time.time())\nselected_series_names = random.sample(all_dicom_dirs, total_series_needed)\nprint('selected_series_names',selected_series_names)\nselected_dicom_paths = [os.path.join(dicom_base_dir, name) for name in selected_series_names]\nselected_dicube_paths = [os.path.join(dicube_base_dir, name + '.dcbs') for name in selected_series_names]\n\n\n1. 存储空间占用对比\n在性能测试前，我们首先计算这50个被选中序列分别以DICOM和DiCube格式存储时所占用的磁盘空间。\n\ndef get_dir_size(path):\n    total = 0\n    with os.scandir(path) as it:\n        for entry in it:\n            if entry.is_file():\n                total += entry.stat().st_size\n    return total\n\ndicom_total_size = sum(get_dir_size(p) for p in selected_dicom_paths)\ndicube_total_size = sum(os.path.getsize(p) for p in selected_dicube_paths)\n\nprint(\"--- 50个随机序列存储空间对比 ---\")\nprint(f\"DICOM 格式总大小: {dicom_total_size / (1024**2):.2f} MB\")\nprint(f\"DiCube 格式总大小: {dicube_total_size / (1024**2):.2f} MB\")\nprint(f\"空间节省率: {(1 - dicube_total_size / dicom_total_size) * 100:.1f}%\")\n\n\n\n2. 并发性能测试执行\n我们定义了针对四种不同场景的读取函数，并使用多进程池来模拟并发访问。\n\n# --- 读取函数定义 (Low-level, for a single item) ---\ndef read_dicom_series_meta_only(series_path):\n    files = [os.path.join(series_path, f) for f in os.listdir(series_path) if f.endswith('.dcm')]\n    for filepath in files:\n        pydicom.dcmread(filepath, stop_before_pixels=True)\n\ndef read_dicom_series_full(series_path):\n    dcm_series = [pydicom.dcmread(os.path.join(series_path, f)) for f in os.listdir(series_path) if f.endswith('.dcm')]\n    # 模拟访问像素数据\n    pixels = [ds.pixel_array for ds in dcm_series]\n    return (len(pixels), pixels[0].shape)\n\ndef read_dicube_meta_only(dcbs_path):\n    dicube.load_meta(dcbs_path)\n\ndef read_dicube_full(dcbs_path):\n    dcb_image = dicube.load(dcbs_path)\n    # 模拟访问像素数据\n    pixels = dcb_image.raw_image\n    return pixels.shape\n\n# --- NEW: Top-level worker functions that are picklable ---\n# These functions take a list of paths and process them.\ndef dicom_meta_worker(paths):\n    for path in paths:\n        read_dicom_series_meta_only(path)\n\ndef dicube_meta_worker(paths):\n    for path in paths:\n        read_dicube_meta_only(path)\n\ndef dicom_full_worker(paths):\n    for path in paths:\n        read_dicom_series_full(path)\n\ndef dicube_full_worker(paths):\n    for path in paths:\n        read_dicube_full(path)\n        \n# --- 测试执行框架 (Unchanged) ---\ndef run_performance_test(paths, worker_function, num_processes, series_per_process):\n    tasks = [paths[i*series_per_process:(i+1)*series_per_process] for i in range(num_processes)]\n    pool = mp.Pool(processes=num_processes)\n    \n    start_time = time.time()\n    # Use the worker function directly on the list of task lists\n    pool.map(worker_function, tasks)\n    end_time = time.time()\n    \n    pool.close()\n    pool.join()\n    return end_time - start_time\n        \n# --- 执行所有测试 (UPDATED to use new worker functions) ---\nprint(\"\\n--- 正在执行并发性能测试 ---\")\n# 元数据测试\ndicom_meta_time = run_performance_test(selected_dicom_paths, dicom_meta_worker, num_processes, series_per_process)\ndicube_meta_time = run_performance_test(selected_dicube_paths, dicube_meta_worker, num_processes, series_per_process)\n\n# 完整数据测试\ndicom_full_time = run_performance_test(selected_dicom_paths, dicom_full_worker, num_processes, series_per_process)\ndicube_full_time = run_performance_test(selected_dicube_paths, dicube_full_worker, num_processes, series_per_process)\n\n\n\n3. 测试结果与分析\n\nprint(\"\\n--- 并发性能测试结果 (10进程 x 5序列) ---\")\n\n# 元数据结果\nprint(\"\\n场景1: 仅读取元数据\")\nprint(f\"DICOM  总耗时: {dicom_meta_time:.2f} 秒\")\nprint(f\"DiCube 总耗时: {dicube_meta_time:.2f} 秒\")\nprint(f\"性能提升: {dicom_meta_time / dicube_meta_time:.1f} 倍\")\n\n# 完整数据结果\nprint(\"\\n场景2: 读取元数据 + 像素数据\")\nprint(f\"DICOM  总耗时: {dicom_full_time:.2f} 秒\")\nprint(f\"DiCube 总耗时: {dicube_full_time:.2f} 秒\")\nprint(f\"性能提升: {dicom_full_time / dicube_full_time:.1f} 倍\")\n\n测试结果清晰地表明，DiCube在两种并发场景下均展现出压倒性的性能优势。尤其是在仅读取元数据的场景中，由于避免了对大量小文件的随机访问和重复解析，性能提升最为显著。在完整数据读取场景中，单文件容器带来的高效I/O同样使DiCube大幅领先。\n值得注意的是，DiCube中的像素数据采用了高效压缩算法，即使考虑解压缩开销，其性能依然远超未压缩的DICOM文件。这种性能优势具有良好的可扩展性——随着并发度的提升，DiCube的领先幅度会进一步扩大。此外，本次测试环境为配备SSD缓存的混合硬盘，已经具备相当不错的读取性能。在纯机械硬盘或云对象存储等I/O受限的环境中，DiCube的性能优势将更加明显，差距可能会呈数量级增长。",
    "crumbs": [
      "首页",
      "DiCube",
      "设计理念与动机"
    ]
  },
  {
    "objectID": "1.0_motivation.html#无缝集成100-dicom-往返兼容",
    "href": "1.0_motivation.html#无缝集成100-dicom-往返兼容",
    "title": "设计理念与动机",
    "section": "无缝集成：100% DICOM 往返兼容",
    "text": "无缝集成：100% DICOM 往返兼容\nDiCube 的关键原则之一是与现有 DICOM 生态完全兼容，通过 100% 无损的往返转换保证：\n\n无损转换：从 DICOM 到 DiCube，再回到 DICOM，像素与元数据无信息损失；\n元数据完整：保留所有标准及私有 DICOM 标签；\n工作流兼容：可随时将 .dcbs 导出为标准 DICOM 文件集，用于 PACS 归档或与存量系统交互。\n\n以下代码验证了多个关键字段在转换前后的一致性。\n\nimport shutil\n\n# 使用之前加载的 dcb_image 对象\nroundtrip_dicom_dir = 'dicube-testdata/roundtrip_dicom'\ndicube.save_to_dicom_folder(dcb_image, roundtrip_dicom_dir)\n\n# 读取原始DICOM文件和转换后的DICOM文件进行对比\noriginal_dcm_path = os.path.join(dicom_dir, os.listdir(dicom_dir)[0])\noriginal_dcm = pydicom.dcmread(original_dcm_path)\n\nroundtrip_dcm_path = os.path.join(roundtrip_dicom_dir, 'slice_0000.dcm')\nroundtrip_dcm = pydicom.dcmread(roundtrip_dcm_path)\n\nprint(\"\\n--- 往返转换验证 ---\")\nfields_to_check = [\n    'PatientName', 'StudyInstanceUID', 'SeriesDescription', \n    'ImageOrientationPatient', 'PixelSpacing'\n]\n\nfor tag in fields_to_check:\n    original_value = original_dcm.get(tag, 'N/A')\n    roundtrip_value = roundtrip_dcm.get(tag, 'N/A')\n    print(f\"字段: {tag}\")\n    print(f\"  - 原始值: {original_value}\")\n    print(f\"  - 转换后: {roundtrip_value}\")\n    # 使用 numpy.allclose 进行浮点数组比较\n    if isinstance(original_value, (pydicom.multival.MultiValue, list)):\n        are_equal = np.allclose(np.array(original_value, dtype=float), np.array(roundtrip_value, dtype=float))\n    else:\n        are_equal = (original_value == roundtrip_value)\n    print(f\"  - 是否一致: {are_equal}\")\n    print(\"-\" * 20)\n\nprint(f\"元数据字段总数对比: {len(original_dcm)} (原始) vs {len(roundtrip_dcm)} (转换后)\")\n\n# 清理测试文件\nos.remove(dcbs_file)\nshutil.rmtree(roundtrip_dicom_dir)",
    "crumbs": [
      "首页",
      "DiCube",
      "设计理念与动机"
    ]
  },
  {
    "objectID": "1.0_motivation.html#总结从性能瓶颈到技术赋能",
    "href": "1.0_motivation.html#总结从性能瓶颈到技术赋能",
    "title": "设计理念与动机",
    "section": "总结：从性能瓶颈到技术赋能",
    "text": "总结：从性能瓶颈到技术赋能\nDiCube通过系统性的结构优化，为解决DICOM在现代工作流中的核心挑战提供了有效方案。\n\n\n\n\n\n\n\n\n\n问题领域\nDICOM的局限性\nDiCube的解决方案\n性能提升\n\n\n\n\n文件管理\n大量碎片文件，并发 I/O 瓶颈\n单文件容器\n并发访问提升 3–10 倍\n\n\n元数据处理\n冗余存储，顺序解析\n去重与索引化查询\n元数据访问提升 10–50 倍\n\n\n存储效率\n缺乏高效标准压缩\n集成 HTJ2K 编解码\n空间节省 50–70%\n\n\n工作流集成\n解析转换逻辑复杂\n现代化 API 与数据结构\n集成效率显著提升\n\n\n\nDiCube的核心价值：\n\n即时性能收益：无需改动上层业务，即可获得显著 I/O 与处理性能提升；\n赋能未来应用：为 AI 训练、实时分析、大规模并发等场景打好数据底座；\n零风险迁移：完整往返兼容，便于与现有 DICOM 生态无缝集成与回退。\n\n通过在工作流中引入DiCube作为高性能的中间格式，开发团队可以更专注于业务逻辑创新，而不是耗费精力去规避底层数据格式的性能陷阱。这不仅能提升当前系统的用户体验，更能为未来的技术演进提供强大的支持。",
    "crumbs": [
      "首页",
      "DiCube",
      "设计理念与动机"
    ]
  },
  {
    "objectID": "spacetransformer_tutorial_outline.html",
    "href": "spacetransformer_tutorial_outline.html",
    "title": "SpaceTransformer教程系列提纲",
    "section": "",
    "text": "标题: “医学图像几何变换的三大痛点与SpaceTransformer的解决方案”\n内容重点: - 传统方法的问题分析： - Frame概念缺失shape信息 - NIfTI Affine矩阵难以理解和调试 - 多步变换的手动簿记复杂性 - SpaceTransformer的核心理念：Space概念 - 性能对比和优势展示 - 与现有工具生态的兼容性\n\n\n\n标题: “Space概念详解：完整的3D医学图像几何描述”\n内容重点: - Space对象的六大组成要素详解 - 与传统Frame、Affine矩阵的对比 - 从DICOM、NIfTI、SimpleITK创建Space对象 - 坐标系统转换（索引坐标 ↔︎ 世界坐标） - 实用示例：Space对象的创建和基本操作\n\n\n\n标题: “优雅的空间变换：声明式几何操作”\n内容重点: - 核心变换操作：flip、rotate、bbox、shape - 变换链式调用的语法和语义 - 抽象-执行模式的设计理念 - 可逆变换的数学保证 - 实际案例：复杂变换流水线的构建\n\n\n\n标题: “图像与点云的统一变换：从算法到临床”\n内容重点: - warp_image函数详解：插值模式、填充策略 - warp_point函数：点集坐标变换 - GPU加速和性能优化 - 实际医学应用场景： - ROI提取与处理 - 分割结果回传 - 关键点检测坐标转换\n\n\n\n标题: “深度学习工作流集成：无痛的几何变换”\n内容重点: - 与PyTorch的无缝集成 - 解决align_corners混淆问题 - 批处理和GPU内存优化 - 完整的AI推理流水线示例： - 预处理变换 - 模型推理 - 后处理和结果回传 - 与常见深度学习框架的配合使用\n\n\n\n标题: “临床案例研究：多器官分割的完整工作流”\n内容重点: - 真实临床场景：全腹部CT多器官分割 - 完整的端到端处理流程 - 性能基准测试和对比 - 错误处理和边界情况 - 与PACS系统的集成验证 - 临床医生反馈和实用建议\n\n\n\n\n循序渐进: 从概念理解到实际应用，层层递进\n实用导向: 每个章节都包含可运行的代码示例\n对比分析: 与传统方法的详细对比，突出优势\n临床相关: 结合真实医学图像处理需求\n性能展示: 包含基准测试和性能分析"
  },
  {
    "objectID": "spacetransformer_tutorial_outline.html#spacetransformer_motivation.qmd",
    "href": "spacetransformer_tutorial_outline.html#spacetransformer_motivation.qmd",
    "title": "SpaceTransformer教程系列提纲",
    "section": "",
    "text": "标题: “医学图像几何变换的三大痛点与SpaceTransformer的解决方案”\n内容重点: - 传统方法的问题分析： - Frame概念缺失shape信息 - NIfTI Affine矩阵难以理解和调试 - 多步变换的手动簿记复杂性 - SpaceTransformer的核心理念：Space概念 - 性能对比和优势展示 - 与现有工具生态的兼容性"
  },
  {
    "objectID": "spacetransformer_tutorial_outline.html#space_concept_fundamentals.qmd",
    "href": "spacetransformer_tutorial_outline.html#space_concept_fundamentals.qmd",
    "title": "SpaceTransformer教程系列提纲",
    "section": "",
    "text": "标题: “Space概念详解：完整的3D医学图像几何描述”\n内容重点: - Space对象的六大组成要素详解 - 与传统Frame、Affine矩阵的对比 - 从DICOM、NIfTI、SimpleITK创建Space对象 - 坐标系统转换（索引坐标 ↔︎ 世界坐标） - 实用示例：Space对象的创建和基本操作"
  },
  {
    "objectID": "spacetransformer_tutorial_outline.html#spatial_transformations.qmd",
    "href": "spacetransformer_tutorial_outline.html#spatial_transformations.qmd",
    "title": "SpaceTransformer教程系列提纲",
    "section": "",
    "text": "标题: “优雅的空间变换：声明式几何操作”\n内容重点: - 核心变换操作：flip、rotate、bbox、shape - 变换链式调用的语法和语义 - 抽象-执行模式的设计理念 - 可逆变换的数学保证 - 实际案例：复杂变换流水线的构建"
  },
  {
    "objectID": "spacetransformer_tutorial_outline.html#image_point_warping.qmd",
    "href": "spacetransformer_tutorial_outline.html#image_point_warping.qmd",
    "title": "SpaceTransformer教程系列提纲",
    "section": "",
    "text": "标题: “图像与点云的统一变换：从算法到临床”\n内容重点: - warp_image函数详解：插值模式、填充策略 - warp_point函数：点集坐标变换 - GPU加速和性能优化 - 实际医学应用场景： - ROI提取与处理 - 分割结果回传 - 关键点检测坐标转换"
  },
  {
    "objectID": "spacetransformer_tutorial_outline.html#deep_learning_integration.qmd",
    "href": "spacetransformer_tutorial_outline.html#deep_learning_integration.qmd",
    "title": "SpaceTransformer教程系列提纲",
    "section": "",
    "text": "标题: “深度学习工作流集成：无痛的几何变换”\n内容重点: - 与PyTorch的无缝集成 - 解决align_corners混淆问题 - 批处理和GPU内存优化 - 完整的AI推理流水线示例： - 预处理变换 - 模型推理 - 后处理和结果回传 - 与常见深度学习框架的配合使用"
  },
  {
    "objectID": "spacetransformer_tutorial_outline.html#clinical_case_study.qmd",
    "href": "spacetransformer_tutorial_outline.html#clinical_case_study.qmd",
    "title": "SpaceTransformer教程系列提纲",
    "section": "",
    "text": "标题: “临床案例研究：多器官分割的完整工作流”\n内容重点: - 真实临床场景：全腹部CT多器官分割 - 完整的端到端处理流程 - 性能基准测试和对比 - 错误处理和边界情况 - 与PACS系统的集成验证 - 临床医生反馈和实用建议"
  },
  {
    "objectID": "spacetransformer_tutorial_outline.html#教程特色",
    "href": "spacetransformer_tutorial_outline.html#教程特色",
    "title": "SpaceTransformer教程系列提纲",
    "section": "",
    "text": "循序渐进: 从概念理解到实际应用，层层递进\n实用导向: 每个章节都包含可运行的代码示例\n对比分析: 与传统方法的详细对比，突出优势\n临床相关: 结合真实医学图像处理需求\n性能展示: 包含基准测试和性能分析"
  },
  {
    "objectID": "STYLE_CN.html",
    "href": "STYLE_CN.html",
    "title": "FastDiag Toolkit 文档",
    "section": "",
    "text": "中文写作与代码风格约定（DiCube 文档）\n目标：保证文档语言一致、专业克制、术语统一、代码可复制运行。\n\n语气与用词\n\n面向工程与临床的专业叙述；避免感叹与夸张；给出可验证的依据或代码。\n术语统一：DICOM、DiCube、NIfTI、HTJ2K、LPS+/RAS+、PACS、InstanceNumber、ImagePositionPatient。\n中英混排：专有名词和 API 使用英文原样；与中文之间保留一个空格，如 “使用 SimpleITK 读取 DICOM”。\n标点：中文句内使用中文标点；代码与路径使用英文半角。\n\n结构与标题\n\n章节标题使用“n. …”“n.m. …”编号，不转义点号；示例：## 1. 背景、### 1.1. 场景。\n小节开头给出一句话结论或定义；段落尽量短（2–4 句）。\n\n列表与表格\n\n列表用 “-”；同层级语法一致，句末不加句号，除非为完整句。\n表格仅在对比时使用，列名简短一致。\n\n代码与数据\n\n统一使用 Quarto 代码块标记：```{python}。\n示例首行简短注释说明目的；必要时给出可替换的数据路径变量。\n打印输出使用明确单位与上下文；避免无用 print。\n变量命名语义化，遵循 snake_case；常量大写。\n\n图与术语\n\n坐标/方向统一使用 LPS+ 术语；提到轴序时显式标注 (Z, Y, X) 或 (X, Y, Z)。\n排序方法与状态名使用等宽反引号包裹：POSITION_RIGHT_HAND、CONSISTENT。\n\n可读性\n\n首次出现的关键概念给 1 句定义；后续直接使用术语。\n示例数据与路径均在代码中集中配置，便于替换与复现。"
  },
  {
    "objectID": "1.2_meta_storage.html",
    "href": "1.2_meta_storage.html",
    "title": "元数据存储机制",
    "section": "",
    "text": "DICOM 作为医学影像的基石，其设计源于上世纪末，采用了“一文件一图像（切片）”的存储模式。这种模式在当时是合理的，但随着影像设备采集的图像层数急剧增加（从几十层到数千层），其固有的元数据冗余问题成为了一个巨大的性能瓶颈和存储负担。\n在一个包含数百个 .dcm 文件的 CT 序列中，绝大部分描述患者身份、检查信息、设备参数的元数据在每个文件中都被完整地复制了一遍。只有像切片位置、实例编号这类与特定切片相关的少数信息是变化的。\n\nimport pydicom\nimport os\nfrom pathlib import Path\n\n# 探查DICOM序列中的元数据冗余\ndicom_dir = \"dicube-testdata/dicom/sample_200\"\n# 我们仅选取前两个文件进行对比\ndicom_files = list(Path(dicom_dir).glob(\"*\"))[:2]\n\n# 读取元数据（stop_before_pixels=True 避免加载像素数据，加快速度）\nds1 = pydicom.dcmread(dicom_files[0], stop_before_pixels=True)\nds2 = pydicom.dcmread(dicom_files[1], stop_before_pixels=True)\n\n# 校验序列级元数据和实例级元数据的异同\npatient_same = ds1.PatientName == ds2.PatientName\nseries_same = ds1.SeriesInstanceUID == ds2.SeriesInstanceUID\ninstance_same = ds1.InstanceNumber == ds2.InstanceNumber\n\nprint(f\"两个切片的 PatientName 相同: {patient_same}\")\nprint(f\"两个切片的 SeriesInstanceUID 相同: {series_same}\")\nprint(f\"两个切片的 InstanceNumber 相同: {instance_same}\")\n\n正如代码所示，绝大多数元数据是序列共享的，而 InstanceNumber 等则是切片独有的。这种设计不仅浪费了大量存储空间，更严重的是，当需要获取整个序列的某个信息时（例如窗宽窗位），程序必须遍历并解析数百个文件，导致了极低的 I/O 效率。",
    "crumbs": [
      "首页",
      "DiCube",
      "元数据存储机制"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#传统-dicom-的历史包袱元数据冗余",
    "href": "1.2_meta_storage.html#传统-dicom-的历史包袱元数据冗余",
    "title": "元数据存储机制",
    "section": "",
    "text": "DICOM 作为医学影像的基石，其设计源于上世纪末，采用了“一文件一图像（切片）”的存储模式。这种模式在当时是合理的，但随着影像设备采集的图像层数急剧增加（从几十层到数千层），其固有的元数据冗余问题成为了一个巨大的性能瓶颈和存储负担。\n在一个包含数百个 .dcm 文件的 CT 序列中，绝大部分描述患者身份、检查信息、设备参数的元数据在每个文件中都被完整地复制了一遍。只有像切片位置、实例编号这类与特定切片相关的少数信息是变化的。\n\nimport pydicom\nimport os\nfrom pathlib import Path\n\n# 探查DICOM序列中的元数据冗余\ndicom_dir = \"dicube-testdata/dicom/sample_200\"\n# 我们仅选取前两个文件进行对比\ndicom_files = list(Path(dicom_dir).glob(\"*\"))[:2]\n\n# 读取元数据（stop_before_pixels=True 避免加载像素数据，加快速度）\nds1 = pydicom.dcmread(dicom_files[0], stop_before_pixels=True)\nds2 = pydicom.dcmread(dicom_files[1], stop_before_pixels=True)\n\n# 校验序列级元数据和实例级元数据的异同\npatient_same = ds1.PatientName == ds2.PatientName\nseries_same = ds1.SeriesInstanceUID == ds2.SeriesInstanceUID\ninstance_same = ds1.InstanceNumber == ds2.InstanceNumber\n\nprint(f\"两个切片的 PatientName 相同: {patient_same}\")\nprint(f\"两个切片的 SeriesInstanceUID 相同: {series_same}\")\nprint(f\"两个切片的 InstanceNumber 相同: {instance_same}\")\n\n正如代码所示，绝大多数元数据是序列共享的，而 InstanceNumber 等则是切片独有的。这种设计不仅浪费了大量存储空间，更严重的是，当需要获取整个序列的某个信息时（例如窗宽窗位），程序必须遍历并解析数百个文件，导致了极低的 I/O 效率。",
    "crumbs": [
      "首页",
      "DiCube",
      "元数据存储机制"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#拥抱标准基于-dicom-json-构建",
    "href": "1.2_meta_storage.html#拥抱标准基于-dicom-json-构建",
    "title": "元数据存储机制",
    "section": "2. 拥抱标准：基于 DICOM JSON 构建",
    "text": "2. 拥抱标准：基于 DICOM JSON 构建\n为了让 DICOM 更好地融入现代 Web 和数据科学生态，DICOM 标准委员会在 PS3.18 部分引入了 DICOM JSON 模型。它为 DICOM 元数据提供了标准化、人类可读的 JSON 表示，简化了非医疗软件对 DICOM 信息的解析与利用。\nDiCube 没有重新发明轮子，而是完全遵从这一现代化标准来组织其内部的元数据。\n\nimport json\n\n# PyDICOM原生支持将元数据导出为DICOM JSON\nds = pydicom.dcmread(dicom_files[0], stop_before_pixels=True)\ndicom_json_str = ds.to_json()\n\n# 解析并展示部分关键字段\njson_data = json.loads(dicom_json_str)\n# 字段的键是其十六进制的Tag编码\nkey_tags = [\"00100010\", \"00080021\", \"00200013\"]  # PatientName, SeriesDate, InstanceNumber\n\nfor tag in key_tags:\n    if tag in json_data:\n        # VR (Value Representation) 字段描述了值的类型\n        vr = json_data[tag][\"vr\"]\n        value = json_data[tag].get(\"Value\", [\"N/A\"])[0]\n        print(f\"Tag {tag} (VR: {vr}): {value}\")\n\n通过采用DICOM JSON标准，DiCube确保了其元数据的互操作性和未来兼容性。",
    "crumbs": [
      "首页",
      "DiCube",
      "元数据存储机制"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#dicommeta的核心设计共享与非共享元数据的分离",
    "href": "1.2_meta_storage.html#dicommeta的核心设计共享与非共享元数据的分离",
    "title": "元数据存储机制",
    "section": "3. DicomMeta的核心设计：共享与非共享元数据的分离",
    "text": "3. DicomMeta的核心设计：共享与非共享元数据的分离\nDicomMeta 是 DiCube 中负责高效管理元数据的核心类。它通过共享/非共享元数据分离机制直击传统 DICOM 的冗余痛点。\n\n共享 (Shared) 元数据: 在整个图像序列中保持不变的信息，如 PatientID、StudyInstanceUID、Modality 等。这部分数据只存储一次。\n非共享 (Per-Slice) 元数据: 每个切片独有的信息，如 InstanceNumber、ImagePositionPatient、SliceLocation 等。这部分数据会为每个切片单独存储。\n\n当从DICOM文件夹加载数据时，DiCube会自动分析并分离这两类元数据。\n\nimport dicube\n\n# 从DICOM文件夹加载数据，DiCube在内部自动完成元数据分离\ndcb_image = dicube.load_from_dicom_folder(dicom_dir)\ndicube.save(dcb_image, \"temp_demo.dcbs\")\n\n# 获取DicomMeta对象有两种方式：\n# 方式1：直接从DiCube文件加载元数据\nmeta = dicube.load_meta(\"temp_demo.dcbs\")\n# 方式2：从已加载的DiCubeImage对象中获取\nmeta = dcb_image.dicom_meta\n\n# display() 方法可以清晰地展示元数据的分层结构\nmeta.display()\n\n这种智能分离机制带来了立竿见影的好处：元数据存储占用急剧减少，并且访问序列级信息（如患者姓名）时无需遍历，实现了O(1)时间复杂度的查找。\n\nfrom dicube.dicom import CommonTags\n\n# 检查共享元数据\npatient_name = meta.get_shared_value(CommonTags.PatientName)\nis_shared = meta.is_shared(CommonTags.PatientName)\nprint(f\"PatientName: '{patient_name}' (是否为共享数据: {is_shared})\")\n\n# 检查非共享元数据\n# get_values 会返回一个包含所有切片该字段值的列表\ninstance_numbers = meta.get_values(CommonTags.InstanceNumber)\nis_shared_instance = meta.is_shared(CommonTags.InstanceNumber)\nprint(f\"InstanceNumber (是否为共享数据: {is_shared_instance})\")\nprint(f\"共找到 {len(instance_numbers)} 个InstanceNumber\")\nprint(f\"范围从: {min(instance_numbers)} 到 {max(instance_numbers)}\")",
    "crumbs": [
      "首页",
      "DiCube",
      "元数据存储机制"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#极致压缩json-zstandard",
    "href": "1.2_meta_storage.html#极致压缩json-zstandard",
    "title": "元数据存储机制",
    "section": "4. 极致压缩：JSON + Zstandard",
    "text": "4. 极致压缩：JSON + Zstandard\n分离元数据解决了冗余，但如何高效地存储这些结构化的文本信息呢？DiCube 选择了由Facebook开发的现代化压缩算法 Zstandard (zstd)。\nZstd 擅长压缩具有重复模式的结构化文本数据（如 JSON），在压缩比与解压速度上均显著优于传统 gzip。\n\n# 估算原始DICOM头文件的总大小\ndicom_header_total_size = 0\nall_files = list(Path(dicom_dir).glob(\"*\"))\n\nfor dcm_file in all_files:\n    # 获取文件总大小\n    total_size = os.path.getsize(dcm_file)\n    \n    # 读取DICOM文件获取pixel_array大小\n    ds = pydicom.dcmread(dcm_file)\n    if hasattr(ds, 'pixel_array'):\n        pixel_size = ds.pixel_array.nbytes\n    else:\n        pixel_size = 0\n    \n    # 头文件大小 = 总大小 - pixel_array大小\n    header_size = total_size - pixel_size\n    dicom_header_total_size += header_size\n\n\n\n# 获取DiCube压缩后的元数据大小\nmeta_json_str = meta.to_json()\nimport zstandard as zstd\ncompressor = zstd.ZstdCompressor(level=9) # 使用较高的压缩级别\ncompressed_meta = compressor.compress(meta_json_str.encode('utf-8'))\ndicube_meta_size = len(compressed_meta)\n\nprint(f\"原始DICOM头文件总大小 (估算): {dicom_header_total_size / 1024:.2f} KB\")\nprint(f\"DiCube Zstd压缩后元数据大小: {dicube_meta_size / 1024:.2f} KB\")\nprint(f\"元数据压缩比高达: {dicom_header_total_size / dicube_meta_size:.1f}x\")\n\n超过 80 倍的压缩比！这表明 DicomMeta 的共享机制与 zstd 压缩形成了完美的组合拳，将元数据存储开销降至最低。",
    "crumbs": [
      "首页",
      "DiCube",
      "元数据存储机制"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#提升开发体验commontags-枚举",
    "href": "1.2_meta_storage.html#提升开发体验commontags-枚举",
    "title": "元数据存储机制",
    "section": "5. 提升开发体验：CommonTags 枚举",
    "text": "5. 提升开发体验：CommonTags 枚举\n直接操作 (0010,0010) 这样的十六进制标签不仅难以记忆，而且容易出错。为了提升代码的可读性和健壮性，DiCube 提供了一个便捷的 CommonTags 枚举类，收录了绝大部分常用的DICOM标签。\n开发者可以通过语义化的名称来访问元数据，使代码更加清晰、易于维护。\n\n# 使用CommonTags枚举类，代码更具可读性\ninstance_numbers = meta.get_values(CommonTags.InstanceNumber)\npositions = meta.get_values(CommonTags.ImagePositionPatient)\n\n# positions 是一个包含每个切片 [X, Y, Z] 坐标的列表\nprint(f\"实例编号范围: {min(instance_numbers)} - {max(instance_numbers)}\")\nprint(f\"切片Z轴位置范围: 从 {positions[0][2]:.2f} 到 {positions[-1][2]:.2f}\")",
    "crumbs": [
      "首页",
      "DiCube",
      "元数据存储机制"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#性能的飞跃秒级与毫秒级的较量",
    "href": "1.2_meta_storage.html#性能的飞跃秒级与毫秒级的较量",
    "title": "元数据存储机制",
    "section": "6. 性能的飞跃：秒级与毫秒级的较量",
    "text": "6. 性能的飞跃：秒级与毫秒级的较量\nDicomMeta 的设计优势最终体现在了性能上。让我们来实际对比一下，从一个包含200个切片的序列中读取所有 InstanceNumber 所需的时间。\n\n传统方式：需要循环打开、解析200个独立的文件。\nDiCube方式：只需打开1个文件，解压一小块元数据，并直接访问解析好的列表。\n\n\n\nimport time\n\n# 传统DICOM方式：遍历所有文件\nstart_time = time.time()\ndicom_instance_numbers = []\nfor dcm_file in all_files:\n    ds = pydicom.dcmread(dcm_file, stop_before_pixels=True)\n    dicom_instance_numbers.append(int(ds.InstanceNumber))\ndicom_time = time.time() - start_time\n\n# DiCube方式：一次性加载\nstart_time = time.time()\ndicube_meta = dicube.load_meta(\"temp_demo.dcbs\")\ndicube_instance_numbers = dicube_meta.get_values(CommonTags.InstanceNumber)\ndicube_time = time.time() - start_time\n\nprint(f\"传统DICOM I/O耗时: {dicom_time * 1000:.2f} 毫秒\")\nprint(f\"DiCube DicomMeta 耗时: {dicube_time * 1000:.2f} 毫秒\")\nprint(f\"\\n性能提升: {dicom_time / dicube_time:.1f} 倍\")\n\n# 清理临时文件\nos.remove(\"temp_demo.dcbs\")\n\n几十倍的性能提升是显而易见的。这背后是 I/O 模式的根本性变革：从多次、琐碎的文件操作，转变为一次性、集中的数据块读取。",
    "crumbs": [
      "首页",
      "DiCube",
      "元数据存储机制"
    ]
  },
  {
    "objectID": "1.2_meta_storage.html#总结",
    "href": "1.2_meta_storage.html#总结",
    "title": "元数据存储机制",
    "section": "7. 总结",
    "text": "7. 总结\nDiCube 的 DicomMeta 机制并非简单的元数据存储，而是一套针对现代医学影像数据处理特点精心设计的解决方案。其核心优势在于：\n\n智能去冗余：通过分离共享与非共享元数据，从根源上解决了DICOM的冗余问题，大幅减少存储占用。\n拥抱现代化标准：基于DICOM JSON标准，并采用高效的Zstandard压缩，确保了兼容性与极致性能。\n数量级的性能提升：将元数据读取从“遍历文件系统”的慢速操作，转变为“内存访问”级别的高速操作，为大规模数据分析和AI训练扫清了障碍。\n\n这些设计共同构成了 DiCube 处理医学影像数据的坚实基础，使其在效率和易用性上远超传统的工作流。",
    "crumbs": [
      "首页",
      "DiCube",
      "元数据存储机制"
    ]
  }
]